{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B99ZtF7-3tzN",
        "SNz90vqU_GEd",
        "7yotYq2M0DfO",
        "notHQ59Arfxu",
        "Smix1LYRAEC0",
        "9lCYz-d6lvoF"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0af051f3f626493688548d3b429033c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87d0fbbae3034dc0b54a6ba2ce182483",
              "IPY_MODEL_d2f4e412d3ea4a10b0550425f0fd27ec",
              "IPY_MODEL_16de76ce71844e46ae222c8fc9bccb16"
            ],
            "layout": "IPY_MODEL_7c012eaf6bea4d1fbd686951dfb0e80b"
          }
        },
        "87d0fbbae3034dc0b54a6ba2ce182483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61961ad818845798ffbad0ed2e9c922",
            "placeholder": "​",
            "style": "IPY_MODEL_5771bfdfa09d4266874006502d23033e",
            "value": "Downloading: 100%"
          }
        },
        "d2f4e412d3ea4a10b0550425f0fd27ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6130b15554784055a22f373a80b6c1ee",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b906806d47cd4e05b11418cda898f887",
            "value": 29
          }
        },
        "16de76ce71844e46ae222c8fc9bccb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf5b71e9b904e5da4becad7c675361b",
            "placeholder": "​",
            "style": "IPY_MODEL_b9b2c4af2e5143e78c4bb775349c2751",
            "value": " 29.0/29.0 [00:00&lt;00:00, 500B/s]"
          }
        },
        "7c012eaf6bea4d1fbd686951dfb0e80b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d61961ad818845798ffbad0ed2e9c922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5771bfdfa09d4266874006502d23033e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6130b15554784055a22f373a80b6c1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b906806d47cd4e05b11418cda898f887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cf5b71e9b904e5da4becad7c675361b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b2c4af2e5143e78c4bb775349c2751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30cc94ded3404120921f925bd2d94328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dbd124e98bd4e0baff45d24bfef613d",
              "IPY_MODEL_96c2d2d1b03748e1af05c45600e88e5d",
              "IPY_MODEL_d6762c3decb04004b2024ea6dafb6f27"
            ],
            "layout": "IPY_MODEL_c5a0568da41a4cfdb89bb1d3623f856d"
          }
        },
        "4dbd124e98bd4e0baff45d24bfef613d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a99f7e515d443683bc7d90bfa62b03",
            "placeholder": "​",
            "style": "IPY_MODEL_907f728fe8db4ba4b882a72276be6823",
            "value": "Downloading: 100%"
          }
        },
        "96c2d2d1b03748e1af05c45600e88e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fa5e538e7448fa93afcd30d8c8fcc7",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_491d0c327cce4faba560699dfc8bf0ea",
            "value": 625
          }
        },
        "d6762c3decb04004b2024ea6dafb6f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da7e70faeef146f68d54e6e22077aa81",
            "placeholder": "​",
            "style": "IPY_MODEL_2eab5c1058f94f0da9b2e552bc6d6022",
            "value": " 625/625 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "c5a0568da41a4cfdb89bb1d3623f856d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a99f7e515d443683bc7d90bfa62b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "907f728fe8db4ba4b882a72276be6823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96fa5e538e7448fa93afcd30d8c8fcc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491d0c327cce4faba560699dfc8bf0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da7e70faeef146f68d54e6e22077aa81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eab5c1058f94f0da9b2e552bc6d6022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "523de55dcc41452cbb888d0f3d636324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a8908f25eea48348c238a0985294a1f",
              "IPY_MODEL_1656f358f36342eea62dd83cc6eae0fe",
              "IPY_MODEL_6e2c5f01a634455b9a357b4889bf0133"
            ],
            "layout": "IPY_MODEL_cddcefa8c33b417c9b84ed1e508dbe9d"
          }
        },
        "3a8908f25eea48348c238a0985294a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3470c39b1a4e4eef9a410f7abdda0a48",
            "placeholder": "​",
            "style": "IPY_MODEL_4c0d7b3a53274e46b39c4f434101d080",
            "value": "Downloading: 100%"
          }
        },
        "1656f358f36342eea62dd83cc6eae0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9908d44eae465e8a735e6cd66398f0",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2ade9bd3182497fae8fc28ac7fdfe43",
            "value": 995526
          }
        },
        "6e2c5f01a634455b9a357b4889bf0133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_281d0b7667e74393aa599a49a41a157f",
            "placeholder": "​",
            "style": "IPY_MODEL_8e83627c33d74ea1911e579aa16b60fa",
            "value": " 972k/972k [00:01&lt;00:00, 1.26MB/s]"
          }
        },
        "cddcefa8c33b417c9b84ed1e508dbe9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3470c39b1a4e4eef9a410f7abdda0a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c0d7b3a53274e46b39c4f434101d080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb9908d44eae465e8a735e6cd66398f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ade9bd3182497fae8fc28ac7fdfe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "281d0b7667e74393aa599a49a41a157f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e83627c33d74ea1911e579aa16b60fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efd5de04a8aa4019ab67809f8bef8db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e914c7ea6ff34bf481a3089b459660c9",
              "IPY_MODEL_c274331d55d046eaa445b24c40a09f09",
              "IPY_MODEL_35660814168a4a07a1a5148ef1565b74"
            ],
            "layout": "IPY_MODEL_9632f53a4923425bb5d76611a0e023d9"
          }
        },
        "e914c7ea6ff34bf481a3089b459660c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0de114060a4f6aaf1fcd4612628470",
            "placeholder": "​",
            "style": "IPY_MODEL_fad064fae30b47b8a2873ad065097ea9",
            "value": "Downloading: 100%"
          }
        },
        "c274331d55d046eaa445b24c40a09f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1cbbbd250a7486393d8dd66f2a849da",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b3ff2a75076410593d5fe8cdbca8aee",
            "value": 1961828
          }
        },
        "35660814168a4a07a1a5148ef1565b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95bbc655a5a49d6a8abb48db23b7adf",
            "placeholder": "​",
            "style": "IPY_MODEL_70200492d1f24574966c77fa97f774a0",
            "value": " 1.87M/1.87M [00:01&lt;00:00, 2.68MB/s]"
          }
        },
        "9632f53a4923425bb5d76611a0e023d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0de114060a4f6aaf1fcd4612628470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad064fae30b47b8a2873ad065097ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1cbbbd250a7486393d8dd66f2a849da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3ff2a75076410593d5fe8cdbca8aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e95bbc655a5a49d6a8abb48db23b7adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70200492d1f24574966c77fa97f774a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aecfd22571d74aa7aefa51b53cb75768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_415887cd9ff64ce9a24d85109fe84464",
              "IPY_MODEL_ce3954e2e273441ab1db9bf1132086d8",
              "IPY_MODEL_09fe3397c8a945fc839a6bf461f0e6da"
            ],
            "layout": "IPY_MODEL_248203349bfe4349a33f6b7fe2e6dc84"
          }
        },
        "415887cd9ff64ce9a24d85109fe84464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f3ed58d25c46f78e7d83d404315e53",
            "placeholder": "​",
            "style": "IPY_MODEL_53315006c21e49dfb724cf74ce4741b2",
            "value": "Downloading: 100%"
          }
        },
        "ce3954e2e273441ab1db9bf1132086d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05fecb6e40464f0a8f08562bb238f7e8",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e6d778c333b48d09661213a5943d8de",
            "value": 714314041
          }
        },
        "09fe3397c8a945fc839a6bf461f0e6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2f2d1e1a1d4405948cea20a76183d9",
            "placeholder": "​",
            "style": "IPY_MODEL_63754a9749d048b6902d0dc6f3cb359c",
            "value": " 681M/681M [00:20&lt;00:00, 32.7MB/s]"
          }
        },
        "248203349bfe4349a33f6b7fe2e6dc84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f3ed58d25c46f78e7d83d404315e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53315006c21e49dfb724cf74ce4741b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05fecb6e40464f0a8f08562bb238f7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e6d778c333b48d09661213a5943d8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e2f2d1e1a1d4405948cea20a76183d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63754a9749d048b6902d0dc6f3cb359c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c17d89863ac341f49f1eab1cd6f8d4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d502385bda08484cad53ae7083bfcb38",
              "IPY_MODEL_52f57c772cc649e19d00efb2fc23f7cb",
              "IPY_MODEL_70d72b86c09c4b81a6d55d2e7275b7f6"
            ],
            "layout": "IPY_MODEL_a9a7aef302964923aae3e3fb12529be6"
          }
        },
        "d502385bda08484cad53ae7083bfcb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1063fdc5d0ae45e1a6a296fc09e2ac29",
            "placeholder": "​",
            "style": "IPY_MODEL_b07ecca24b324ee09e45c095618531f8",
            "value": "Downloading: 100%"
          }
        },
        "52f57c772cc649e19d00efb2fc23f7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aed0aa89b464a78afc5d29e1cc65735",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4bda0d69bd541c3b6d9d60c9636ccfe",
            "value": 29
          }
        },
        "70d72b86c09c4b81a6d55d2e7275b7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5e2b6a47bd44ffbd0d45de2d54ba3e",
            "placeholder": "​",
            "style": "IPY_MODEL_95a2b88cb81c4a4184fe3e451cc76a7c",
            "value": " 29.0/29.0 [00:00&lt;00:00, 526B/s]"
          }
        },
        "a9a7aef302964923aae3e3fb12529be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1063fdc5d0ae45e1a6a296fc09e2ac29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07ecca24b324ee09e45c095618531f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aed0aa89b464a78afc5d29e1cc65735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bda0d69bd541c3b6d9d60c9636ccfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc5e2b6a47bd44ffbd0d45de2d54ba3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95a2b88cb81c4a4184fe3e451cc76a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902defff56344ea395dbcb61e0c9e99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8944a48a35345a98abb39fbcbf55ae4",
              "IPY_MODEL_a04e32197ce8482cbe6978ffd41e3ecd",
              "IPY_MODEL_bc4d14c9ae1248189195480c6b24a794"
            ],
            "layout": "IPY_MODEL_3866652bbdc24f2b862c4e0b8790b090"
          }
        },
        "c8944a48a35345a98abb39fbcbf55ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d4cd946c214e4eb27ec2d9de234a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe01244c6a74c65a461b1448a723650",
            "value": "Downloading: 100%"
          }
        },
        "a04e32197ce8482cbe6978ffd41e3ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db784857eb164667a43f88845a080bc3",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24f32ed20a934a96841f4a78e12d8a7f",
            "value": 625
          }
        },
        "bc4d14c9ae1248189195480c6b24a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb256d3df52444e1b7a45a3e438648a6",
            "placeholder": "​",
            "style": "IPY_MODEL_1efe339459f545dea502994288a8ccec",
            "value": " 625/625 [00:00&lt;00:00, 14.5kB/s]"
          }
        },
        "3866652bbdc24f2b862c4e0b8790b090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d4cd946c214e4eb27ec2d9de234a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe01244c6a74c65a461b1448a723650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db784857eb164667a43f88845a080bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f32ed20a934a96841f4a78e12d8a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb256d3df52444e1b7a45a3e438648a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1efe339459f545dea502994288a8ccec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f980eab42cc422c9dabb3a12e0562b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab163f315f6a4745827c8bc31e04c072",
              "IPY_MODEL_6900d5ea4c2d4dd8b14f9b6a908843e6",
              "IPY_MODEL_642bc5f91bb54ac786eb8f7f1c54755d"
            ],
            "layout": "IPY_MODEL_306ced83fc1046ca9abb63d3111bfb2a"
          }
        },
        "ab163f315f6a4745827c8bc31e04c072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf96f1a6ce94637b742f251aebb9e6d",
            "placeholder": "​",
            "style": "IPY_MODEL_4d930bcd00a1452389cc18eb302124ee",
            "value": "Downloading: 100%"
          }
        },
        "6900d5ea4c2d4dd8b14f9b6a908843e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcfd2449247d478b8af10d6b50bf1e31",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc2440f4bda34c3da917c5a4ad3da21e",
            "value": 995526
          }
        },
        "642bc5f91bb54ac786eb8f7f1c54755d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78752218cda845ff897cd5a9aa1b18b5",
            "placeholder": "​",
            "style": "IPY_MODEL_4444efe17c7d47b3a876bf87320f9d32",
            "value": " 972k/972k [00:00&lt;00:00, 6.03MB/s]"
          }
        },
        "306ced83fc1046ca9abb63d3111bfb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf96f1a6ce94637b742f251aebb9e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d930bcd00a1452389cc18eb302124ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcfd2449247d478b8af10d6b50bf1e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2440f4bda34c3da917c5a4ad3da21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78752218cda845ff897cd5a9aa1b18b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4444efe17c7d47b3a876bf87320f9d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1d423f440a4b4b81e39c65e44bc3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36d5c63ea978400c940bfc548b5dcb09",
              "IPY_MODEL_3adb53fc114949fe9c754aac3cafd48a",
              "IPY_MODEL_379d1257d3da40d6b14c0c8f476599dd"
            ],
            "layout": "IPY_MODEL_708fe354e5c9431bbf682e3b5819b564"
          }
        },
        "36d5c63ea978400c940bfc548b5dcb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44de8ded12d643ecb0a3b98ca36338d1",
            "placeholder": "​",
            "style": "IPY_MODEL_30bbbb6229314dcda92bdee727be6828",
            "value": "Downloading: 100%"
          }
        },
        "3adb53fc114949fe9c754aac3cafd48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8047f1b790416698eeb44ba704328d",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f616eb31385415b95abd742b28de16e",
            "value": 1961828
          }
        },
        "379d1257d3da40d6b14c0c8f476599dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23669f124d09432a8c298228fa9271bf",
            "placeholder": "​",
            "style": "IPY_MODEL_32e7790388194e25b6fe74b3dfbf2a7a",
            "value": " 1.87M/1.87M [00:00&lt;00:00, 1.63MB/s]"
          }
        },
        "708fe354e5c9431bbf682e3b5819b564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44de8ded12d643ecb0a3b98ca36338d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bbbb6229314dcda92bdee727be6828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d8047f1b790416698eeb44ba704328d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f616eb31385415b95abd742b28de16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23669f124d09432a8c298228fa9271bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e7790388194e25b6fe74b3dfbf2a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0285c1cb9e64fcc9479067a22992cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2165f7c9533548979cb0c04d496e7a18",
              "IPY_MODEL_0c46d62fc5044859b5aabd965ce0db0c",
              "IPY_MODEL_ffaeaa18dafc4ead9e0da4b7d1f4775d"
            ],
            "layout": "IPY_MODEL_6afb87d412144690943e92b92fb3d4a9"
          }
        },
        "2165f7c9533548979cb0c04d496e7a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a69ebc6c074479ab25476d54028705",
            "placeholder": "​",
            "style": "IPY_MODEL_f6210b5460c145608661bac6bea1ffa7",
            "value": "Downloading: 100%"
          }
        },
        "0c46d62fc5044859b5aabd965ce0db0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18a20559570d42c1897ac0982b953005",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b2761137e54956a0e148ca2d21778b",
            "value": 714314041
          }
        },
        "ffaeaa18dafc4ead9e0da4b7d1f4775d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b88d21fc1c493c97137856e4526156",
            "placeholder": "​",
            "style": "IPY_MODEL_62e48cdc220a43c6afd8bf4e189d6f08",
            "value": " 681M/681M [00:17&lt;00:00, 47.6MB/s]"
          }
        },
        "6afb87d412144690943e92b92fb3d4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a69ebc6c074479ab25476d54028705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6210b5460c145608661bac6bea1ffa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18a20559570d42c1897ac0982b953005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b2761137e54956a0e148ca2d21778b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8b88d21fc1c493c97137856e4526156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e48cdc220a43c6afd8bf4e189d6f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893d7b75c1524d32913000d646fd714f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d99b51cc42bc45f192c6a26e1f4b864b",
              "IPY_MODEL_a42a7ce15154478690390b637e54c4cb",
              "IPY_MODEL_dc99fb11cacb48f99c8ca9736495cfb0"
            ],
            "layout": "IPY_MODEL_2b22be34ba5648e5840a0e6af318fceb"
          }
        },
        "d99b51cc42bc45f192c6a26e1f4b864b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05093a41e4b340ac8994ef58113417ba",
            "placeholder": "​",
            "style": "IPY_MODEL_34d9591b0f55467097c81a3fb580276f",
            "value": "Downloading: 100%"
          }
        },
        "a42a7ce15154478690390b637e54c4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ec0070f9e147f89c5c8c40077bb532",
            "max": 1649718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3c12481d5af4f94bc52d9c298bd03a8",
            "value": 1649718
          }
        },
        "dc99fb11cacb48f99c8ca9736495cfb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639916ed7a49422dba774f23b85ad809",
            "placeholder": "​",
            "style": "IPY_MODEL_87acd0c18fb54a6fa572b6f30d0ae53c",
            "value": " 1.57M/1.57M [00:00&lt;00:00, 1.70MB/s]"
          }
        },
        "2b22be34ba5648e5840a0e6af318fceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05093a41e4b340ac8994ef58113417ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d9591b0f55467097c81a3fb580276f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75ec0070f9e147f89c5c8c40077bb532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c12481d5af4f94bc52d9c298bd03a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "639916ed7a49422dba774f23b85ad809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87acd0c18fb54a6fa572b6f30d0ae53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675bd83826084c5fb8438210bbddbf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93760ed055b84aa2b6009b5584170119",
              "IPY_MODEL_8391cc5f7f0a4c70be653a5001f800bb",
              "IPY_MODEL_3ea4eca126b143f8ad29e25074371159"
            ],
            "layout": "IPY_MODEL_59f83dbc59c44346888607013737dbb3"
          }
        },
        "93760ed055b84aa2b6009b5584170119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_971c991ea81e4c1aacd42d3ac492b9c9",
            "placeholder": "​",
            "style": "IPY_MODEL_813a631779d24855aeaca09209d1e48f",
            "value": "Downloading: 100%"
          }
        },
        "8391cc5f7f0a4c70be653a5001f800bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f707336fec48de9de3b1487379bca3",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627f42dbac8d47e795e42b09bd9595ee",
            "value": 112
          }
        },
        "3ea4eca126b143f8ad29e25074371159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685b9bdd23b74955a014434d4a13ffd9",
            "placeholder": "​",
            "style": "IPY_MODEL_064836b456c84075987773ef8c1a424b",
            "value": " 112/112 [00:00&lt;00:00, 2.79kB/s]"
          }
        },
        "59f83dbc59c44346888607013737dbb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971c991ea81e4c1aacd42d3ac492b9c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813a631779d24855aeaca09209d1e48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f707336fec48de9de3b1487379bca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627f42dbac8d47e795e42b09bd9595ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "685b9bdd23b74955a014434d4a13ffd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064836b456c84075987773ef8c1a424b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "190ee46a72bd49cdb1f9c3d5f33363d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29c15df4225042fe9034b567e4c57810",
              "IPY_MODEL_afc3b5aef8804431995fc39287f4967a",
              "IPY_MODEL_27a9cddb3b254b64b074544f384f4642"
            ],
            "layout": "IPY_MODEL_384a9f5bd0a84e6b881829b1356b603d"
          }
        },
        "29c15df4225042fe9034b567e4c57810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef89a79e4f047549c23786c72cb7ec1",
            "placeholder": "​",
            "style": "IPY_MODEL_63dc8cf78a4f4196859bed1192e9f1a9",
            "value": "Downloading: 100%"
          }
        },
        "afc3b5aef8804431995fc39287f4967a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a22bdfc23dd347018ebeeed0d668b48b",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbd5c723d6b74ecd92910836e6f16eae",
            "value": 24
          }
        },
        "27a9cddb3b254b64b074544f384f4642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3879f9844efd450fa2568abcba585287",
            "placeholder": "​",
            "style": "IPY_MODEL_0065eecb61534f3eb5ef89c10a19df1d",
            "value": " 24.0/24.0 [00:00&lt;00:00, 591B/s]"
          }
        },
        "384a9f5bd0a84e6b881829b1356b603d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef89a79e4f047549c23786c72cb7ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63dc8cf78a4f4196859bed1192e9f1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a22bdfc23dd347018ebeeed0d668b48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd5c723d6b74ecd92910836e6f16eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3879f9844efd450fa2568abcba585287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0065eecb61534f3eb5ef89c10a19df1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8105ec23811d42f893298bfb902c2ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_021924faed294e4bb81995cfc001753c",
              "IPY_MODEL_7a229c3b09a14a9e951488e9f0b33ac7",
              "IPY_MODEL_985f3015b3794e62b16f8e8ada91e7ed"
            ],
            "layout": "IPY_MODEL_3b3444e056e54ebca56fbb177958d9d7"
          }
        },
        "021924faed294e4bb81995cfc001753c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb161ec9ffb4e93819efb7f850c934e",
            "placeholder": "​",
            "style": "IPY_MODEL_cc7275f77afa42f3a2c06220eda3f51d",
            "value": "Downloading: 100%"
          }
        },
        "7a229c3b09a14a9e951488e9f0b33ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9debf3ae2f8148739d0a2ee7b57e1001",
            "max": 642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c835d783bff4411f8f334a0b3dc77efa",
            "value": 642
          }
        },
        "985f3015b3794e62b16f8e8ada91e7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f10fc033c1f412b9f48440cf3b00ffc",
            "placeholder": "​",
            "style": "IPY_MODEL_40eae8a3fc194affa4205e8f1746e083",
            "value": " 642/642 [00:00&lt;00:00, 14.4kB/s]"
          }
        },
        "3b3444e056e54ebca56fbb177958d9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb161ec9ffb4e93819efb7f850c934e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7275f77afa42f3a2c06220eda3f51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9debf3ae2f8148739d0a2ee7b57e1001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c835d783bff4411f8f334a0b3dc77efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f10fc033c1f412b9f48440cf3b00ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40eae8a3fc194affa4205e8f1746e083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "000649ede68249aeb41c0f3ae7579da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e63118c095da4d37b8b88dc7be730a56",
              "IPY_MODEL_a34ef00462cd4370804579513ec2cfd0",
              "IPY_MODEL_ebd056dbb62443be9d6173947b660bcc"
            ],
            "layout": "IPY_MODEL_028b8596c90949a58f5ef49b80284c1e"
          }
        },
        "e63118c095da4d37b8b88dc7be730a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f7ee259df6c41a8ac90bdaf52e048da",
            "placeholder": "​",
            "style": "IPY_MODEL_353502940b3b4e9a99a9b4ce7b280426",
            "value": "Downloading: 100%"
          }
        },
        "a34ef00462cd4370804579513ec2cfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa57acc94aab4ed5a2289b45211b7d36",
            "max": 714355318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1987d6dd4c174a55830a2595ee4cece4",
            "value": 714355318
          }
        },
        "ebd056dbb62443be9d6173947b660bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0956682acbcf4c519b5f5006a7af705b",
            "placeholder": "​",
            "style": "IPY_MODEL_a8229f8843a9478c9b1353d6225aabc9",
            "value": " 681M/681M [00:16&lt;00:00, 46.5MB/s]"
          }
        },
        "028b8596c90949a58f5ef49b80284c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7ee259df6c41a8ac90bdaf52e048da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353502940b3b4e9a99a9b4ce7b280426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa57acc94aab4ed5a2289b45211b7d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1987d6dd4c174a55830a2595ee4cece4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0956682acbcf4c519b5f5006a7af705b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8229f8843a9478c9b1353d6225aabc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!cd msdt-follina-main\n",
        "!python3 follina.py -c \"notepad\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxPIQHQT_AbC",
        "outputId": "eeb9c125-80ed-4230-f199-24b90c0372ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'follina.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBHavPjnsjS1"
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "Z7XSO_bA-yT-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIF4ueuj5Ytm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c894742a-7cfe-47d1-8c1f-992fdb6e746b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 12.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpq5KM7a30K_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0af051f3f626493688548d3b429033c5",
            "87d0fbbae3034dc0b54a6ba2ce182483",
            "d2f4e412d3ea4a10b0550425f0fd27ec",
            "16de76ce71844e46ae222c8fc9bccb16",
            "7c012eaf6bea4d1fbd686951dfb0e80b",
            "d61961ad818845798ffbad0ed2e9c922",
            "5771bfdfa09d4266874006502d23033e",
            "6130b15554784055a22f373a80b6c1ee",
            "b906806d47cd4e05b11418cda898f887",
            "2cf5b71e9b904e5da4becad7c675361b",
            "b9b2c4af2e5143e78c4bb775349c2751",
            "30cc94ded3404120921f925bd2d94328",
            "4dbd124e98bd4e0baff45d24bfef613d",
            "96c2d2d1b03748e1af05c45600e88e5d",
            "d6762c3decb04004b2024ea6dafb6f27",
            "c5a0568da41a4cfdb89bb1d3623f856d",
            "17a99f7e515d443683bc7d90bfa62b03",
            "907f728fe8db4ba4b882a72276be6823",
            "96fa5e538e7448fa93afcd30d8c8fcc7",
            "491d0c327cce4faba560699dfc8bf0ea",
            "da7e70faeef146f68d54e6e22077aa81",
            "2eab5c1058f94f0da9b2e552bc6d6022",
            "523de55dcc41452cbb888d0f3d636324",
            "3a8908f25eea48348c238a0985294a1f",
            "1656f358f36342eea62dd83cc6eae0fe",
            "6e2c5f01a634455b9a357b4889bf0133",
            "cddcefa8c33b417c9b84ed1e508dbe9d",
            "3470c39b1a4e4eef9a410f7abdda0a48",
            "4c0d7b3a53274e46b39c4f434101d080",
            "cb9908d44eae465e8a735e6cd66398f0",
            "f2ade9bd3182497fae8fc28ac7fdfe43",
            "281d0b7667e74393aa599a49a41a157f",
            "8e83627c33d74ea1911e579aa16b60fa",
            "efd5de04a8aa4019ab67809f8bef8db4",
            "e914c7ea6ff34bf481a3089b459660c9",
            "c274331d55d046eaa445b24c40a09f09",
            "35660814168a4a07a1a5148ef1565b74",
            "9632f53a4923425bb5d76611a0e023d9",
            "ee0de114060a4f6aaf1fcd4612628470",
            "fad064fae30b47b8a2873ad065097ea9",
            "f1cbbbd250a7486393d8dd66f2a849da",
            "3b3ff2a75076410593d5fe8cdbca8aee",
            "e95bbc655a5a49d6a8abb48db23b7adf",
            "70200492d1f24574966c77fa97f774a0",
            "aecfd22571d74aa7aefa51b53cb75768",
            "415887cd9ff64ce9a24d85109fe84464",
            "ce3954e2e273441ab1db9bf1132086d8",
            "09fe3397c8a945fc839a6bf461f0e6da",
            "248203349bfe4349a33f6b7fe2e6dc84",
            "a3f3ed58d25c46f78e7d83d404315e53",
            "53315006c21e49dfb724cf74ce4741b2",
            "05fecb6e40464f0a8f08562bb238f7e8",
            "7e6d778c333b48d09661213a5943d8de",
            "6e2f2d1e1a1d4405948cea20a76183d9",
            "63754a9749d048b6902d0dc6f3cb359c"
          ]
        },
        "outputId": "8158b2b7-a4b1-473c-a1f8-29145c48ecac"
      },
      "source": [
        "from deeppavlov import configs, build_model\n",
        "\n",
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult_torch, download=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-30 21:59:06.631 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_mult_torch.tar.gz to /root/.deeppavlov/ner_ontonotes_bert_mult_torch.tar.gz\n",
            "100%|██████████| 1.38G/1.38G [02:10<00:00, 10.5MB/s]\n",
            "2022-06-30 22:01:19.271 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/ner_ontonotes_bert_mult_torch.tar.gz archive into /root/.deeppavlov/models\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype=np.int):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0af051f3f626493688548d3b429033c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30cc94ded3404120921f925bd2d94328"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "523de55dcc41452cbb888d0f3d636324"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efd5de04a8aa4019ab67809f8bef8db4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-30 22:02:02.106 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/tag.dict]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aecfd22571d74aa7aefa51b53cb75768"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2022-06-30 22:02:27.961 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 360: Load path /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/model is given.\n",
            "2022-06-30 22:02:27.963 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 367: Load path /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/model.pth.tar exists.\n",
            "2022-06-30 22:02:27.967 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 368: Initializing `TorchTransformersSequenceTagger` from saved.\n",
            "2022-06-30 22:02:27.970 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 371: Loading weights from /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/model.pth.tar.\n",
            "2022-06-30 22:02:30.996 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
            " BertForTokenClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6xU8x2EHLMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_ner=ner_model(['Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.'])\n",
        "counter=0\n",
        "print(list_ner[0][0])\n",
        "list_of_ent=[]\n",
        "list_of_pos=[]\n",
        "list_of_rels=[[]]\n",
        "for i in list_ner[1][0]:\n",
        "  if i!='O':\n",
        "    list_of_ent.append(i)\n",
        "    list_of_pos.append(counter)\n",
        "    print(i[2:])\n",
        "    #print(list[0][0][counter])\n",
        "  counter=counter+1\n",
        "print(list_of_ent,list_of_pos)\n",
        "\n",
        "counter=1\n",
        "for j in list_of_ent:\n",
        "  if (list_of_ent[counter-1][0] == \"B\")and(list_of_ent[counter][0] == \"B\"):\n",
        "    value_of=list_of_pos[counter]-list_of_pos[counter-1]\n",
        "    print(value_of)\n",
        "    for i in range(list_of_pos[counter-1],list_of_pos[counter]+1):\n",
        "      print(list_ner[0][0][i])\n",
        "  if (counter<list_of_pos[-1]-1):\n",
        "    counter+=1"
      ],
      "metadata": {
        "id": "xQcKvtTzpVJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7iXjZup8GL1"
      },
      "source": [
        "from deeppavlov import configs, build_model\n",
        "model = build_model(configs.relation_extraction.re_rured, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1RoSmS9RFR1"
      },
      "source": [
        "sentence_tokens = [['Вице', '-', 'премьер', 'по', 'социальным', 'вопросам', 'Татьяна', 'Голикова', 'рассказала', ',', 'в', 'каких', 'регионах', 'России', 'зафиксирована', 'наиболее', 'высокая', 'смертность', 'от', 'рака', ',', 'сообщает', 'РИА', 'Новости', '.', 'По', 'словам', 'Голиковой', ',', 'чаще', 'всего', 'онкологические', 'заболевания', 'становились', 'причиной', 'смерти', 'в', 'Псковской', ',', 'Тверской', ',', 'Тульской', 'и', 'Орловской', 'областях', ',', 'а', 'также', 'в', 'Севастополе', '.', 'Вице', '-', 'премьер', 'напомнила', ',', 'что', 'главные', 'факторы', 'смертности', 'в', 'России', '—', 'рак', 'и', 'болезни', 'системы', 'кровообращения', '.', 'В', 'начале', 'года', 'стало', 'известно', ',', 'что', 'смертность', 'от', 'онкологических', 'заболеваний', 'среди', 'россиян', 'снизилась', 'впервые', 'за', 'три', 'года', '.', 'По', 'данным', 'Росстата', ',', 'в', '2017', 'году', 'от', 'рака', 'умерли', '289', 'тысяч', 'человек', '.', 'Это', 'на', '3', ',', '5', 'процента', 'меньше', ',', 'чем', 'годом', 'ранее', '.']]\n",
        "entity_pos = [[[(6, 7)], [(13, 14)]]]\n",
        "entity_tags = [[\"PERSON\", \"GPE\"]]\n",
        "pred = model(sentence_tokens, entity_pos, entity_tags)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# КУРСАЧ 2 СЕМ"
      ],
      "metadata": {
        "id": "Vclc1fFSVRnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeppavlov\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8Ih4a8JYVXdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "707f7704-6a7d-4912-e5f3-61bd39bc5be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deeppavlov\n",
            "  Downloading deeppavlov-0.17.4-py3-none-any.whl (878 kB)\n",
            "\u001b[K     |████████████████████████████████| 878 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 50.1 MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 30.8 MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
            "Collecting pymorphy2==0.8\n",
            "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 21.1 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.62.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
            "Collecting pyopenssl==22.0.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 40.4 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 20.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting ruamel.yaml==0.15.100\n",
            "  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n",
            "\u001b[K     |████████████████████████████████| 654 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.17.3)\n",
            "Collecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting overrides==2.7.0\n",
            "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
            "Collecting aio-pika==6.4.1\n",
            "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 11 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 28.9 MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting requests==2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 28.2 MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 27.8 MB/s \n",
            "\u001b[?25hCollecting yarl\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 58.6 MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting cryptography>=35.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2022.6.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
            "Collecting httptools==0.1.*\n",
            "  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 71.4 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.1.1)\n",
            "Collecting multidict>=4.0\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=26ad9778d80667ce885fc10e2850822c78a1feb57e8afd5cdf5cb6815d79de4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5603 sha256=74ade2b69d25aca1b117622bb59974f1cb62cf87815208a5c7cd8ca81901ce0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41405 sha256=2679ae57b2c830d55add0ab0b9571a55dc2ae311d05ad0ac4f6598afdc0b23ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=2fa8f3cb234168ba1aecbc1a0cff4363981be75904573c8559af3a9f4d63f8a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=fea1fc8c503e65a0ae338bc986add36d6d0a5c92f05314ab209fa420020e172f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=0e843e9fb7f23b4d037d15152c301116e1f808787b4ea59484e3426b0a8186c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n",
            "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n",
            "Installing collected packages: multidict, idna, yarl, pamqp, numpy, websockets, uvloop, tqdm, starlette, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, filelock, fastapi, Cython, aio-pika, deeppavlov\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.1\n",
            "    Uninstalling pytz-2022.1:\n",
            "      Successfully uninstalled pytz-2022.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.8.2\n",
            "    Uninstalling pydantic-1.8.2:\n",
            "      Successfully uninstalled pydantic-1.8.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.14.1\n",
            "    Uninstalling prometheus-client-0.14.1:\n",
            "      Successfully uninstalled prometheus-client-0.14.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.7.1\n",
            "    Uninstalling filelock-3.7.1:\n",
            "      Successfully uninstalled filelock-3.7.1\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.30\n",
            "    Uninstalling Cython-0.29.30:\n",
            "      Successfully uninstalled Cython-0.29.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
            "thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "spacy 3.3.1 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-37.0.4 dawg-python-0.7.2 deeppavlov-0.17.4 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-6.0.2 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-22.0.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.62.0 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.18.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqRTcB3gKlWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fed040f-88b6-4837-fc73-bbd5e6c6373e"
      },
      "source": [
        "!pip install corus\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting corus\n",
            "  Downloading corus-0.9.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: corus\n",
            "Successfully installed corus-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVmI_pZGKqih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5ca4ee-25da-41fa-8ec1-668968e4f68e"
      },
      "source": [
        " !wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-06 22:26:55--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220706%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220706T222655Z&X-Amz-Expires=300&X-Amz-Signature=c5f2da24f6b17c34b2526d7580b4301f4b20920aaede3ec3bb693f3272123dfc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-07-06 22:26:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220706%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220706T222655Z&X-Amz-Expires=300&X-Amz-Signature=c5f2da24f6b17c34b2526d7580b4301f4b20920aaede3ec3bb693f3272123dfc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  8.09MB/s    in 34s     \n",
            "\n",
            "2022-07-06 22:27:30 (14.7 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import configs, build_model\n",
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult_torch, download=True)"
      ],
      "metadata": {
        "id": "XUpWJtlFXT1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c17d89863ac341f49f1eab1cd6f8d4e6",
            "d502385bda08484cad53ae7083bfcb38",
            "52f57c772cc649e19d00efb2fc23f7cb",
            "70d72b86c09c4b81a6d55d2e7275b7f6",
            "a9a7aef302964923aae3e3fb12529be6",
            "1063fdc5d0ae45e1a6a296fc09e2ac29",
            "b07ecca24b324ee09e45c095618531f8",
            "9aed0aa89b464a78afc5d29e1cc65735",
            "b4bda0d69bd541c3b6d9d60c9636ccfe",
            "dc5e2b6a47bd44ffbd0d45de2d54ba3e",
            "95a2b88cb81c4a4184fe3e451cc76a7c",
            "902defff56344ea395dbcb61e0c9e99f",
            "c8944a48a35345a98abb39fbcbf55ae4",
            "a04e32197ce8482cbe6978ffd41e3ecd",
            "bc4d14c9ae1248189195480c6b24a794",
            "3866652bbdc24f2b862c4e0b8790b090",
            "82d4cd946c214e4eb27ec2d9de234a6c",
            "2fe01244c6a74c65a461b1448a723650",
            "db784857eb164667a43f88845a080bc3",
            "24f32ed20a934a96841f4a78e12d8a7f",
            "eb256d3df52444e1b7a45a3e438648a6",
            "1efe339459f545dea502994288a8ccec",
            "1f980eab42cc422c9dabb3a12e0562b8",
            "ab163f315f6a4745827c8bc31e04c072",
            "6900d5ea4c2d4dd8b14f9b6a908843e6",
            "642bc5f91bb54ac786eb8f7f1c54755d",
            "306ced83fc1046ca9abb63d3111bfb2a",
            "1bf96f1a6ce94637b742f251aebb9e6d",
            "4d930bcd00a1452389cc18eb302124ee",
            "bcfd2449247d478b8af10d6b50bf1e31",
            "bc2440f4bda34c3da917c5a4ad3da21e",
            "78752218cda845ff897cd5a9aa1b18b5",
            "4444efe17c7d47b3a876bf87320f9d32",
            "ec1d423f440a4b4b81e39c65e44bc3ad",
            "36d5c63ea978400c940bfc548b5dcb09",
            "3adb53fc114949fe9c754aac3cafd48a",
            "379d1257d3da40d6b14c0c8f476599dd",
            "708fe354e5c9431bbf682e3b5819b564",
            "44de8ded12d643ecb0a3b98ca36338d1",
            "30bbbb6229314dcda92bdee727be6828",
            "3d8047f1b790416698eeb44ba704328d",
            "4f616eb31385415b95abd742b28de16e",
            "23669f124d09432a8c298228fa9271bf",
            "32e7790388194e25b6fe74b3dfbf2a7a",
            "f0285c1cb9e64fcc9479067a22992cc3",
            "2165f7c9533548979cb0c04d496e7a18",
            "0c46d62fc5044859b5aabd965ce0db0c",
            "ffaeaa18dafc4ead9e0da4b7d1f4775d",
            "6afb87d412144690943e92b92fb3d4a9",
            "53a69ebc6c074479ab25476d54028705",
            "f6210b5460c145608661bac6bea1ffa7",
            "18a20559570d42c1897ac0982b953005",
            "f2b2761137e54956a0e148ca2d21778b",
            "d8b88d21fc1c493c97137856e4526156",
            "62e48cdc220a43c6afd8bf4e189d6f08"
          ]
        },
        "outputId": "092bf568-bbd4-47de-e88e-6cf5b3eb3ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-06 22:27:31.601 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_mult_torch.tar.gz to /root/.deeppavlov/ner_ontonotes_bert_mult_torch.tar.gz\n",
            "100%|██████████| 1.38G/1.38G [00:51<00:00, 26.8MB/s]\n",
            "2022-07-06 22:28:23.738 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/ner_ontonotes_bert_mult_torch.tar.gz archive into /root/.deeppavlov/models\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype=np.int):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c17d89863ac341f49f1eab1cd6f8d4e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "902defff56344ea395dbcb61e0c9e99f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f980eab42cc422c9dabb3a12e0562b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec1d423f440a4b4b81e39c65e44bc3ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-06 22:28:56.155 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/tag.dict]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0285c1cb9e64fcc9479067a22992cc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2022-07-06 22:29:17.903 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 360: Load path /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/model is given.\n",
            "2022-07-06 22:29:17.907 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 367: Load path /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/model.pth.tar exists.\n",
            "2022-07-06 22:29:17.913 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 368: Initializing `TorchTransformersSequenceTagger` from saved.\n",
            "2022-07-06 22:29:17.916 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 371: Loading weights from /root/.deeppavlov/models/ner_ontonotes_bert_mult_torch/bert-base-multilingual-cased/model.pth.tar.\n",
            "2022-07-06 22:29:21.180 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
            " BertForTokenClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import configs, build_model\n",
        "model = build_model(configs.relation_extraction.re_rured, download=True)"
      ],
      "metadata": {
        "id": "v9EJk_2tXT92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "893d7b75c1524d32913000d646fd714f",
            "d99b51cc42bc45f192c6a26e1f4b864b",
            "a42a7ce15154478690390b637e54c4cb",
            "dc99fb11cacb48f99c8ca9736495cfb0",
            "2b22be34ba5648e5840a0e6af318fceb",
            "05093a41e4b340ac8994ef58113417ba",
            "34d9591b0f55467097c81a3fb580276f",
            "75ec0070f9e147f89c5c8c40077bb532",
            "b3c12481d5af4f94bc52d9c298bd03a8",
            "639916ed7a49422dba774f23b85ad809",
            "87acd0c18fb54a6fa572b6f30d0ae53c",
            "675bd83826084c5fb8438210bbddbf2c",
            "93760ed055b84aa2b6009b5584170119",
            "8391cc5f7f0a4c70be653a5001f800bb",
            "3ea4eca126b143f8ad29e25074371159",
            "59f83dbc59c44346888607013737dbb3",
            "971c991ea81e4c1aacd42d3ac492b9c9",
            "813a631779d24855aeaca09209d1e48f",
            "25f707336fec48de9de3b1487379bca3",
            "627f42dbac8d47e795e42b09bd9595ee",
            "685b9bdd23b74955a014434d4a13ffd9",
            "064836b456c84075987773ef8c1a424b",
            "190ee46a72bd49cdb1f9c3d5f33363d9",
            "29c15df4225042fe9034b567e4c57810",
            "afc3b5aef8804431995fc39287f4967a",
            "27a9cddb3b254b64b074544f384f4642",
            "384a9f5bd0a84e6b881829b1356b603d",
            "9ef89a79e4f047549c23786c72cb7ec1",
            "63dc8cf78a4f4196859bed1192e9f1a9",
            "a22bdfc23dd347018ebeeed0d668b48b",
            "fbd5c723d6b74ecd92910836e6f16eae",
            "3879f9844efd450fa2568abcba585287",
            "0065eecb61534f3eb5ef89c10a19df1d",
            "8105ec23811d42f893298bfb902c2ecc",
            "021924faed294e4bb81995cfc001753c",
            "7a229c3b09a14a9e951488e9f0b33ac7",
            "985f3015b3794e62b16f8e8ada91e7ed",
            "3b3444e056e54ebca56fbb177958d9d7",
            "5fb161ec9ffb4e93819efb7f850c934e",
            "cc7275f77afa42f3a2c06220eda3f51d",
            "9debf3ae2f8148739d0a2ee7b57e1001",
            "c835d783bff4411f8f334a0b3dc77efa",
            "0f10fc033c1f412b9f48440cf3b00ffc",
            "40eae8a3fc194affa4205e8f1746e083",
            "000649ede68249aeb41c0f3ae7579da2",
            "e63118c095da4d37b8b88dc7be730a56",
            "a34ef00462cd4370804579513ec2cfd0",
            "ebd056dbb62443be9d6173947b660bcc",
            "028b8596c90949a58f5ef49b80284c1e",
            "8f7ee259df6c41a8ac90bdaf52e048da",
            "353502940b3b4e9a99a9b4ce7b280426",
            "fa57acc94aab4ed5a2289b45211b7d36",
            "1987d6dd4c174a55830a2595ee4cece4",
            "0956682acbcf4c519b5f5006a7af705b",
            "a8229f8843a9478c9b1353d6225aabc9"
          ]
        },
        "outputId": "f4d6a029-bfdf-4e04-f6cf-e78f5a1a2680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-06 22:29:21.945 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/relation_extraction/re_rured_model.tar.gz to /root/.deeppavlov/models/re_rured_model.tar.gz\n",
            "100%|██████████| 1.41G/1.41G [00:49<00:00, 28.6MB/s]\n",
            "2022-07-06 22:30:11.893 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/re_rured_model.tar.gz archive into /root/.deeppavlov/models/re_rured\n",
            "2022-07-06 22:30:33.67 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/relation_extraction/rured.tar.gz to /root/.deeppavlov/downloads/rured.tar.gz\n",
            "100%|██████████| 21.3M/21.3M [00:01<00:00, 16.0MB/s]\n",
            "2022-07-06 22:30:35.115 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/rured.tar.gz archive into /root/.deeppavlov/downloads/rured\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.57M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "893d7b75c1524d32913000d646fd714f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "675bd83826084c5fb8438210bbddbf2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "190ee46a72bd49cdb1f9c3d5f33363d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8105ec23811d42f893298bfb902c2ecc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-06 22:30:38.222 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 149: Load path /root/.deeppavlov/models/re_rured/model is given.\n",
            "2022-07-06 22:30:38.225 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 156: Load path /root/.deeppavlov/models/re_rured/model.pth.tar exists.\n",
            "2022-07-06 22:30:38.227 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 157: Initializing `REBertModel` from saved.\n",
            "2022-07-06 22:30:38.230 INFO in 'deeppavlov.models.classifiers.re_bert'['re_bert'] at line 159: From pretrained DeepPavlov/rubert-base-cased.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "000649ede68249aeb41c0f3ae7579da2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2022-07-06 22:31:00.33 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 163: Loading weights from /root/.deeppavlov/models/re_rured/model.pth.tar.\n",
            "2022-07-06 22:31:03.334 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
            " BertWithAdaThresholdLocContextPooling(\n",
            "  (loss_fnt): ATLoss()\n",
            "  (model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119548, 768)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (head_extractor): Linear(in_features=1565, out_features=768, bias=True)\n",
            "  (tail_extractor): Linear(in_features=1565, out_features=768, bias=True)\n",
            "  (bilinear): Linear(in_features=6144, out_features=30, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulK9nVxUK0cN",
        "outputId": "27d5c3cf-1fa8-4705-b68f-1aa752814edf"
      },
      "source": [
        "from corus import load_lenta\n",
        "\n",
        "path = 'lenta-ru-news.csv.gz'\n",
        "records = load_lenta(path)\n",
        "next(records)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LentaRecord(\n",
              "    url='https://lenta.ru/news/2018/12/14/cancer/',\n",
              "    title='Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака',\n",
              "    text='Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n",
              "    topic='Россия',\n",
              "    tags='Общество',\n",
              "    date=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEFsbCkXLrWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19eac6ba-14e9-4ec4-ccbb-9fd95a54cc20"
      },
      "source": [
        "text_lenta=next(records).text\n",
        "print(text_lenta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Австрийские правоохранительные органы не представили доказательств нарушения российскими биатлонистами антидопинговых правил. Об этом сообщил посол России в Вене Дмитрий Любинский по итогам встречи уполномоченного адвоката дипмиссии с представителями прокуратуры страны, передает ТАСС. «Действует презумпция невиновности. Каких-либо ограничений свободы передвижения для команды нет», — добавили в посольстве. Международный союз биатлонистов (IBU) также не будет применять санкции к российским биатлонистам. Все они продолжат выступление на Кубке мира. Полиция нагрянула в отель сборной России в Хохфильцене вечером 12 декабря. Как написал биатлонист Александр Логинов, их считают виновными в махинациях с переливанием крови. Биатлонисту Антону Шипулину, также попавшему в список, полиция нанесла отдельный визит: сейчас он тренируется отдельно в австрийском Обертиллахе. Обвинения спортсмен назвал бредом, а также указал на «охоту на ведьм» в мировом биатлоне. В Австрии прием допинга — уголовное преступление. Максимальное наказание за его употребление — три года тюрьмы.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Counter\n",
        "list_ner=ner_model([text_lenta])\n",
        "\n",
        "lenta_list=list_ner[0][0] #########\n",
        "\n",
        "counter=0\n",
        "\n",
        "list_of_ent=[]\n",
        "list_of_pos=[]\n",
        "\n",
        "for i in list_ner[1][0]:\n",
        "  if i!='O':\n",
        "    list_of_ent.append(i)\n",
        "    list_of_pos.append(counter)\n",
        "  counter=counter+1\n",
        "print(list_of_ent)\n",
        "print(list_of_pos)\n",
        "\n",
        "counter=1\n",
        "\n",
        "pos=[]\n",
        "tag=[]\n",
        "for j in list_of_ent:\n",
        "\n",
        "  temp_list_pos=[]     #Подсписок для сохранения позиции найденых именованных сущностей\n",
        "  temp_list_ent=[]   # Подсписок для сохранения тегов найденых именованных сущностей\n",
        "  if (counter==len(list_of_ent[:-1])):\n",
        "    break\n",
        "  \n",
        "  if (list_of_ent[counter-1][0] == \"I\") and (list_of_ent[counter][0] == \"B\"):\n",
        "    if (list_of_ent[counter+1][0] == \"I\")and(counter<len(list_of_ent[:-1])):\n",
        "      print(list_of_ent[counter-2],list_of_ent[counter-1],list_of_ent[counter],list_of_ent[counter+1])\n",
        "      print(list_of_pos[counter-2],list_of_pos[counter-1],list_of_pos[counter],list_of_pos[counter+1])\n",
        "\n",
        "      temp_list_pos.append(list_of_pos[counter-2]) \n",
        "      temp_list_pos.append(list_of_pos[counter-1])\n",
        "      temp_list_pos.append(list_of_pos[counter])\n",
        "      temp_list_pos.append(list_of_pos[counter+1])\n",
        "      ###########################################\n",
        "      temp_list_ent.append(list_of_ent[counter-2]) \n",
        "      temp_list_ent.append(list_of_ent[counter-1])\n",
        "      temp_list_ent.append(list_of_ent[counter])\n",
        "      temp_list_ent.append(list_of_ent[counter+1])\n",
        "    else:\n",
        "        print(list_of_ent[counter-2],list_of_ent[counter-1],list_of_ent[counter])\n",
        "        print(list_of_pos[counter-2],list_of_pos[counter-1],list_of_pos[counter])\n",
        "\n",
        "        temp_list_pos.append(list_of_pos[counter-2]) \n",
        "        temp_list_pos.append(list_of_pos[counter-1])\n",
        "        temp_list_pos.append(list_of_pos[counter])\n",
        "        #########################################\n",
        "        temp_list_ent.append(list_of_ent[counter-2]) \n",
        "        temp_list_ent.append(list_of_ent[counter-1])\n",
        "        temp_list_ent.append(list_of_ent[counter])\n",
        "\n",
        "  else:\n",
        "      print(list_of_ent[counter-2],list_of_ent[counter-1],list_of_ent[counter],list_of_ent[counter+1])\n",
        "      print(list_of_pos[counter-2],list_of_pos[counter-1],list_of_pos[counter],list_of_pos[counter+1])\n",
        "\n",
        "      temp_list_pos.append(list_of_pos[counter-2]) \n",
        "      temp_list_pos.append(list_of_pos[counter-1])\n",
        "      temp_list_pos.append(list_of_pos[counter])\n",
        "      temp_list_pos.append(list_of_pos[counter+1])\n",
        "      ###########################################\n",
        "      temp_list_ent.append(list_of_ent[counter-2]) \n",
        "      temp_list_ent.append(list_of_ent[counter-1])\n",
        "      temp_list_ent.append(list_of_ent[counter])\n",
        "      temp_list_ent.append(list_of_ent[counter+1])\n",
        "\n",
        "  counter=(counter+1)\n",
        " \n",
        "  if len(temp_list_pos):\n",
        "    pos.append(temp_list_pos)\n",
        " \n",
        "  if len(temp_list_ent):\n",
        "    tag.append(temp_list_ent)\n",
        "\n",
        "print(pos)\n",
        "print(tag)"
      ],
      "metadata": {
        "id": "oG9rJS_x3z3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38981b8-ed9d-493b-a689-1eef7523c275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-NORP', 'B-NORP', 'B-GPE', 'B-GPE', 'B-PERSON', 'I-PERSON', 'B-ORG', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'B-NORP', 'B-EVENT', 'I-EVENT', 'B-GPE', 'B-GPE', 'B-TIME', 'I-DATE', 'I-DATE', 'B-PERSON', 'I-PERSON', 'B-PERSON', 'I-PERSON', 'B-GPE', 'B-GPE', 'B-GPE', 'B-DATE', 'I-DATE']\n",
            "[0, 7, 16, 18, 19, 20, 33, 56, 57, 58, 60, 68, 76, 77, 84, 86, 87, 88, 89, 94, 95, 107, 108, 125, 126, 147, 160, 161]\n",
            "I-DATE B-NORP B-NORP B-GPE\n",
            "161 0 7 16\n",
            "B-NORP B-NORP B-GPE B-GPE\n",
            "0 7 16 18\n",
            "B-NORP B-GPE B-GPE B-PERSON\n",
            "7 16 18 19\n",
            "B-GPE B-GPE B-PERSON I-PERSON\n",
            "16 18 19 20\n",
            "B-GPE B-PERSON I-PERSON B-ORG\n",
            "18 19 20 33\n",
            "B-PERSON I-PERSON B-ORG\n",
            "19 20 33\n",
            "I-PERSON B-ORG B-ORG I-ORG\n",
            "20 33 56 57\n",
            "B-ORG B-ORG I-ORG I-ORG\n",
            "33 56 57 58\n",
            "B-ORG I-ORG I-ORG B-ORG\n",
            "56 57 58 60\n",
            "I-ORG I-ORG B-ORG\n",
            "57 58 60\n",
            "I-ORG B-ORG B-NORP B-EVENT\n",
            "58 60 68 76\n",
            "B-ORG B-NORP B-EVENT I-EVENT\n",
            "60 68 76 77\n",
            "B-NORP B-EVENT I-EVENT B-GPE\n",
            "68 76 77 84\n",
            "B-EVENT I-EVENT B-GPE\n",
            "76 77 84\n",
            "I-EVENT B-GPE B-GPE B-TIME\n",
            "77 84 86 87\n",
            "B-GPE B-GPE B-TIME I-DATE\n",
            "84 86 87 88\n",
            "B-GPE B-TIME I-DATE I-DATE\n",
            "86 87 88 89\n",
            "B-TIME I-DATE I-DATE B-PERSON\n",
            "87 88 89 94\n",
            "I-DATE I-DATE B-PERSON I-PERSON\n",
            "88 89 94 95\n",
            "I-DATE B-PERSON I-PERSON B-PERSON\n",
            "89 94 95 107\n",
            "B-PERSON I-PERSON B-PERSON I-PERSON\n",
            "94 95 107 108\n",
            "I-PERSON B-PERSON I-PERSON B-GPE\n",
            "95 107 108 125\n",
            "B-PERSON I-PERSON B-GPE\n",
            "107 108 125\n",
            "I-PERSON B-GPE B-GPE B-GPE\n",
            "108 125 126 147\n",
            "B-GPE B-GPE B-GPE B-DATE\n",
            "125 126 147 160\n",
            "B-GPE B-GPE B-DATE I-DATE\n",
            "126 147 160 161\n",
            "[[161, 0, 7, 16], [0, 7, 16, 18], [7, 16, 18, 19], [16, 18, 19, 20], [18, 19, 20, 33], [19, 20, 33], [20, 33, 56, 57], [33, 56, 57, 58], [56, 57, 58, 60], [57, 58, 60], [58, 60, 68, 76], [60, 68, 76, 77], [68, 76, 77, 84], [76, 77, 84], [77, 84, 86, 87], [84, 86, 87, 88], [86, 87, 88, 89], [87, 88, 89, 94], [88, 89, 94, 95], [89, 94, 95, 107], [94, 95, 107, 108], [95, 107, 108, 125], [107, 108, 125], [108, 125, 126, 147], [125, 126, 147, 160], [126, 147, 160, 161]]\n",
            "[['I-DATE', 'B-NORP', 'B-NORP', 'B-GPE'], ['B-NORP', 'B-NORP', 'B-GPE', 'B-GPE'], ['B-NORP', 'B-GPE', 'B-GPE', 'B-PERSON'], ['B-GPE', 'B-GPE', 'B-PERSON', 'I-PERSON'], ['B-GPE', 'B-PERSON', 'I-PERSON', 'B-ORG'], ['B-PERSON', 'I-PERSON', 'B-ORG'], ['I-PERSON', 'B-ORG', 'B-ORG', 'I-ORG'], ['B-ORG', 'B-ORG', 'I-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'I-ORG', 'B-ORG'], ['I-ORG', 'I-ORG', 'B-ORG'], ['I-ORG', 'B-ORG', 'B-NORP', 'B-EVENT'], ['B-ORG', 'B-NORP', 'B-EVENT', 'I-EVENT'], ['B-NORP', 'B-EVENT', 'I-EVENT', 'B-GPE'], ['B-EVENT', 'I-EVENT', 'B-GPE'], ['I-EVENT', 'B-GPE', 'B-GPE', 'B-TIME'], ['B-GPE', 'B-GPE', 'B-TIME', 'I-DATE'], ['B-GPE', 'B-TIME', 'I-DATE', 'I-DATE'], ['B-TIME', 'I-DATE', 'I-DATE', 'B-PERSON'], ['I-DATE', 'I-DATE', 'B-PERSON', 'I-PERSON'], ['I-DATE', 'B-PERSON', 'I-PERSON', 'B-PERSON'], ['B-PERSON', 'I-PERSON', 'B-PERSON', 'I-PERSON'], ['I-PERSON', 'B-PERSON', 'I-PERSON', 'B-GPE'], ['B-PERSON', 'I-PERSON', 'B-GPE'], ['I-PERSON', 'B-GPE', 'B-GPE', 'B-GPE'], ['B-GPE', 'B-GPE', 'B-GPE', 'B-DATE'], ['B-GPE', 'B-GPE', 'B-DATE', 'I-DATE']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re_pos_list=[]\n",
        "for pos_ in pos:\n",
        "  if len(pos_) == 4:\n",
        "    re_pos_0=(pos_[0],pos_[1])\n",
        "    re_pos_1=(pos_[2],pos_[3])\n",
        "    re_pos_temp=[[],[]]\n",
        "    re_pos_temp[0]=[re_pos_0]\n",
        "    re_pos_temp[1]=[re_pos_1]\n",
        "    re_pos_temp=[re_pos_temp]\n",
        "    print(re_pos_temp)\n",
        "    re_pos_list.append(re_pos_temp)\n",
        "  else:\n",
        "    re_pos_0=(pos_[0],pos_[1])\n",
        "    re_pos_1=(pos_[2]-1,pos_[2]+1)\n",
        "    re_pos_temp=[[],[]]\n",
        "    re_pos_temp[0]=[re_pos_0]\n",
        "    re_pos_temp[1]=[re_pos_1]\n",
        "    re_pos_temp=[re_pos_temp]\n",
        "    print(re_pos_temp)\n",
        "    re_pos_list.append(re_pos_temp)\n",
        "    \n",
        "print(re_pos_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xingnFm9PXGD",
        "outputId": "1a9c6c70-dd51-4363-a19a-996c8b2de0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[(161, 0)], [(7, 16)]]]\n",
            "[[[(0, 7)], [(16, 18)]]]\n",
            "[[[(7, 16)], [(18, 19)]]]\n",
            "[[[(16, 18)], [(19, 20)]]]\n",
            "[[[(18, 19)], [(20, 33)]]]\n",
            "[[[(19, 20)], [(32, 34)]]]\n",
            "[[[(20, 33)], [(56, 57)]]]\n",
            "[[[(33, 56)], [(57, 58)]]]\n",
            "[[[(56, 57)], [(58, 60)]]]\n",
            "[[[(57, 58)], [(59, 61)]]]\n",
            "[[[(58, 60)], [(68, 76)]]]\n",
            "[[[(60, 68)], [(76, 77)]]]\n",
            "[[[(68, 76)], [(77, 84)]]]\n",
            "[[[(76, 77)], [(83, 85)]]]\n",
            "[[[(77, 84)], [(86, 87)]]]\n",
            "[[[(84, 86)], [(87, 88)]]]\n",
            "[[[(86, 87)], [(88, 89)]]]\n",
            "[[[(87, 88)], [(89, 94)]]]\n",
            "[[[(88, 89)], [(94, 95)]]]\n",
            "[[[(89, 94)], [(95, 107)]]]\n",
            "[[[(94, 95)], [(107, 108)]]]\n",
            "[[[(95, 107)], [(108, 125)]]]\n",
            "[[[(107, 108)], [(124, 126)]]]\n",
            "[[[(108, 125)], [(126, 147)]]]\n",
            "[[[(125, 126)], [(147, 160)]]]\n",
            "[[[(126, 147)], [(160, 161)]]]\n",
            "[[[[(161, 0)], [(7, 16)]]], [[[(0, 7)], [(16, 18)]]], [[[(7, 16)], [(18, 19)]]], [[[(16, 18)], [(19, 20)]]], [[[(18, 19)], [(20, 33)]]], [[[(19, 20)], [(32, 34)]]], [[[(20, 33)], [(56, 57)]]], [[[(33, 56)], [(57, 58)]]], [[[(56, 57)], [(58, 60)]]], [[[(57, 58)], [(59, 61)]]], [[[(58, 60)], [(68, 76)]]], [[[(60, 68)], [(76, 77)]]], [[[(68, 76)], [(77, 84)]]], [[[(76, 77)], [(83, 85)]]], [[[(77, 84)], [(86, 87)]]], [[[(84, 86)], [(87, 88)]]], [[[(86, 87)], [(88, 89)]]], [[[(87, 88)], [(89, 94)]]], [[[(88, 89)], [(94, 95)]]], [[[(89, 94)], [(95, 107)]]], [[[(94, 95)], [(107, 108)]]], [[[(95, 107)], [(108, 125)]]], [[[(107, 108)], [(124, 126)]]], [[[(108, 125)], [(126, 147)]]], [[[(125, 126)], [(147, 160)]]], [[[(126, 147)], [(160, 161)]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_fix(tag):\n",
        "  if tag == 'ORG':\n",
        "    tag='ORGANIZATION'\n",
        "    return tag\n",
        "  else:\n",
        "    return tag"
      ],
      "metadata": {
        "id": "tEcz1oKKZKKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_tag_list=[]\n",
        "for tag_ in tag:\n",
        "  tag_1=tag_fix(tag_[0][2:])\n",
        "  tag_2=tag_fix(tag_[2][2:])\n",
        "  tag_temp=[[tag_1,tag_2]]\n",
        "  print(tag_temp)\n",
        "  re_tag_list.append(tag_temp)\n",
        "\n",
        "print(re_tag_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgheZLGSV7Lc",
        "outputId": "57e35e3b-17a2-4555-89ab-468c9bf62978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['DATE', 'NORP']]\n",
            "[['NORP', 'GPE']]\n",
            "[['NORP', 'GPE']]\n",
            "[['GPE', 'PERSON']]\n",
            "[['GPE', 'PERSON']]\n",
            "[['PERSON', 'ORGANIZATION']]\n",
            "[['PERSON', 'ORGANIZATION']]\n",
            "[['ORGANIZATION', 'ORGANIZATION']]\n",
            "[['ORGANIZATION', 'ORGANIZATION']]\n",
            "[['ORGANIZATION', 'ORGANIZATION']]\n",
            "[['ORGANIZATION', 'NORP']]\n",
            "[['ORGANIZATION', 'EVENT']]\n",
            "[['NORP', 'EVENT']]\n",
            "[['EVENT', 'GPE']]\n",
            "[['EVENT', 'GPE']]\n",
            "[['GPE', 'TIME']]\n",
            "[['GPE', 'DATE']]\n",
            "[['TIME', 'DATE']]\n",
            "[['DATE', 'PERSON']]\n",
            "[['DATE', 'PERSON']]\n",
            "[['PERSON', 'PERSON']]\n",
            "[['PERSON', 'PERSON']]\n",
            "[['PERSON', 'GPE']]\n",
            "[['PERSON', 'GPE']]\n",
            "[['GPE', 'GPE']]\n",
            "[['GPE', 'DATE']]\n",
            "[[['DATE', 'NORP']], [['NORP', 'GPE']], [['NORP', 'GPE']], [['GPE', 'PERSON']], [['GPE', 'PERSON']], [['PERSON', 'ORGANIZATION']], [['PERSON', 'ORGANIZATION']], [['ORGANIZATION', 'ORGANIZATION']], [['ORGANIZATION', 'ORGANIZATION']], [['ORGANIZATION', 'ORGANIZATION']], [['ORGANIZATION', 'NORP']], [['ORGANIZATION', 'EVENT']], [['NORP', 'EVENT']], [['EVENT', 'GPE']], [['EVENT', 'GPE']], [['GPE', 'TIME']], [['GPE', 'DATE']], [['TIME', 'DATE']], [['DATE', 'PERSON']], [['DATE', 'PERSON']], [['PERSON', 'PERSON']], [['PERSON', 'PERSON']], [['PERSON', 'GPE']], [['PERSON', 'GPE']], [['GPE', 'GPE']], [['GPE', 'DATE']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "for tag in re_tag_list:\n",
        "  sentence_tokens = [lenta_list]\n",
        "  entity_pos = re_pos_list[counter]\n",
        "  entity_tags = tag\n",
        "  pred = model(sentence_tokens, entity_pos, entity_tags)\n",
        "  #print(lenta_list[entity_pos[0][0]])\n",
        "  if pred[1]!=['no relation']:\n",
        "    print(lenta_list[entity_pos[0][0][0][0]],lenta_list[entity_pos[0][0][0][1]])\n",
        "    print(lenta_list[entity_pos[0][1][0][0]],lenta_list[entity_pos[0][1][0][1]-1])\n",
        "    #print(lenta_list[entity_pos[0][0][0][1]])\n",
        "    #print(lenta_list[entity_pos[0][1][0][0]])\n",
        "    print(pred[1])\n",
        "  counter=counter+1"
      ],
      "metadata": {
        "id": "L3efWonoYajH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7b55bc-1551-4760-ac39-996d5dcfb421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "2022-07-06 22:33:25.946 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:28.119 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:30.53 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:31.982 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:33.951 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:35.937 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:37.929 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:39.875 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:41.813 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:43.761 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "союз биатлонистов\n",
            "( IBU\n",
            "['-']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-06 22:33:45.684 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:47.632 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:49.547 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:51.496 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:53.423 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мира России\n",
            "Хохфильцене Хохфильцене\n",
            "['местонахождение']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-06 22:33:55.366 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:57.295 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:33:59.235 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:01.195 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:03.163 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:05.117 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:07.72 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:09.22 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:10.931 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:12.858 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2022-07-06 22:34:14.755 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_ner[0])\n",
        "print(list_ner[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ZuVOUA9iAl",
        "outputId": "251a1294-7f16-4edd-cce3-38775fa557b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Австрийские', 'правоохранительные', 'органы', 'не', 'представили', 'доказательств', 'нарушения', 'российскими', 'биатлонистами', 'антидопинговых', 'правил', '.', 'Об', 'этом', 'сообщил', 'посол', 'России', 'в', 'Вене', 'Дмитрий', 'Любинский', 'по', 'итогам', 'встречи', 'уполномоченного', 'адвоката', 'дипмиссии', 'с', 'представителями', 'прокуратуры', 'страны', ',', 'передает', 'ТАСС', '.', '«', 'Действует', 'презумпция', 'невиновности', '.', 'Каких', '-', 'либо', 'ограничений', 'свободы', 'передвижения', 'для', 'команды', 'нет', '»', ',', '—', 'добавили', 'в', 'посольстве', '.', 'Международный', 'союз', 'биатлонистов', '(', 'IBU', ')', 'также', 'не', 'будет', 'применять', 'санкции', 'к', 'российским', 'биатлонистам', '.', 'Все', 'они', 'продолжат', 'выступление', 'на', 'Кубке', 'мира', '.', 'Полиция', 'нагрянула', 'в', 'отель', 'сборной', 'России', 'в', 'Хохфильцене', 'вечером', '12', 'декабря', '.', 'Как', 'написал', 'биатлонист', 'Александр', 'Логинов', ',', 'их', 'считают', 'виновными', 'в', 'махинациях', 'с', 'переливанием', 'крови', '.', 'Биатлонисту', 'Антону', 'Шипулину', ',', 'также', 'попавшему', 'в', 'список', ',', 'полиция', 'нанесла', 'отдельный', 'визит', ':', 'сейчас', 'он', 'тренируется', 'отдельно', 'в', 'австрийском', 'Обертиллахе', '.', 'Обвинения', 'спортсмен', 'назвал', 'бредом', ',', 'а', 'также', 'указал', 'на', '«', 'охоту', 'на', 'ведьм', '»', 'в', 'мировом', 'биатлоне', '.', 'В', 'Австрии', 'прием', 'допинга', '—', 'уголовное', 'преступление', '.', 'Максимальное', 'наказание', 'за', 'его', 'употребление', '—', 'три', 'года', 'тюрьмы', '.']]\n",
            "[['B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'I-EVENT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'B-TIME', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = [['Россиянка', 'Мария', 'Бутина', ',', 'судимая', 'в', 'США', 'по', 'обвинению', 'в', 'участии', 'в', 'заговоре', 'с', 'целью', 'ведения', 'деятельности', 'в', 'пользу', 'иностранного', 'государства', ',', 'может', 'стать', 'фигурантом', 'еще', 'одного', 'дела', '.', 'Об', 'этом', 'сообщает', 'Daily', 'Beast', '.', 'Издание', 'обратило', 'внимание', 'на', 'запрос', 'федеральной', 'прокуратуры', 'в', 'Вашингтоне', ',', 'который', 'опубликовал', 'в', 'Twitter', 'журналист', 'Спенсер', 'Хсу', '.', 'Данная', 'бумага', 'находилась', 'в', 'закрытых', 'судебных', 'документах', '.', 'Прокуратура', 'просит', 'разрешение', 'транспортировать', 'Бутину', 'из', 'тюрьмы', 'для', 'дачи', 'показаний', 'по', 'вероятному', 'уголовному', 'расследованию', ',', 'детали', 'которого', 'не', 'уточняются', '.', 'Перевозку', 'россиянки', 'планируется', 'осуществить', 'тайно', ',', 'в', 'том', 'числе', 'и', 'в', 'целях', 'безопасности', 'самой', 'ответчицы', '.', '13', 'декабря', 'Мария', 'Бутина', 'в', 'суде', 'призналась', 'в', 'работе', 'иностранным', 'агентом', 'под', 'руководством', 'российского', 'государственного', 'чиновника', 'без', 'согласования', 'с', 'Генпрокуратурой', 'США', '.', 'Она', 'пошла', 'на', 'сделку', 'со', 'следствием', 'и', 'признала', 'вину', 'по', 'некоторым', 'пунктам', 'обвинения', '.', 'Следующее', 'слушание', 'по', 'делу', 'назначено', 'на', '12', 'февраля', '.', 'Бутина', 'была', 'задержана', 'в', 'США', '15', 'июля', '.', 'Американская', 'сторона', 'заявляет', ',', 'что', 'она', 'пыталась', 'повлиять', 'на', 'главных', 'спонсоров', 'Республиканской', 'партии', 'для', 'продвижения', 'российских', 'интересов', '.', 'Кремль', 'считает', 'все', 'обвинения', 'со', 'стороны', 'США', 'в', 'адрес', 'россиянки', 'необоснованными', ',', 'а', 'в', 'МИД', 'заявили', ',', 'что', 'ее', 'подвергали', 'пыткам', 'в', 'тюрьме', '.']]\n",
        "entity_pos = [[[(0,1)], [(2,3)]]]\n",
        "entity_tags = [['NORP', 'PERSON']]\n",
        "pred = model(sentence_tokens, entity_pos, entity_tags)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "bJNwz7kGXUGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5d3f7b-e341-4359-96df-eafa855ce0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "2022-06-30 22:36:57.336 INFO in 'deeppavlov.models.preprocessors.re_preprocessor'['re_preprocessor'] at line 226: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['-'], ['no relation']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu --no-cache\n",
        "#!python -m deeppavlov install entity_linking_rus\n",
        "from deeppavlov import configs, build_model\n",
        "el_model = build_model(configs.kbqa.entity_linking_rus, download=True)"
      ],
      "metadata": {
        "id": "QUXKtYaVXUKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el_model(['Москва — столица России, город федерального значения, административный центр Центрального федерального округа и центр Московской области.'])\n",
        "el_model([text_lenta])\n"
      ],
      "metadata": {
        "id": "-S1Kx3gJXXMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n",
        "import stanza\n",
        "stanza.download('ru')\n",
        "def stanza_nlp_ru(text):\n",
        "  nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner')\n",
        "  doc = nlp(text)\n",
        "  print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')\n",
        "stanza_nlp_ru(text_lenta)"
      ],
      "metadata": {
        "id": "LL4cG0yKhYw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvwnSkXShZDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question Answering Model**"
      ],
      "metadata": {
        "id": "PXzko2xiCy5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeppavlov\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "# !python -m deeppavlov install squad_bert\n",
        "# !python -m deeppavlov install squad_torch_bert\n",
        "# !python -m deeppavlov download deeppavlov/configs/squad/squad_ru.json\n",
        "\n",
        "# from deeppavlov import build_model, configs\n",
        "# %pip install -U numpy==1.18.5\n",
        "\n",
        "# model = build_model(configs.squad.squad_ru, download=True)\n",
        "\n",
        "# restart runtime\n",
        "\n"
      ],
      "metadata": {
        "id": "gII5eYZuZmPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import configs, build_model\n",
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult_torch, download=True)\n"
      ],
      "metadata": {
        "id": "hEQGNx_lOaC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus\n",
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
        "\n",
        "from corus import load_lenta\n",
        "\n",
        "path = 'lenta-ru-news.csv.gz'\n",
        "records = load_lenta(path)\n",
        "next(records)\n",
        "\n",
        "text_lenta=next(records).text\n",
        "print(text_lenta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPf_I4bPZ0f2",
        "outputId": "ddbecbc5-070a-40da-e687-4db72f40cf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting corus\n",
            "  Downloading corus-0.9.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: corus\n",
            "Successfully installed corus-0.9.0\n",
            "--2022-06-29 21:16:22--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T211622Z&X-Amz-Expires=300&X-Amz-Signature=2f21b2757d2666a8119abff7d2323dc4bb03f51ea294a7ae4e220a332549eb1c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-06-29 21:16:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T211622Z&X-Amz-Expires=300&X-Amz-Signature=2f21b2757d2666a8119abff7d2323dc4bb03f51ea294a7ae4e220a332549eb1c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  14.0MB/s    in 19s     \n",
            "\n",
            "2022-06-29 21:16:41 (26.8 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
            "\n",
            "Австрийские правоохранительные органы не представили доказательств нарушения российскими биатлонистами антидопинговых правил. Об этом сообщил посол России в Вене Дмитрий Любинский по итогам встречи уполномоченного адвоката дипмиссии с представителями прокуратуры страны, передает ТАСС. «Действует презумпция невиновности. Каких-либо ограничений свободы передвижения для команды нет», — добавили в посольстве. Международный союз биатлонистов (IBU) также не будет применять санкции к российским биатлонистам. Все они продолжат выступление на Кубке мира. Полиция нагрянула в отель сборной России в Хохфильцене вечером 12 декабря. Как написал биатлонист Александр Логинов, их считают виновными в махинациях с переливанием крови. Биатлонисту Антону Шипулину, также попавшему в список, полиция нанесла отдельный визит: сейчас он тренируется отдельно в австрийском Обертиллахе. Обвинения спортсмен назвал бредом, а также указал на «охоту на ведьм» в мировом биатлоне. В Австрии прием допинга — уголовное преступление. Максимальное наказание за его употребление — три года тюрьмы.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "list_of_lenta=[]\n",
        "path = 'lenta-ru-news.csv.gz'\n",
        "records = load_lenta(path)\n",
        "for i in range(0,10):\n",
        "  text_tmp=next(records).text\n",
        "  list_of_lenta.append(text_tmp)\n",
        "  print(list_of_lenta[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W7eOwsMSQ1u",
        "outputId": "f8bdfab6-b574-4487-acb1-5733bc86f156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.\n",
            "Австрийские правоохранительные органы не представили доказательств нарушения российскими биатлонистами антидопинговых правил. Об этом сообщил посол России в Вене Дмитрий Любинский по итогам встречи уполномоченного адвоката дипмиссии с представителями прокуратуры страны, передает ТАСС. «Действует презумпция невиновности. Каких-либо ограничений свободы передвижения для команды нет», — добавили в посольстве. Международный союз биатлонистов (IBU) также не будет применять санкции к российским биатлонистам. Все они продолжат выступление на Кубке мира. Полиция нагрянула в отель сборной России в Хохфильцене вечером 12 декабря. Как написал биатлонист Александр Логинов, их считают виновными в махинациях с переливанием крови. Биатлонисту Антону Шипулину, также попавшему в список, полиция нанесла отдельный визит: сейчас он тренируется отдельно в австрийском Обертиллахе. Обвинения спортсмен назвал бредом, а также указал на «охоту на ведьм» в мировом биатлоне. В Австрии прием допинга — уголовное преступление. Максимальное наказание за его употребление — три года тюрьмы.\n",
            "Сотрудники социальной сети Instagram проанализировали поставленные пользователями смайлики, геолокации и хештеги и опубликовали итоги 2018 года. Об этом сообщается на официальном сайте Instagram. Таким образом, самой счастливой геолокацией Instagram признал Диснейленд в Токио, так как больше всего счастливых смайликов в 2018 году пользователи ставили именно под фотографиями из японского Диснейленда. Также эксперты назвали самый популярный фильтр для лица: им стал фильтр с сердечками на глазах. А, например, самыми часто используемыми хештегами в 2018 году были #metoo, #timesup и #marchforourlives. В ноябре сотрудники британской ассоциации потребителей Which? составили рейтинг самых безопасных стран для путешествий. Специалисты проанализировали 20 самых популярных туристических направлений по четырем критериям: уровень преступности, угроза здоровью, вероятность теракта и стихийных бедствий. Самой безопасной страной по всем параметрам стала Исландия.\n",
            "С начала расследования российского вмешательства в выборы власти США потратили более 25 миллионов долларов. Об этом сообщает Associated Press со ссылкой на отчет Министерства юстиции США. В документе содержатся данные о расходах на следствие с апреля по сентябрь 2018 года. За эти полгода было потрачено 4,6 миллиона долларов, из которых почти 3 миллиона долларов ушли на зарплату сотрудников, 580 тысяч — на поездки и сопутствующие расходы. Ранее Минюст США уже публиковал отчеты о затратах на дело о российском вмешательстве за предыдущие месяцы. 11 декабря расследование спецпрокурора Робера Мюллера показало, что по меньшей мере 14 человек из окружения президента США Дональда Трампа контактировали с россиянами во время его избирательной кампании и последующего переходного периода перед вступлением в должность главы государства. Мюллер с 2017 года ведет дело о якобы российском вмешательстве в американские выборы в 2016-м. Перед ним поставлена задача выяснить, был ли сговор между штабом Трампа и Россией. Кремль и Белый дом отвергают все обвинения. Россию неоднократно обвиняли во вмешательстве в выборы президента США с помощью хакеров. В июне спецслужбы выдвинули заочное обвинение 12 российским разведчикам. По данным спецслужб США, российская разведка использовала две хакерские группировки для взлома серверов Демократической партии.\n",
            "Хакерская группировка Anonymous опубликовала новые документы о деятельности британского аналитического центра Integrity Initiative. Из материалов следует, что центр получает финансирование от некого Института государственного управления под руководством Кристофера Доннелли. Хакеры выложили в открытый доступ его паспорт, резюме, а также сведения о его связях с Министерством обороны Великобритании. Согласно документам, в 2014 году Доннелли выдвинул ряд предложений британским властям в связи с ситуацией в Крыму. В частности, он планировал заминировать Севастопольскую бухту, окружить полуостров войсками, а также уничтожить оставшиеся в Крыму самолеты «в знак серьезности намерений». После публикации заметки часть документов, на которые члены группировки ссылаются в своем расследовании, была удалена. Также хакеры утверждают, что Доннелли был инициатором расследования «российского вмешательства» в референдум о независимости в Каталонии. Он пригласил членов испанского отделения Integrity Initiative в качестве свидетелей. По данным группировки, Доннелли получал деньги на это от Министерства иностранных дел Великобритании. «Британская разведка платила собственным агентам за фальшивые доказательства вмешательства России в каталонский референдум, а затем приказала им солгать в парламенте с целью убедить их предпринять антироссийские шаги», — пишут хакеры. Члены Anonymous опубликовали только часть документов, связанных с деятельностью Кристофера Доннелли. Если расследование Великобритании в отношении Integrity Initiative не даст результатов, они пригрозили выложить новые доказательства того, что Доннелли тесно взаимодействует с британскими спецслужбами и использует свое положение для влияния на политику страны. 23 ноября Anonymous впервые опубликовали документы Integrity Initiative, которые содержат инструкции по борьбе с российской пропагандой и примеры дезинформации со стороны Москвы. Хакеры утверждают, что этот проект финансируется правительством Великобритании и работает сразу в нескольких странах, в том числе в Германии, Франции, Испании.\n",
            "Архиепископ канонической Украинской православной церкви Московского патриархата (УПЦ МП) Лонгин отказался участвовать в «объединительном соборе» по приглашению Вселенского патриарха Варфоломея. Он назвал это мероприятие «собором нечестивых» и «сатанинским сборищем». Об этом говорится в его письме, выдержки из которого публикует «Страна». Священнослужитель подчеркнул, что архиереи УПЦ МП против этого собрания. «Если Вы называете себя Матерью всех Церквей, то почему Вы отдали на поругание наши Православные святыни, на растерзание истинную Православную Церковь наших братьев сослужителей, допустили мучение и пытание священников?» — написал Лонгин. В своем послании он также осудил снятие анафемы с предстоятеля неканонической УПЦ Киевского патриархата Филарета. «То, что произошло на синоде в Стамбуле, шокировало весь Православный мир», — отметил архиепископ. «Объединительный собор», инициированный президентом Украины Петром Порошенко и патриархом Варфоломеем, пройдет 15 декабря в Софийском соборе Киева, передает РИА Новости. На нем изберут предстоятеля «единой церкви» и примут ее устав. Церковный раскол на Украине обострился несколько месяцев назад. В начале октября на Соборе Константинопольской церкви патриарх Варфоломей подтвердил свое намерение предоставить стране автокефалию, снял анафемы с глав раскольничьих церквей и восстановил свою юрисдикцию над Киевской митрополией. В связи с этим Русская православная церковь 15 октября разорвала евхаристическое общение со Вселенским патриархатом.\n",
            "Российская молодежь лучше усвоит духовные ценности, если распространять их через интернет и социальные сети. С такой инициативой выступил глава Федерального агентства по делам молодежи Александр Бугаев в ходе религиозного форума «Россия в будущее», передает радио «Говорит Москва». Бугаев отметил, что раньше с этой функцией справлялись плакаты, которые можно было повесить в учебных заведениях, однако в настоящее время этого недостаточно. «Намного эффективнее будет, если мы об этом хорошем, добром и ценном расскажем в социальных группах в интернете. При помощи мессенджеров, неформальных объединений молодежи, которые зачастую охватывают огромное количество людей», — сказал он. По словам чиновника, современные способы распространения информации помогут молодым людям лучше уяснить моральные ценности. В мае стало известно, что в российских школах могут начать преподавать новый курс для учеников и их родителей — о семейном укладе. В рамках курса дети будут изучать основы семейной психологии, мужской и женской культуры, семейного уклада, здорового образа жизни, духовно-нравственное развитие, подготовку к будущему родительству и другие темы.\n",
            "Полицейские Алекс Коллинс и Трейси Холлоуэй, оказавшие первую помощь Сергею Скрипалю и его дочери Юлии, рассказали подробности того дня, когда обнаружили их. Констебль и сержант поделились воспоминаниями с газетой The Guardian. По словам стражей порядка, их дежурство началось за час с четвертью до того, как в полицию поступило сообщение о пожилом мужчине и молодой женщине, которым стало плохо на улице. Наряд прибыл на место за две минуты, и состояние пострадавших сразу показалось сотрудникам правоохранительных органов странным. Коллинс отметил, что женщина (Юлия) лежала на земле на боку. Прохожий, врач по специальности, оказывал ей помощь, освобождая дыхательные пути. «Мужчина [Скрипаль] сидел на скамейке неподвижный, в кататоническом ступоре, глядя куда-то в пространство. Он дышал, но ни на что не отзывался. Нашей первой мыслью было: это наркотики», — пояснил констебль. Холлоуэй добавила, что Скрипаль сохранял ту же позу, когда медики пытались погрузить его на носилки. Он, по ее словам, застыл в сидячем положении и не мог пошевелиться и изменить положение. Коллинс рассказал, что осмотрел Скрипалей в перчатках, а Холлоуэй без всякой защиты обыскала их, чтобы установить личности. Найденные вещи озадачили полицейских. «Мы заглянули в их кошельки, пытаясь найти паспорта. Был телефон с русскоязычным интерфейсом. Имена незнакомые. Это было странно. Это было неправильно. Это было не совсем нормально», — вспоминает сержант. Стражи порядка приказали прохожим отойти и вызвали медиков и наряд пожарных с костюмами химзащиты. В марте бывший офицер ГРУ Сергей Скрипаль и его дочь Юлия были найдены в бессознательном состоянии в сквере в британском Солсбери. Лондон считает, что они были отравлены нервно-паралитическим веществом класса «Новичок». Британские власти обвиняют в причастности к отравлению Россию. Москва все обвинения отвергает.\n",
            "Минобороны опубликовало на YouTube видео полета российских стратегических бомбардировщиков Ту-160, отправленных в Венесуэлу, над водами Карибского моря. Пилоты провели в небе почти 10 часов. «На некоторых этапах маршрута российские ракетоносцы работали совместно с истребителями Су-30 и F-16 Национальной Боливарианской военной авиации. Летчики двух стран отработали взаимодействие при выполнении полетных заданий», — отмечает ведомство под роликом. В южноамериканскую страну были направлены два стратегических ракетоносца Ту-160, тяжелый военный транспортный самолет Ан-124 и дальнемагистральный самолет Ил-62 российских воздушно-космических сил (ВКС). Как передает ТАСС, 14 декабря они покинули государство и полетели на домашнюю базу. Ту-160, сверхзвуковой стратегический бомбардировщик-ракетоносец с изменяемой геометрией крыла, является самым крупным, мощным и тяжелым боевым сверхзвуковым самолетом в мире.\n",
            "Директора завода «Электроприбор» Муталиба Эмиралиева обвинили в уклонении от уплаты налогов и хищении бюджетных средств в общей сложности более чем на 70 миллионов рублей. Об этом сообщают «Известия». В 2014 году Эмиралиев выиграл государственный контракт от Министерства обороны России на ремонт зенитно-ракетного комплекса «Форт» в Мурманске. Подрядчик должен был заменить вышедшие из строя блоки, ячейки, платы и другие высокоточные механизмы вооружения. Общую стоимость комплектующих оценили в 50 миллионов рублей. По версии следствия, Эмиралиев нанял выходцев с Украины, которые за бесценок сделали косметический ремонт оборудования. Он предоставил Минобороны поддельные документы с подтверждением расходов, согласно которым орудия якобы вывозили на ремонт в Пензу и вернули обратно восстановленными и пригодными к использованию. В действительности Эмиралиев не потратил на ремонт почти ничего. В ходе расследования было обнаружено, что обвиняемый использовал похожую схему при выполнении госконтракта на ремонт одного из объектов противоракетной обороны в Московской области. Помимо этого, ему вменяют уклонение от уплаты налогов на сумму более 24 миллионов рублей, что и стало поводом для начала расследования. Следователи полагают, что за Эмиралиевым стоят высокопоставленные чиновники Минобороны, причастные к организации схемы по хищению бюджетных средств при выполнении госзаказов. Зенитно-ракетный комплекс «Форт» предназначен для установки на боевых кораблях военно-морского флота. В частности, такое вооружение используется на тяжелом атомном крейсере «Петр Великий». В 2011 году были обнаружены хищения на 265 миллионов рублей, которые произошли при ремонте крейсера.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "asks=[]\n",
        "nodes=[]\n",
        "\n",
        "\n",
        "for text_lenta in list_of_lenta:\n",
        "  token_temp=text_lenta.split()\n",
        "  if len(token_temp)<250:\n",
        "    print(len(token_temp))\n",
        "    list_ner=ner_model([text_lenta])\n",
        "    print(\"len is ok\")\n",
        "    for tag in list_ner[1][0]:\n",
        "      counter=counter+1\n",
        "      if counter<len(list_ner[1][0]):\n",
        "        if (list_ner[1][0][counter] == 'B-PERSON') and (list_ner[1][0][counter+1] == 'I-PERSON'):\n",
        "          ask='Кто '+ list_ner[0][0][counter] +' '+ list_ner[0][0][counter+1] + '?'\n",
        "          asks.append(ask)\n",
        "          print(ask)\n",
        "          nodes.append(list_ner[0][0][counter] +' '+ list_ner[0][0][counter+1])\n",
        "        # elif (list_ner[1][0][counter] == 'B-PERSON'):\n",
        "        #   ask='Кто '+ list_ner[0][0][counter]+'?'\n",
        "        #   asks.append(ask)\n",
        "    counter=0\n",
        "asks = list(set(asks))\n",
        "print(asks)\n",
        "###################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjjGzXGpS80X",
        "outputId": "dd518613-a48d-4ae8-f75b-b10ceeb90ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92\n",
            "len is ok\n",
            "137\n",
            "len is ok\n",
            "Кто Дмитрий Любинский?\n",
            "Кто Александр Логинов?\n",
            "Кто Антону Шипулину?\n",
            "120\n",
            "len is ok\n",
            "190\n",
            "len is ok\n",
            "Кто Дональда Трампа?\n",
            "191\n",
            "len is ok\n",
            "Кто Петром Порошенко?\n",
            "154\n",
            "len is ok\n",
            "Кто Александр Бугаев?\n",
            "109\n",
            "len is ok\n",
            "219\n",
            "len is ok\n",
            "Кто Муталиба Эмиралиева?\n",
            "['Кто Антону Шипулину?', 'Кто Александр Бугаев?', 'Кто Петром Порошенко?', 'Кто Александр Логинов?', 'Кто Муталиба Эмиралиева?', 'Кто Дмитрий Любинский?', 'Кто Дональда Трампа?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list_ner=ner_model(['Россиянка Мария Бутина, судимая в США по обвинению в участии в заговоре с целью ведения деятельности в пользу иностранного государства, может стать фигурантом еще одного дела. Об этом сообщает Daily Beast. Издание обратило внимание на запрос федеральной прокуратуры в Вашингтоне, который опубликовал в Twitter журналист Спенсер Хсу. Данная бумага находилась в закрытых судебных документах. Прокуратура просит разрешение транспортировать Бутину из тюрьмы для дачи показаний по вероятному уголовному расследованию, детали которого не уточняются. Перевозку россиянки планируется осуществить тайно, в том числе и в целях безопасности самой ответчицы. 13 декабря Мария Бутина в суде призналась в работе иностранным агентом под руководством российского государственного чиновника без согласования с Генпрокуратурой США. Она пошла на сделку со следствием и признала вину по некоторым пунктам обвинения. Следующее слушание по делу назначено на 12 февраля. Бутина была задержана в США 15 июля. Американская сторона заявляет, что она пыталась повлиять на главных спонсоров Республиканской партии для продвижения российских интересов. Кремль считает все обвинения со стороны США в адрес россиянки необоснованными, а в МИД заявили, что ее подвергали пыткам в тюрьме.'])\n",
        "#list_ner=ner_model(['Австрийские правоохранительные органы не представили доказательств нарушения российскими биатлонистами антидопинговых правил. Об этом сообщил посол России в Вене Дмитрий Любинский по итогам встречи уполномоченного адвоката дипмиссии с представителями прокуратуры страны, передает ТАСС. «Действует презумпция невиновности. Каких-либо ограничений свободы передвижения для команды нет», — добавили в посольстве. Международный союз биатлонистов (IBU) также не будет применять санкции к российским биатлонистам. Все они продолжат выступление на Кубке мира. Полиция нагрянула в отель сборной России в Хохфильцене вечером 12 декабря. Как написал биатлонист Александр Логинов, их считают виновными в махинациях с переливанием крови. Биатлонисту Антону Шипулину, также попавшему в список, полиция нанесла отдельный визит: сейчас он тренируется отдельно в австрийском Обертиллахе. Обвинения спортсмен назвал бредом, а также указал на «охоту на ведьм» в мировом биатлоне. В Австрии прием допинга — уголовное преступление. Максимальное наказание за его употребление — три года тюрьмы.'])\n",
        "list_ner=ner_model([text_lenta])"
      ],
      "metadata": {
        "id": "HG10yG-BOw16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_eiiIFr87aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=['Россиянка Мария Бутина, судимая в США по обвинению в участии в заговоре с целью ведения деятельности в пользу иностранного государства, может стать фигурантом еще одного дела. Об этом сообщает Daily Beast. Издание обратило внимание на запрос федеральной прокуратуры в Вашингтоне, который опубликовал в Twitter журналист Спенсер Хсу. Данная бумага находилась в закрытых судебных документах. Прокуратура просит разрешение транспортировать Бутину из тюрьмы для дачи показаний по вероятному уголовному расследованию, детали которого не уточняются. Перевозку россиянки планируется осуществить тайно, в том числе и в целях безопасности самой ответчицы. 13 декабря Мария Бутина в суде призналась в работе иностранным агентом под руководством российского государственного чиновника без согласования с Генпрокуратурой США. Она пошла на сделку со следствием и признала вину по некоторым пунктам обвинения. Следующее слушание по делу назначено на 12 февраля. Бутина была задержана в США 15 июля. Американская сторона заявляет, что она пыталась повлиять на главных спонсоров Республиканской партии для продвижения российских интересов. Кремль считает все обвинения со стороны США в адрес россиянки необоснованными, а в МИД заявили, что ее подвергали пыткам в тюрьме.']\n",
        "#text=['Австрийские правоохранительные органы не представили доказательств нарушения российскими биатлонистами антидопинговых правил. Об этом сообщил посол России в Вене Дмитрий Любинский по итогам встречи уполномоченного адвоката дипмиссии с представителями прокуратуры страны, передает ТАСС. «Действует презумпция невиновности. Каких-либо ограничений свободы передвижения для команды нет», — добавили в посольстве. Международный союз биатлонистов (IBU) также не будет применять санкции к российским биатлонистам. Все они продолжат выступление на Кубке мира. Полиция нагрянула в отель сборной России в Хохфильцене вечером 12 декабря. Как написал биатлонист Александр Логинов, их считают виновными в махинациях с переливанием крови. Биатлонисту Антону Шипулину, также попавшему в список, полиция нанесла отдельный визит: сейчас он тренируется отдельно в австрийском Обертиллахе. Обвинения спортсмен назвал бредом, а также указал на «охоту на ведьм» в мировом биатлоне. В Австрии прием допинга — уголовное преступление. Максимальное наказание за его употребление — три года тюрьмы.']\n",
        "#text=text_lenta\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsCvjWQFMDVg",
        "outputId": "394d4262-07a1-4502-daa2-d6e88ebb2eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Россиянка Мария Бутина, судимая в США по обвинению в участии в заговоре с целью ведения деятельности в пользу иностранного государства, может стать фигурантом еще одного дела. Об этом сообщает Daily Beast. Издание обратило внимание на запрос федеральной прокуратуры в Вашингтоне, который опубликовал в Twitter журналист Спенсер Хсу. Данная бумага находилась в закрытых судебных документах. Прокуратура просит разрешение транспортировать Бутину из тюрьмы для дачи показаний по вероятному уголовному расследованию, детали которого не уточняются. Перевозку россиянки планируется осуществить тайно, в том числе и в целях безопасности самой ответчицы. 13 декабря Мария Бутина в суде призналась в работе иностранным агентом под руководством российского государственного чиновника без согласования с Генпрокуратурой США. Она пошла на сделку со следствием и признала вину по некоторым пунктам обвинения. Следующее слушание по делу назначено на 12 февраля. Бутина была задержана в США 15 июля. Американская сторона заявляет, что она пыталась повлиять на главных спонсоров Республиканской партии для продвижения российских интересов. Кремль считает все обвинения со стороны США в адрес россиянки необоснованными, а в МИД заявили, что ее подвергали пыткам в тюрьме.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_ner[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gltQHRvpC3M6",
        "outputId": "74f3892d-23a6-4d37-f542-79f8b4881e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Директора', 'завода', '«', 'Электроприбор', '»', 'Муталиба', 'Эмиралиева', 'обвинили', 'в', 'уклонении', 'от', 'уплаты', 'налогов', 'и', 'хищении', 'бюджетных', 'средств', 'в', 'общей', 'сложности', 'более', 'чем', 'на', '70', 'миллионов', 'рублей', '.', 'Об', 'этом', 'сообщают', '«', 'Известия', '»', '.', 'В', '2014', 'году', 'Эмиралиев', 'выиграл', 'государственный', 'контракт', 'от', 'Министерства', 'обороны', 'России', 'на', 'ремонт', 'зенитно', '-', 'ракетного', 'комплекса', '«', 'Форт', '»', 'в', 'Мурманске', '.', 'Подрядчик', 'должен', 'был', 'заменить', 'вышедшие', 'из', 'строя', 'блоки', ',', 'ячейки', ',', 'платы', 'и', 'другие', 'высокоточные', 'механизмы', 'вооружения', '.', 'Общую', 'стоимость', 'комплектующих', 'оценили', 'в', '50', 'миллионов', 'рублей', '.', 'По', 'версии', 'следствия', ',', 'Эмиралиев', 'нанял', 'выходцев', 'с', 'Украины', ',', 'которые', 'за', 'бесценок', 'сделали', 'косметический', 'ремонт', 'оборудования', '.', 'Он', 'предоставил', 'Минобороны', 'поддельные', 'документы', 'с', 'подтверждением', 'расходов', ',', 'согласно', 'которым', 'орудия', 'якобы', 'вывозили', 'на', 'ремонт', 'в', 'Пензу', 'и', 'вернули', 'обратно', 'восстановленными', 'и', 'пригодными', 'к', 'использованию', '.', 'В', 'действительности', 'Эмиралиев', 'не', 'потратил', 'на', 'ремонт', 'почти', 'ничего', '.', 'В', 'ходе', 'расследования', 'было', 'обнаружено', ',', 'что', 'обвиняемый', 'использовал', 'похожую', 'схему', 'при', 'выполнении', 'госконтракта', 'на', 'ремонт', 'одного', 'из', 'объектов', 'противоракетной', 'обороны', 'в', 'Московской', 'области', '.', 'Помимо', 'этого', ',', 'ему', 'вменяют', 'уклонение', 'от', 'уплаты', 'налогов', 'на', 'сумму', 'более', '24', 'миллионов', 'рублей', ',', 'что', 'и', 'стало', 'поводом', 'для', 'начала', 'расследования', '.', 'Следователи', 'полагают', ',', 'что', 'за', 'Эмиралиевым', 'стоят', 'высокопоставленные', 'чиновники', 'Минобороны', ',', 'причастные', 'к', 'организации', 'схемы', 'по', 'хищению', 'бюджетных', 'средств', 'при', 'выполнении', 'госзаказов', '.', 'Зенитно', '-', 'ракетный', 'комплекс', '«', 'Форт', '»', 'предназначен', 'для', 'установки', 'на', 'боевых', 'кораблях', 'военно', '-', 'морского', 'флота', '.', 'В', 'частности', ',', 'такое', 'вооружение', 'используется', 'на', 'тяжелом', 'атомном', 'крейсере', '«', 'Петр', 'Великий', '»', '.', 'В', '2011', 'году', 'были', 'обнаружены', 'хищения', 'на', '265', 'миллионов', 'рублей', ',', 'которые', 'произошли', 'при', 'ремонте', 'крейсера', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_ner[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mXERcbTC3bA",
        "outputId": "d86254f6-aa92-48f2-d57f-57772703bf70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-ORG', 'B-ORG', 'I-ORG', 'I-ORG', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'I-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-DATE', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FAC', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FAC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov install squad_bert\n",
        "!python -m deeppavlov install squad_torch_bert\n",
        "!python -m deeppavlov download deeppavlov/configs/squad/squad_ru.json"
      ],
      "metadata": {
        "id": "x0t_qCisL3Rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc63135-5cfc-42c0-9a06-cc9a88ad5c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-29 21:00:57.406 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-2rrpe2z3\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-2rrpe2z3\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23593 sha256=eb53d0c89d1c57cb60b060eb27433c5f6c21ca0ed67dc6e06cc013470a9903f0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jfia64_e/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.6 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.46.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.1.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=75addc4de8f0aaedc90004be816ed54742dc7937ae972fffd99c54cf414d7ff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n",
            "2022-06-29 21:01:54.774 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_torch_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_torch_bert.json'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.6.0\n",
            "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.0.35)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.62.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (1.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2.22.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.11.4)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.15.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.8.1\n",
            "    Uninstalling huggingface-hub-0.8.1:\n",
            "      Successfully uninstalled huggingface-hub-0.8.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.20.1\n",
            "    Uninstalling transformers-4.20.1:\n",
            "      Successfully uninstalled transformers-4.20.1\n",
            "Successfully installed huggingface-hub-0.0.8 tokenizers-0.10.3 transformers-4.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.18.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.18.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.6.3 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torchvision-0.7.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/__main__.py\", line 4, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/deep.py\", line 80, in main\n",
            "    deep_download(pipeline_config_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/download.py\", line 161, in deep_download\n",
            "    downloads = get_configs_downloads(config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/download.py\", line 74, in get_configs_downloads\n",
            "    for url, dest in get_config_downloads(config):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/download.py\", line 44, in get_config_downloads\n",
            "    config = parse_config(config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/commands/utils.py\", line 96, in parse_config\n",
            "    config = read_json(find_config(config))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/file.py\", line 38, in read_json\n",
            "    with open(fpath, encoding='utf8') as fin:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'deeppavlov/configs/squad/squad_ru.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asks=[]\n",
        "nodes=[]\n",
        "counter=0\n",
        "for tag in list_ner[1][0]:\n",
        "  counter=counter+1\n",
        "  if counter<len(list_ner[1][0]):\n",
        "    if (list_ner[1][0][counter] == 'B-PERSON') and (list_ner[1][0][counter+1] == 'I-PERSON'):\n",
        "      ask='Кто '+ list_ner[0][0][counter] +' '+ list_ner[0][0][counter+1] + '?'\n",
        "      asks.append(ask)\n",
        "      nodes.append(list_ner[0][0][counter] +' '+ list_ner[0][0][counter+1])\n",
        "    # elif (list_ner[1][0][counter] == 'B-PERSON'):\n",
        "    #   ask='Кто '+ list_ner[0][0][counter]+'?'\n",
        "    #   asks.append(ask)\n",
        "\n",
        "asks = list(set(asks))\n",
        "print(asks)\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOml71aYHsCX",
        "outputId": "ab9fae10-ba1c-4ba2-9e2d-17b79ea18bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Кто Муталиба Эмиралиева?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# asks=[]\n",
        "# nodes=[]\n",
        "counter=0\n",
        "for tag in list_ner[1][0]:\n",
        "  counter=counter+1\n",
        "  if counter<len(list_ner[1][0]):\n",
        "    if (list_ner[1][0][counter] == 'B-DATE') and (list_ner[1][0][counter+1] == 'I-DATE'):\n",
        "      ask='Что произошло '+ list_ner[0][0][counter] +' '+ list_ner[0][0][counter+1] + '?'\n",
        "      asks.append(ask)\n",
        "      nodes.append(list_ner[0][0][counter] +' '+ list_ner[0][0][counter+1])\n",
        "    # elif (list_ner[1][0][counter] == 'B-PERSON'):\n",
        "    #   ask='Кто '+ list_ner[0][0][counter]+'?'\n",
        "    #   asks.append(ask)\n",
        "\n",
        "asks = list(set(asks))\n",
        "print(asks)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E82_Y1nnRqIk",
        "outputId": "0b7ccd4b-8921-449c-a886-329c80b3d785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Что произошло 2011 году?', 'Кто Муталиба Эмиралиева?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import build_model, configs\n",
        "%pip install -U numpy==1.18.5\n",
        "#!pip install -U tensorflow-gpu\n",
        "\n",
        "model = build_model(configs.squad.squad_ru, download=True)"
      ],
      "metadata": {
        "id": "bSeVFQXDHU7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asks=['Кто Мария Бутина?', 'Что произошло 12 февраля?', 'Что произошло 15 июля?', 'Что произошло 13 декабря?', 'Кто Спенсер Хсу?']\n",
        "\n",
        "counter=0\n",
        "for ask in asks:\n",
        "  \n",
        "  answ=(model(text, [ask])[0][0])\n",
        "  print(ask)\n",
        "  print(answ)\n",
        "  #print(nodes[counter]+'--Это-->'+answ)\n",
        "  counter=counter+1\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKvLndpoL6g2",
        "outputId": "1c74abf8-fe24-4704-c0d1-82501a8ca55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кто Мария Бутина?\n",
            "Россиянка\n",
            "\n",
            "Что произошло 12 февраля?\n",
            "Следующее слушание по делу\n",
            "\n",
            "Что произошло 15 июля?\n",
            "Бутина была задержана в США\n",
            "\n",
            "Что произошло 13 декабря?\n",
            "Следующее слушание по делу\n",
            "\n",
            "Кто Спенсер Хсу?\n",
            "журналист\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meADWxHaF9b6",
        "outputId": "2fb18c49-2ff2-465d-89e5-959090135fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[''], [-1], [1561.276611328125]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#model = build_model(configs.squad.squad_ru, download=True)\n",
        "\n",
        "counter=0\n",
        "for ask in asks:\n",
        "  \n",
        "  answ=(model(text, [ask])[0][0])\n",
        "  print(ask)\n",
        "  print(answ)\n",
        "  print(nodes[counter]+'--Произошло-->'+answ)\n",
        "  counter=counter+1\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG7wp_IVYi0m",
        "outputId": "226513ed-903f-411c-f3c6-aece5a7e828f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Что произошло 13 декабря?\n",
            "\n",
            "13 декабря--Произошло-->\n",
            "\n",
            "Что произошло 12 февраля?\n",
            "\n",
            "12 февраля--Произошло-->\n",
            "\n",
            "Что произошло 15 июля?\n",
            "\n",
            "15 июля--Произошло-->\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Осталось сформировать пул \"вопросов\" в зависимости от типа сущности, таким образом сущности будут связаны отношениями. В neo4j можно будет сформировать граф где сущности будут связаны, а не разбросаны по парам"
      ],
      "metadata": {
        "id": "gMcNw-aMhNbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "umh3UiomHsYd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMrhDiOlVs9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cb07ac-f613-4bb2-efd6-bad507f50479"
      },
      "source": [
        "!pip install natasha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natasha in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.15.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.8)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.18.0)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.393442.3710985)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9Hn5OUV3jM",
        "outputId": "6994bc86-4ba9-4e2e-bafe-4b3ed8973cc5"
      },
      "source": [
        "from natasha import NewsNERTagger\n",
        "from natasha import (\n",
        "    Segmenter,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    \n",
        "    Doc\n",
        ")\n",
        "\n",
        "segmenter = Segmenter()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "\n",
        "\n",
        "text = text_lenta \n",
        "doc = Doc(text_lenta)\n",
        "\n",
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "doc.parse_syntax(syntax_parser)\n",
        "\n",
        "sent = doc.sents[0]\n",
        "sent.syntax.print()\n",
        "sent.morph.print()\n",
        "\n",
        "\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "doc.tag_ner(ner_tagger)\n",
        "doc.ner.print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┌──────────► Россиянка    nsubj\n",
            "│         ┌─ Мария        \n",
            "│         └► Бутина       flat:name\n",
            "│         ┌► ,            punct\n",
            "│ ┌─┌─┌─┌─└─ судимая      \n",
            "│ │ │ │ │ ┌► в            case\n",
            "│ │ │ │ └►└─ США          obl\n",
            "│ │ │ │   ┌► по           case\n",
            "│ │ │ └►┌─└─ обвинению    obl\n",
            "│ │ │   │ ┌► в            case\n",
            "│ │ │ ┌─└►└─ участии      nmod\n",
            "│ │ │ │   ┌► в            case\n",
            "│ │ │ └──►└─ заговоре     nmod\n",
            "│ │ │     ┌► с            case\n",
            "│ │ └──►┌─└─ целью        obl\n",
            "│ │ ┌───└►┌─ ведения      nmod\n",
            "│ │ │   ┌─└► деятельности nmod\n",
            "│ │ │   │ ┌► в            case\n",
            "│ │ │ ┌─└►└─ пользу       nmod\n",
            "│ │ │ │   ┌► иностранного amod\n",
            "│ │ │ └──►└─ государства  nmod\n",
            "│ └►│        ,            punct\n",
            "└───│ ┌───┌─ может        \n",
            "    │ │ ┌─└► стать        xcomp\n",
            "    │ │ └──► фигурантом   xcomp\n",
            "    │ │   ┌► еще          advmod\n",
            "    │ │ ┌►└─ одного       nummod\n",
            "    └►│ └─── дела         nmod\n",
            "      └────► .            punct\n",
            "           Россиянка NOUN|Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\n",
            "               Мария PROPN|Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\n",
            "              Бутина PROPN|Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\n",
            "                   , PUNCT\n",
            "             судимая VERB|Aspect=Perf|Case=Nom|Gender=Fem|Number=Sing|Tense=Past|VerbForm=Part|Voice=Pass\n",
            "                   в ADP\n",
            "                 США PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Plur\n",
            "                  по ADP\n",
            "           обвинению NOUN|Animacy=Inan|Case=Dat|Gender=Neut|Number=Sing\n",
            "                   в ADP\n",
            "             участии NOUN|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "                   в ADP\n",
            "            заговоре NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            "                   с ADP\n",
            "               целью NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
            "             ведения NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "        деятельности NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "                   в ADP\n",
            "              пользу NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "        иностранного ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "         государства NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "                   , PUNCT\n",
            "               может VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "               стать VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "          фигурантом NOUN|Animacy=Anim|Case=Ins|Gender=Masc|Number=Sing\n",
            "                 еще ADV|Degree=Pos\n",
            "              одного NUM|Case=Gen|Gender=Neut|Number=Sing\n",
            "                дела NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "                   . PUNCT\n",
            "Россиянка Мария Бутина, судимая в США по обвинению в участии в \n",
            "          PER─────────            LOC                          \n",
            "заговоре с целью ведения деятельности в пользу иностранного \n",
            "государства, может стать фигурантом еще одного дела. Об этом сообщает \n",
            "Daily Beast. Издание обратило внимание на запрос федеральной \n",
            "ORG────────                                                  \n",
            "прокуратуры в Вашингтоне, который опубликовал в Twitter журналист \n",
            "              LOC───────                        ORG────           \n",
            "Спенсер Хсу. Данная бумага находилась в закрытых судебных документах. \n",
            "PER────────                                                           \n",
            "Прокуратура просит разрешение транспортировать Бутину из тюрьмы для \n",
            "                                               PER───               \n",
            "дачи показаний по вероятному уголовному расследованию, детали которого\n",
            " не уточняются. Перевозку россиянки планируется осуществить тайно, в \n",
            "том числе и в целях безопасности самой ответчицы. 13 декабря Мария \n",
            "                                                             PER───\n",
            "Бутина в суде призналась в работе иностранным агентом под руководством\n",
            "──────                                                                \n",
            " российского государственного чиновника без согласования с \n",
            "Генпрокуратурой США. Она пошла на сделку со следствием и признала вину\n",
            "ORG──────────── LOC                                                   \n",
            " по некоторым пунктам обвинения. Следующее слушание по делу назначено \n",
            "на 12 февраля. Бутина была задержана в США 15 июля. Американская \n",
            "                                       LOC                       \n",
            "сторона заявляет, что она пыталась повлиять на главных спонсоров \n",
            "Республиканской партии для продвижения российских интересов. Кремль \n",
            "ORG───────────────────                                       LOC─── \n",
            "считает все обвинения со стороны США в адрес россиянки \n",
            "                                 LOC                   \n",
            "необоснованными, а в МИД заявили, что ее подвергали пыткам в тюрьме.\n",
            "                     ORG                                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-M6QDuOys0"
      },
      "source": [
        "for tkn in doc.syntax.tokens:\n",
        "  print(tkn.rel,tkn.text)\n",
        "  \n",
        "print(doc.syntax.tokens[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lONnIYhH7OZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b34af23-cb97-4dab-fe98-45dd0634c21f"
      },
      "source": [
        "\n",
        "counter=0\n",
        "for tkn in doc.morph.tokens:\n",
        "  if tkn.pos=='VERB':\n",
        "    print()\n",
        "    print(tkn.pos,tkn.text)\n",
        "    print(doc.syntax.tokens[counter])\n",
        "    \n",
        "    cntr=0\n",
        "    for i in doc.syntax.tokens:\n",
        "      verb_ct=0\n",
        "      if i.head_id==doc.syntax.tokens[counter].id:\n",
        "        if doc.morph.tokens[cntr].pos != 'PUNCT':\n",
        "          print(i.text, doc.morph.tokens[cntr].pos)\n",
        "       \n",
        "      cntr=cntr+1\n",
        "  counter=counter+1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "VERB судимая\n",
            "SyntaxToken(id='1_5', text='судимая', head_id='1_1', rel='acl')\n",
            "США PROPN\n",
            "обвинению NOUN\n",
            "целью NOUN\n",
            "\n",
            "VERB может\n",
            "SyntaxToken(id='1_23', text='может', head_id='1_0', rel='root')\n",
            "Россиянка NOUN\n",
            "стать VERB\n",
            "\n",
            "VERB стать\n",
            "SyntaxToken(id='1_24', text='стать', head_id='1_23', rel='xcomp')\n",
            "фигурантом NOUN\n",
            "\n",
            "VERB сообщает\n",
            "SyntaxToken(id='2_3', text='сообщает', head_id='2_0', rel='root')\n",
            "этом PRON\n",
            "Daily X\n",
            "\n",
            "VERB обратило\n",
            "SyntaxToken(id='3_2', text='обратило', head_id='3_0', rel='root')\n",
            "Издание NOUN\n",
            "внимание NOUN\n",
            "\n",
            "VERB опубликовал\n",
            "SyntaxToken(id='3_12', text='опубликовал', head_id='3_9', rel='acl:relcl')\n",
            "который PRON\n",
            "Twitter PROPN\n",
            "журналист NOUN\n",
            "\n",
            "VERB находилась\n",
            "SyntaxToken(id='4_3', text='находилась', head_id='4_0', rel='root')\n",
            "бумага NOUN\n",
            "документах NOUN\n",
            "\n",
            "VERB закрытых\n",
            "SyntaxToken(id='4_5', text='закрытых', head_id='4_7', rel='amod')\n",
            "\n",
            "VERB просит\n",
            "SyntaxToken(id='5_2', text='просит', head_id='5_0', rel='root')\n",
            "Прокуратура NOUN\n",
            "разрешение NOUN\n",
            "\n",
            "VERB транспортировать\n",
            "SyntaxToken(id='5_4', text='транспортировать', head_id='5_3', rel='nmod')\n",
            "Бутину PROPN\n",
            "тюрьмы NOUN\n",
            "дачи NOUN\n",
            "\n",
            "VERB уточняются\n",
            "SyntaxToken(id='5_19', text='уточняются', head_id='5_14', rel='acl:relcl')\n",
            "детали NOUN\n",
            "не PART\n",
            "\n",
            "VERB планируется\n",
            "SyntaxToken(id='6_3', text='планируется', head_id='6_0', rel='root')\n",
            "осуществить VERB\n",
            "\n",
            "VERB осуществить\n",
            "SyntaxToken(id='6_4', text='осуществить', head_id='6_3', rel='csubj:pass')\n",
            "Перевозку NOUN\n",
            "тайно ADV\n",
            "\n",
            "VERB призналась\n",
            "SyntaxToken(id='7_7', text='призналась', head_id='7_0', rel='root')\n",
            "13 ADJ\n",
            "Мария PROPN\n",
            "суде NOUN\n",
            "работе NOUN\n",
            "агентом NOUN\n",
            "согласования NOUN\n",
            "\n",
            "VERB пошла\n",
            "SyntaxToken(id='8_2', text='пошла', head_id='8_0', rel='root')\n",
            "Она PRON\n",
            "сделку NOUN\n",
            "признала VERB\n",
            "\n",
            "VERB признала\n",
            "SyntaxToken(id='8_8', text='признала', head_id='8_2', rel='conj')\n",
            "и CCONJ\n",
            "вину NOUN\n",
            "\n",
            "VERB назначено\n",
            "SyntaxToken(id='9_5', text='назначено', head_id='9_0', rel='root')\n",
            "слушание NOUN\n",
            "12 ADJ\n",
            "\n",
            "VERB задержана\n",
            "SyntaxToken(id='10_3', text='задержана', head_id='10_0', rel='root')\n",
            "Бутина PROPN\n",
            "была AUX\n",
            "США PROPN\n",
            "15 ADJ\n",
            "\n",
            "VERB заявляет\n",
            "SyntaxToken(id='11_3', text='заявляет', head_id='11_0', rel='root')\n",
            "сторона NOUN\n",
            "пыталась VERB\n",
            "\n",
            "VERB пыталась\n",
            "SyntaxToken(id='11_7', text='пыталась', head_id='11_3', rel='ccomp')\n",
            "что SCONJ\n",
            "она PRON\n",
            "повлиять VERB\n",
            "\n",
            "VERB повлиять\n",
            "SyntaxToken(id='11_8', text='повлиять', head_id='11_7', rel='xcomp')\n",
            "спонсоров NOUN\n",
            "продвижения NOUN\n",
            "\n",
            "VERB считает\n",
            "SyntaxToken(id='12_2', text='считает', head_id='12_0', rel='root')\n",
            "Кремль PROPN\n",
            "обвинения NOUN\n",
            "необоснованными ADJ\n",
            "заявили VERB\n",
            "\n",
            "VERB заявили\n",
            "SyntaxToken(id='12_16', text='заявили', head_id='12_2', rel='conj')\n",
            "а CCONJ\n",
            "МИД PROPN\n",
            "подвергали VERB\n",
            "\n",
            "VERB подвергали\n",
            "SyntaxToken(id='12_20', text='подвергали', head_id='12_16', rel='ccomp')\n",
            "что SCONJ\n",
            "ее PRON\n",
            "пыткам NOUN\n",
            "тюрьме NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXwi2KG3Ba1j"
      },
      "source": [
        "Правило:\n",
        "У подлежащего есть tag Per\n",
        "\n",
        "В предложении нет VERB\n",
        "\n",
        "Тогда дополнение будет в отношении 'является' к подлежащему"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B99ZtF7-3tzN"
      },
      "source": [
        "# lr2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "Yhs1VUA43y8t",
        "outputId": "f0e7a8cd-7712-4e56-dabe-f1a26f70121e"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "#generates x and y numpy arrays for \n",
        "# y = a*x + b + a * noise\n",
        "# in range -1 .. 1\n",
        "# with random noise of given amplitude (noise)\n",
        "# vizualizes it and unloads to csv\n",
        "def generate_linear(a, b, noise, filename, size = 100):\n",
        "    print('Generating random data y = a*x + b')\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = a * x + b +  noise*a*(np.random.rand(size, 1) -0.5)\n",
        "    data = np.hstack((x,y))\n",
        "    np.savetxt(filename,data,delimiter=',')\n",
        "    return(x,y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# thats an example of linear regression using polyfit\n",
        "def linear_regression_numpy(filename):\n",
        "    # now let's read it back\n",
        "    with open(filename, 'r') as f:\n",
        "        data = np.loadtxt(f,delimiter=',')\n",
        "    #split to initial arrays\n",
        "    x,y = np.hsplit(data,2)\n",
        "    #printing shapes is useful for debugging\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    #our model\n",
        "    time_start = time()\n",
        "    model = np.polyfit(np.transpose(x)[0], np.transpose(y)[0], 1)\n",
        "    time_end = time()\n",
        "    print(f\"polyfit in {time_end - time_start} seconds\")\n",
        "    # our hypothesis for give x\n",
        "    h =  model[0]*x + model[1]\n",
        "\n",
        "    #and check if it's ok\n",
        "    plt.title(\"Linear regression task\")\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.plot(x, y, \"b.\", label = 'experiment')\n",
        "    plt.plot(x, h, \"r\", label = 'model')    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return(model)\n",
        "\n",
        "def linear_regression_exact(filename):\n",
        "    print(\"Ex1: your code here - exact solution usin invert matrix\")\n",
        "    \n",
        "    return\n",
        "    \n",
        "def check(model, ground_truth):\n",
        "    if len(model) != len(ground_truth):\n",
        "        print(\"Model is inconsistent\")\n",
        "        return False\n",
        "    else:\n",
        "        r = np.dot(model-ground_truth,model-ground_truth)/(np.dot(ground_truth,ground_truth))\n",
        "        print(r)\n",
        "        if r < 0.0001:            \n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "# Ex1: make the same with polynoms\n",
        "\n",
        "#generates x and y numpy arrays for \n",
        "# y = a_n*X^n + ... + a2*x^2 + a1*x + a0 + noise\n",
        "# in range -1 .. 1\n",
        "# with random noise of given amplitude (noise)\n",
        "# vizualizes it and unloads to csv\n",
        "def generate_poly(a, n, noise, filename, size = 100):\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = np.zeros((size,1))\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    if len(a) != (n+1):\n",
        "        print(f'ERROR: Length of polynomial coefficients ({len(a)}) must be the same as polynomial degree {n}')\n",
        "        return\n",
        "    for i in range(0,n+1):\n",
        "        y = y + a[i] * np.power(x,i) + noise*(np.random.rand(size, 1) -0.5)\n",
        "    print(np.shape(x))\n",
        "    data = np.hstack((x,y))\n",
        "    np.savetxt(filename,data,delimiter=',')\n",
        "\n",
        "\n",
        "def polynomial_regression_numpy(filename):\n",
        "    print(\"Ex1: your code here\")\n",
        "    with open(filename, 'r') as f:\n",
        "        data = np.loadtxt(f,delimiter=',')\n",
        "        x,y = np.hsplit(data,2)\n",
        "    #printing shapes is useful for debugging\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    time_start = time()\n",
        "    print(\"Ex1: your code here\")\n",
        "\n",
        "    \n",
        "    time_end = time()\n",
        "    print(f\"polyfit in {time_end - time_start} seconds\")\n",
        "    \n",
        "\n",
        "# Ex.2 gradient descent for linear regression without regularization\n",
        "\n",
        "# find minimum of function J(theta) using gradient descent\n",
        "# alpha - speed of descend\n",
        "# theta - vector of arguments, we're looking for the optimal ones (shape is 1 х N)\n",
        "# J(theta) function which is being minimizing over theta (shape is 1 x 1 - scalar)\n",
        "# dJ(theta) - gradient, i.e. partial derivatives of J over theta - dJ/dtheta_i (shape is 1 x N - the same as theta)\n",
        "# x and y are both vectors\n",
        "\n",
        "def gradient_descent_step(dJ, theta, alpha):\n",
        "    print(\"your code goes here\")\n",
        "\n",
        "    return(theta)\n",
        "\n",
        "# get gradient over all xy dataset - gradient descent\n",
        "def get_dJ(x, y, theta):\n",
        "    theta_new = theta\n",
        "    print(\"your code goes here - calculate new theta\")\n",
        "    return theta_new   \n",
        "\n",
        "# get gradient over all minibatch of size M of xy dataset - minibatch gradient descent\n",
        "def get_dJ_minibatch(x, y, theta, M):\n",
        "    theta_new = theta\n",
        "    print(\"your code goes here - calculate new theta\")\n",
        "    return theta_new     \n",
        "\n",
        "# get gradient over all minibatch of single sample from xy dataset - stochastic gradient descent\n",
        "def get_dJ_sgd(x, y, theta):\n",
        "    theta_new = theta\n",
        "    print(\"your code goes here - calculate new theta\")\n",
        "    return theta_new     \n",
        "\n",
        "# try each of gradient decsent (complete, minibatch, sgd) for varius alphas\n",
        "# L - number of iterations\n",
        "# plot results as J(i)\n",
        "def minimize(theta, x, y, L):\n",
        "    #n - number of samples in learning subset, m - ...\n",
        "    n = 12345 # <-- calculate it properly!\n",
        "    theta = np.zeros(n) #you can try random initialization\n",
        "    dJ = np.zeros(n)\n",
        "    for i in range(0,L):\n",
        "        theta = get_dJ(x,y,theta) # here you should try different gradient descents\n",
        "        J = 0 # here you should calculate it properly\n",
        "    #and plot J(i)\n",
        "    print(\"your code goes here\")\n",
        "    return\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_linear(1,-3,1,'linear.csv',100)\n",
        "    model = linear_regression_numpy(\"linear.csv\")\n",
        "    print(f\"Is model correct?\\n{check(model, np.array([1,-3]))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating random data y = a*x + b\n",
            "(100, 1)\n",
            "(100, 1)\n",
            "polyfit in 0.017896175384521484 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xUdb3/8dcH3IIXTAQ9pYhgqSnCQduQW6MwDC37eTnaUfJGZUhmv+Pv1yklTUk0PdnFTDpK5cGOmiaYecoSEXfeNhIYmWIKKCZoXkAUFBD2/pw/1hoaZs/Mnstas9bMvJ+Pxzz2zLp+Zu2912d9L+u7zN0REREppFfSAYiISLopUYiISFFKFCIiUpQShYiIFKVEISIiRSlRiIhIUUoUkigzG2NmzyQdR70ys6fMbGzScRRiZkPMzM1su6RjkcopUUhNmNkKMzsqd7q7P+TuByQRUyNw92Hu3h71ds2s3czOjnq7Up+UKKQplXKFG+VVsAX0/yZ1SX+4kigzG2tmK7M+rzCzfzezJ8zsTTO73cz6Zs3/tJktNrO1ZvaomY3ImnehmS03s3VmtsTMTsyaN9HMHjGzH5jZamBqnlimmtksM7vZzN4CJprZe8zsZ2b2spmtMrPLzax3uHxvM/uemb1uZs+b2XnZ1SzhVfkVZvYI8A6wr5l90MzuM7M1ZvaMmf1r1v4/Fca9LtzXv4fTB5rZb8LvvMbMHsokneySmpn1MbNrzOyl8HWNmfXJPs5m9lUzezX8Pp8r8Du5AhgDXGdm683sunD6D83sRTN7y8wWmdmYrHVGm9nCcN4rZvb9Ats+KYz54AJ/EpJG7q6XXrG/gBXAUXmmjwVW5iy3ANgT2A14GpgczjsEeBX4MNAbOCtcvk84/zPher2AU4C3gfeF8yYCW4CvANsBO+SJZSqwGTgh3MYOwK+AG4CdgD3C2M4Jl58MLAEGAf2BuYAD24Xz24G/AcPCfb4HeBH4XPj5EOB14KBw+ZeBMeH7/sCh4fsrgeuBlvA1BrDc4wpcBswP49wdeBSYlnWct4TLtACfIkhe/Qv8vtqBs3OmnQ4MCGP/KvB3oG84rwM4I3y/M3BY+H5I5piE33sZ8IGk/x71Ku+lEoWk0bXu/pK7rwH+BxgZTp8E3ODuj7l7p7vfBGwCDgNw9zvC9brc/XZgKTA6a7svufuP3H2Lu28osO8Od7/L3buAXQhOqOe7+9vu/irwA+DUcNl/BX7o7ivd/Q3gqjzbm+nuT7n7FuAYYIW7/1cYw5+A2QQJDoIkdZCZ7eLub7j741nT3wfs4+6bPWjXyTdI22nAZe7+qru/BnwLOCNr/uZw/mZ3vwdYD5TcPuTuN7v76jD27wF9stbfDHzAzAa6+3p3n5+z+vnA14Cx7r6s1H1KOihRSBr9Pev9OwRXqAD7AF8Nq2DWmtlaYG+CUgRmdmZWtdRa4GBgYNa2Xixh39nL7ENw9f1y1jZvILhiJ9zviwXWLbS9D+fEfxrw3nD+SQSJ6QUz+4OZtYXTrya4Ep9jZs+Z2YUFYt8TeCHr8wvhtIzVYcLKyD62PQqrBJ8OqwTXEpSQMsf3C8D+wF/N7I9m9umc1b8GTHf3lUjdUZc1qScvAle4+xW5M8xsH+AnwDiCUkGnmS0GLGuxUoZKzl7mRYISy8CcE2zGywTVThl7l7C9P7j7J/Lu2P2PwPFm1gKcB/wS2Nvd1xFU9Xw1rNufZ2Z/dPf7czbxEkEyeir8PDicVoltjlXYHvF1guP7lLt3mdkbhMfX3ZcCE8K2k38BZpnZgKxNjAd+b2Z/d/fZFcYkCVGJQmqpxcz6Zr3KvVD5CTDZzD5sgZ3M7Fgz60fQhuDAawBhQ21VDabu/jIwB/ieme1iZr3M7P1m9rFwkV8C/2Zme5nZrsAFPWzyN8D+ZnaGmbWEr1FmdqCZbW9mp5nZe9x9M/AW0BV+l0+b2QfMzIA3gc7MvBy/AC42s93NbCBwCXBzhV//FWDfrM/9CNo4XgO2M7NLCKrmCGM83cx2D6vs1oaTs2N8iqDqbbqZHVdhTJIQJQqppXuADVmvqeWs7O4LgS8C1wFvEFTHTAznLQG+R9Co+gowHHgkgpjPBLYnaLR+A5hF0F4AQeKaAzwB/Ing+20hOJHni38dwZX1qQRX+n8H/oOgrh+C9oQVFvS4mkxQLQWwH0FD+frw+/3Y3R/Is4vLgYVhPH8BHg+nVeKHwMlm9oaZXQvcC/weeJagSmsj21arHQM8ZWbrw3VPzW0Hcvc/A58GfmJmn6wwLklApueEiFQpPPld7+77JB2LSJRUohCpkJntEN77sJ2Z7QVcStCdVqShqEQhUiEz2xH4A/BBgqq03wL/5u5vJRqYSMSUKEREpChVPYmISFENeR/FwIEDfciQIUmHISJSNxYtWvS6u++eb15DJoohQ4awcOHCpMMQEakbZvZCoXmqehIRkaKUKEREpCglChERKaoh2yjy2bx5MytXrmTjxo1Jh9IU+vbty6BBg2hpaUk6FBGpUtMkipUrV9KvXz+GDBlCMLaaxMXdWb16NStXrmTo0KFJhyMiVWqaqqeNGzcyYMAAJYkaMDMGDBig0ptIg2iaRAEoSdSQjrVIbXR0wJVXBj/j0jRVTyIijaajA8aNg3ffhe23h/vvh7a2ntcrV1OVKJrJJZdcwty5c2Pdx8yZM3nppUofoCYiucotHbS3B0miszP42d4eT1wqUTSgzs5OLrvsstj3M3PmTA4++GD23HPPnhcWkaIqKR2MHRssm1ln7Nh4YlOJooio6/5uvvlmRo8ezciRIznnnHN47LHHGDFiBBs3buTtt99m2LBhPPnkk7S3t/PRj36UY489lgMOOIDJkyfT1RU8VXLOnDm0tbVx6KGH8pnPfIb169cDwbAlF1xwAYceeih33HEHEydOZNasWVvnTZkyhZEjR9La2srjjz/O0Ucfzfvf/36uv/76rfFdffXVjBo1ihEjRnDppZcCsGLFCg488EC++MUvMmzYMMaPH8+GDRuYNWsWCxcu5LTTTmPkyJFs2LABEalcJaWDtrYgoUybFl+1EyhRFJTJ7t/8ZvCz2mTx9NNPc/vtt/PII4+wePFievfuzTPPPMNxxx3HxRdfzNe//nVOP/10Dj44eMzzggUL+NGPfsSSJUtYvnw5d955J6+//jqXX345c+fO5fHHH6e1tZXvf//7W/cxYMAAHn/8cU499dRu+x88eDCLFy9mzJgxW5PI/PnztyaEOXPmsHTpUhYsWMDixYtZtGgRDz74IABLly7ly1/+Mk899RS77rors2fP5uSTT6a1tZVbbrmFxYsXs8MOO1R3gESaXKZ00Lt3eaWDtjaYMiW+JAGqeiooX3av5hdx//33s2jRIkaNGgXAhg0b2GOPPbjkkksYNWoUffv25dprr926/OjRo9l33+DZ9hMmTODhhx+mb9++LFmyhCOOOAKAd999l7asoE455ZSC+z/uuOB59sOHD2f9+vX069ePfv360adPH9auXcucOXOYM2cOhxxyCADr169n6dKlDB48mKFDhzJy5EgAPvShD7FixYrKD4RIk+joCM4bY8eWdu7IlA7KWadWlCgKiLruz90566yzuPLKK7eZ/vLLL7N+/Xo2b97Mxo0b2WmnnYDu3UvNDHfnE5/4BL/4xS/y7iOzbj59+vQBoFevXlvfZz5v2bIFd2fKlCmcc84526y3YsWKbZbv3bu3qplEelBpb6S2tnQliAxVPRUQdd3fuHHjmDVrFq+++ioAa9as4YUXXuCcc85h2rRpnHbaaVxwwQVbl1+wYAHPP/88XV1d3H777XzkIx/hsMMO45FHHmHZsmUAvP322zz77LPVBRY6+uijufHGG7e2eaxatWprrIX069ePdevWRbJ/kUZSq95ItaISRRFRZveDDjqIyy+/nPHjx9PV1UVLSwvHH388LS0tfPazn6Wzs5PDDz+cefPm0atXL0aNGsV5553HsmXLOPLIIznxxBPp1asXM2fOZMKECWzatAmAyy+/nP3337/q+MaPH8/TTz+9tSpr55135uabb6Z3794F15k4cSKTJ09mhx12oKOjQ+0UIqFa9UaqlYZ8ZnZra6vnPrjo6aef5sADD0woovK0t7fz3e9+l9/85jdJh1KVejrmIlErt40iaWa2yN1b881TiUJEJAZpbW+ohBJFCo0dO5ax9V5WFZGGocZsEZEamjEDjj46+FkvVKIQEamRGTMg0wN9zpzg56RJycVTKpUoRERqZPbs4p/TSolCRKRGTjqp+Oe0UqKoQ0OGDOH111+vehkRqa1Jk+CGG2D8+OBnPVQ7gdooRERqatKk+kkQGSpR1MiKFSv44Ac/yMSJE9l///057bTTmDt3LkcccQT77bcfCxYsYM2aNZxwwgmMGDGCww47jCeeeAKA1atXM378eIYNG8bZZ59N9k2SuUOXd3Z2JvUVRaRBNWeJ4vzzYfHiaLc5ciRcc03RRZYtW8Ydd9zBjTfeyKhRo7j11lt5+OGHufvuu/n2t7/N3nvvzSGHHMJdd93FvHnzOPPMM1m8eDHf+ta3+MhHPsIll1zCb3/7W372s58B2w5d3tLSwrnnnsstt9zCmWeeGe13E5Gm1pyJIiFDhw5l+PDhAAwbNoxx48ZhZgwfPpwVK1bwwgsvMDvsBvHxj3+c1atX89Zbb/Hggw9y5513AnDsscfSv39/oPDQ5SLSONIwFEhzJooervzjkju8d/bQ31u2bKGlpaWs7RUaulxEikvDybcUlQ5XHjW1UaTImDFjuOWWW4BgYMCBAweyyy678NGPfpRbb70VgN/97ne88cYbQOGhy0WksJ6eXhn1I5CrUepw5XHH3JwlipSaOnUqn//85xkxYgQ77rgjN910EwCXXnopEyZMYNiwYRx++OEMHjwYyD90+fTp09lnn32S/BoiqVbs6ZVpuYLPKGW48lrErERRI0OGDOHJJ5/c+nnmzJl55911113d1h0wYABzMvf75zjllFPyPgJVjysVya/YybfQFXxS1VSlPB41E/PozkdZs2l32tv3a4xEYWZXA/8HeBdYDnzO3dfmWe4Y4IdAb+Cn7n5VTQMVkYZT7OSbm0QGDEi+hNHTcOXnzh7HlM55wYcu6Bgb/TOGkmqjuA842N1HAM8CU3IXMLPewHTgk8BBwAQzO6imUYpIQ2prgylTup+Acx+BvHp1so80LdT20NEBmIEZ71k0b+v0Z668M5ZElkiJwt2z61HmAyfnWWw0sMzdnwMws9uA44ElVewXM6t0dSlDIz45URpXbi+o7JNtUo80Ldj2YEa3XHDKKXDbbRwQUyxpaKP4PHB7nul7AS9mfV4JfLjQRsxsEjAJ2NrYm61v376sXr2aAQMGKFnEzN1ZvXo1ffv2TToUkR4VawwupY0gLrntJW2Hdz9vPcaHmfft+UzpVicTrdgShZnNBd6bZ9ZF7v7rcJmLgC3ALdXuz91nADMgeGZ27vxBgwaxcuVKXnvttWp3JSXo27cvgwYNSjoMaXBR3A9RrBcUJPdI00x7yTsbDPKMzLNdbw8S29j4Y4ktUbj7UcXmm9lE4NPAOM9fT7EK2Dvr86BwWkVaWloYOnRopauLSMpU0y00O8GU0gU1CW2HG+/kTtxpJ1i/no4OmNZeu1JOUr2ejgG+DnzM3bsdi9Afgf3MbChBgjgV+GyNQhSRlOupJFBIvgSTVPVSXoWqxrOup2tdykmq19N1QD/gPjNbbGbXA5jZnmZ2D4C7bwHOA+4FngZ+6e5PJRSviKRMpiTQu3d5JYFCCSZfL6iaCnsxbWOvvYIEkXDnkKR6PX2gwPSXgE9lfb4HuKdWcYlI/ai0oTl1VU35ShCjR8Njj9U+lgLS0OtJRKQilVTBJNmTaRt1kCAylChEpOkk1ZMJd+iVp8b/xBMhfJRApeIcEVeJQkQkbp2dsF2e0+2558L06VVvPu6BATXMuIhIXDZuDKqYcpPElClB6SKCJAGlD0deKZUoRESitnYthE+i3MZXvgLXXhv57uJuoFeiEJGGkfiT61atgnwjElx5JVx4YWy7jbuBXolCRBpCog8devJJGD68+/Qf/xi+9KWahBBnA73aKESkIcRdT5/Xgw8GbRC5SWLWrKANokZJIm5KFCLSECq9U7sis2cHCeJjH9t2+rx5QYI46aRuq6TpWdzlUtWTiDSEOOrpu7V5XHdd0CCd6/HH4ZBDim4n6SflVUOJQkQaRpT19Nkn92s4n7bOH3Zf6LnnoIRRqSsdwDAtlChERPJob4cZG8/gdL+5+8xXX4Xddy95W6kbX6pMShQiIrkOPpgpT+UZrHrdOth557I3l5rxpSqkRCEiklHgWRDzH3yXw8a0VLXpxMaXioAShYhIoYcFdXWBGYfVNprUUaIQkeZVwtPkRPdRiEgzyvc0OUjF0+R6ksT9GCpRiEhNxTUeU0nbrfMSRFL3YyhRiEgs8p244zrRFdpuJoYp30hHgqg2SSZ1P4YShYhErtCJO64TXaFxntoON/JuPoESRBRJMqn7MdRGISKRK3TiLnU8pnLr4XO3O+UbRtvh6WqDiGLQwsz9GNOm1XYYEJUoRCRyha58S7nxrJIr78x22w432NB9/o47eDC/uq9VlahKA0ncj6FEISKRK5YQejrRVVQ9ZfmrmDoeddrb4f6xyd/sVs93ZytRiEgsKr3yLevKu4deTG2k64Rcr3dnK1GISKqUdOVd591c640ShYikTsErbyWIRKjXk0idqucnppWtju+kbgQqUYjUoXp/YlrJCpQg0tCLqZkkUqIws6vN7K9m9oSZ/crMdi2w3Aoz+4uZLTazhbWOUyRulZYKouiTn2oFShDb9XYMT+V3TrqEF+f+kypR3AdMcfctZvYfwBTgggLLHunur9cuNJHaqKZUUO9PTCuoSBtERwdsPy6d3znpEl7c+0+kROHuc9x9S/hxPjAoiThEklRNqSCpO3RjU0IbRJq/c9IlvLj3n4Y2is8DtxeY58AcM3PgBnefUWgjZjYJmAQwePDgyIMUiVq1pYJ67ZO/jTJ7MaX1Oyddwot7/+Yx9Rgws7nAe/PMusjdfx0ucxHQCvyL5wnEzPZy91VmtgdBddVX3P3Bnvbd2trqCxeqSUPSL64ht1OvTru5Fvt9Jf27rHb/ZrbI3VvzzosrUfTEzCYC5wDj3P2dEpafCqx39+/2tKwShUhK1WmCgOTbIeJWLFEk1evpGODrwHGFkoSZ7WRm/TLvgfHAk7WLUkQi4d4Q90Ek3Q6RpKRuuLsO6AfcF3Z9vR7AzPY0s3vCZf4JeNjM/gwsAH7r7r9PJlwRKdumTUFy6JXnNFNHCSKj1CHSG1Eijdnu/oEC018CPhW+fw7451rGJdKsIq1fX7MGBgzIP6/OkkO2eh79tVpp6PUkIgmKrO59+XL4QN5rwLpOENnS2usqbhrrSaTJVV333tERVDHlJoldd019FVPSd1PXC5UoRJpcxX3wb7sNJkzIv8EHHoguwJhEVZJKultsLShRiDS5suver7gCLr64+/Rzz4Xp00veb9In2IqepJej0bvMZihRiDS5kk/YZ5wBN9/cffp3vgNf+1rZ+0z6BDtgQNAhy73yXkxRJJt6oEQh0sQyJ+xNm4KT5vTpMGlSzkKHHgp/+lP3lWfNgpNOqmi/SZ9gOzrg/POD/ffqBddcU4PHttYxJQqROhFHVU17e5AkurqC13nnwfDh4fYL3UU9fz58+MNV7TfpE2wmUXV1BV9z9erKttMsXWaVKETqQFxVNWPHBlfUXV3B585OaDu8QIJ47jkYOrRbXJWcJKM8wVYSQ5SJqhm6zCpRiKRcRwdMnfqPK/8oq2ra2oLqpvPOg3c3G3TlWWjNGujfP29c1SSvKE6wlcbQLCWBqChRiKRYdhtCV1dw9R91Vc2kc4zcZgkg2On22xdcL+l2hmpjaIaSQFR0w51IimXXpffqBUcdFWEPoUID9XV1/aMrUBFpGPsoiRia8SY9lShEUiy3Ln3q1AiSRERDfaeh+qbWMaShW28SlChEUizSE2EMz4JIQ/VNLWNIQ3VbEpQoRFKu6hNhHT8sKG2S7tabFCUKkUalBBG5NFS3JUGJQqSApMciqpgSRKzSUN1Wa0oUInnUZaOlEoTERN1jRfKoq+cjN8DzqOPQjN1Y46IShUgeddFoqRJEQXVZIkwxJQqRPFLdaBlzgqjbtpkszdqNNS5KFCIFpK7RsgYliEa5Eq+LEmEdUaKQplG3V8o1rGJqlCvxVJcI65AShTSFurxSTqANopGuxFNXIqxjShTSFOrqSjnBRmpdiUs+ShTSFOriSjklvZh0JS65lCikKaT6SjklCUKkECUKaRqpu1JWgpA6UfDObDO7x8yG1C4UkSahO6mlzhQbwuO/gDlmdpGZtUS9YzObZmZPmNliM5tjZnsWWO4sM1savs6KOg6RmlGCkDplXuQP1Mx2Br4JHAP8N1mPXnf371e1Y7Nd3P2t8P3/BQ5y98k5y+wGLARaAQcWAR9y9zeKbbu1tdUXLlxYTXgi0VEVk9QBM1vk7q355vU0KOC7wNtAH6BfzqsqmSQR2okgEeQ6GrjP3deEyeE+gqQlkm5dXSpBVEiD+aVPwcZsMzsG+D5wN3Cou78T9c7N7ArgTOBN4Mg8i+wFvJj1eWU4Ld+2JgGTAAYPHhxtoCKlevtt2Hnn/POUHHpUlzdGNoFiJYqLgM+4+4WVJgkzm2tmT+Z5HQ/g7he5+97ALcB5lewjw91nuHuru7fuvvvu1WxKpHwvvxyUHvIlCZUgSlZXw7s3kYIlCncfU+3G3f2oEhe9BbgHuDRn+ipgbNbnQUB7tXFJ+ep2nKQylf09n3gC/vmf889TcihbXdwY2YQSu4/CzPZz96Xhx+OBv+ZZ7F7g22bWP/w8HphSi/jkH5qlOqCs73nPPXDssfnnKUFULNU3RjaxJJ9wd1VYDfUEQQL4NwAzazWznwK4+xpgGvDH8HVZOE1ikq8hsVmqA0r6ntddF1Qx5SaJAw5QFVNE2tpgyhQliTRJrETh7icVmL4QODvr843AjbWKq5kVuqKOqzogquqsqLZT9Huedx5Mn959pQkT4NZbK99pgpqlOlGqpyE8ZKtCI6zGUR0QVXVWlNVieb/nmDHw8MPdF778crjoosp2lALNUp0o0VCikK2KXVFHPU5SVMN+Rz18+NbvOXAgrF7dfYHbboNTTql8BylRV8OuS+KUKGSrWjYkllKdVUrVSOTVYoXuon700YY6k6p3kZSj6BAe9UpDeNSHYomgnKqRSOraCyWI55+HIUMq3Gi6qY1CshUbwkMlCklMseqscqpGqqoWK5Qg1q6F97ynwo3Wh9QNuy6ppUQhqRR71UihBLF5M2ynfwuRbPqPkFSKrb2kUILIDOInIt0oUUhqRVo1oqG+RSqmRCGNTQlCpGpJDuEhCWmK8f6LPAui41FP/Ps3xe9AGoZKFE0mjjtyo+xmWfW2eihBpOGO5DTEIFIOJYomE/UduVGe9KraVoEEseMOHmwn/JyGO5LTEINIOVT11GQy3U579y7e7bTUqpFCI65WUrVS0Si1BaqYtuvtGN5tO6V+/zilIQaRcqhE0WTa2uCaa2D2bDjppPxXsuVc2ee736HSkkFZ904UqWLq6IDtx+XfTqbb7c9/3nM8cdEzF6TeKFE0mY4OOP/84CT60EMwfHj3E1W5d0XnnvSuvLKyqpWSTqAl9GIqZTs33RTEdtNNybQR6K5oqSdKFE2mlCRQ7l3RuSe9au6qLngCLbOba1TDg4iIEkXTKeUkXm3VSKRVKzHcB6GRU0XKo9Fjm1BdjBoa841ydXEMRGqo2OixShRSlthPsLqTWiQRGmZcIhHrjWIl3CinEoBIMpQoGkycJ9RYGoFLKEHoTmaRZClRNJC4T6iRNgKXUcWkXkoiyVKiaCBxn1Aj6c1UQRuEeimJJEuJooGk+oRaRSO17mQWSZYSRQOJ+4RaUdVWRL2YdCezSHKUKBpMnCfUkqu23KFXgfEm1c1VpO5o9NiYNOKDaXoc9bSzMyhB5EsS7koSInVKJYoYNGp3zoJVW2+/DTvvnH8lJQeRupdIojCzacDxQBfwKjDR3V/Ks1wn8Jfw49/c/bjaRVm5Ru7OuU3V1iuvwHvfm39BJQiRhpFU1dPV7j7C3UcCvwEuKbDcBncfGb7qIklAEzyYZsmSoIopX5JQFZNIw0kkUbj7W1kfdwIa6sySqaKZNq1xqp0A+MMfggQxbNi200eNUoIQaWCJtVGY2RXAmcCbwJEFFutrZguBLcBV7n5Xke1NAiYBDB48OOJoy5eW7pyRDOlx553B4/BynXFGso+KE5GaiG30WDObC+SrwL7I3X+dtdwUoK+7X5pnG3u5+yoz2xeYB4xz9+U97bueRo+Nc2ymqhvVf/jD4HF4uaZNg4svjizORqBBC6XeJTJ6rLsfVeKitwD3AN0ShbuvCn8+Z2btwCFAj4miXnR0BCeWzZuhpSX6Ru+KG9UvuAC+853u0++8E048MboAG0Sj9nITyUikjcLM9sv6eDzw1zzL9DezPuH7gcARwJLaRFgbP/95cHJxD35GXYtTdqP6mWcGbRC5SaKjIwhSSSKvfAlZpJEk1UZxlZkdQNA99gVgMoCZtQKT3f1s4EDgBjPrIkhoV7l73SSKNFRFlDykx2GHwWOPdZ++fDnsu2+METaGVI+xJRIBPeEuBqVWRXR0wJFH/mO5Bx6ocVLZZRdYt6779NWrYbfdahhI/UvDhYFINfSEuxortW2grS1IDjU/wRQaqG/DBujbt0ZBNJa09HITiYMSRQzKqYqo6QmmUILo7Cw8iJ+IND0liioUqm5I3fMTIhrqW0SakxJFhXpqh0hFVYQShIhEQPUNFUp1l0iz/EmiAYbZaMTh20XSTiWKCqWyS2SDlyB0Y5tIMpQoKpSqdogIE0Sau3k28vDtImmmRFGFxNshIi5BpP2KPZWlOJEmoDaKOpKpn4+rDSLV7S408PDtIimnEkWd6OiAtsONvOfGiNog6uGKPfFSnEgTUqKoBxZvgsiIot0lzW0cIlIZJYqElHRCLdAGseMOHlS9xBBXNRQo25sAAAuPSURBVFfsaW/jEJHKKFEkoMcTaoEE0fGo094O948t/wQcxZV+T9vIbuPYtAmmTg1eShYi9U2JIkutqk0KdvPsoRdTG5VXB1V7pV/KNjJtHJs2QVcXzJ0LDz2kkoVIvVOvp1DmRPjNbwY/47zzN/eBQlO+Ee+d1FH0ZiplG5k2jqOOCsYY7OpKZ+8pESmPEkWoll1DMyfULZ3GOxviH2qj7CfdVbGNtraguqlPn+r2JyLpoaqnUE27htaoF1NGFL2ZytlGqu5aF5Gq6Ql3WWbMgNmz4aSTYNKkGAJr8LGYRKR+6Ql3JejogPPPD0oUDz0Ew4dHeCWsBCEidUxtFKFY2ijyDbWxyy4NMdy3iDQPJYpQFA2+W+VLEB/6UJAc3nyzig2LiNSeEkWo6gHn3PMmiJ/a2ey4g9Pxo/LbTERE0kBtFFkqGr7CPbhpIMdvTp7JCb86i85O6N1Az07QWE4izUeJolJdXUE9Va4774QTT2RAB2z/23SPxFoujeUk0pyUKMq1ZQu0tHSf/thjMHr01o+V3kuQ5it2PWFOpDkpUZRq0ybo27f79OXLYd99865SblVW2q/Y6+F5FSISPSWKnrzzDuy0U/fpK1fCXntFuqs0X7FnSjrXXAOrV6ezxCMi8VCiKGTduuCeh1yvvAJ77BHLLtN6xZ72ko6IxCvx7rFm9lUzczMbWGD+WWa2NHydFXtA69YFXVxzk8SaNUEPp5iSBKT3mdBpf5a2iMQr0RKFme0NjAf+VmD+bsClQCvgwCIzu9vd34gloEmT4Cc/2XbaunWw886x7C6fND4TOq0lHRGpjaRLFD8Avk6QBPI5GrjP3deEyeE+4JjYornppn+837QpKEHUMEmkVVpLOiJSG4mVKMzseGCVu//ZCg2aB3sBL2Z9XhlOy7e9ScAkgMGDB1cW1KZNla0XobR2j01jSUdEaiPWRGFmc4H35pl1EfANgmqnSLj7DGAGBMOMR7XdWoqj0TitiUdE6kesicLdj8o33cyGA0OBTGliEPC4mY12979nLboKGJv1eRDQHkuwKRB191j1VhKRKCTSRuHuf3H3Pdx9iLsPIahSOjQnSQDcC4w3s/5m1p+gBHJvjcOtmUhHsEW9lUQkGqm7j8LMWoHJ7n62u68xs2nAH8PZl7n7mgTDi1XUjxBVbyURiYIehdrg1EYhIqXQo1CbmHoriUi1kr6PQkREUk6JooF0dMCVVwY/RUSioqqnOlBKO4O6wopIXJQoylTrxuFSE0CahygXkfqmRFGGQiftOJNHqQlAXWFFJC5KFGUodANbnFU+pSaAqO/BEBHJUKIoQ76TdtxVPuUkAHWFFZE4KFGUodBJO+4qHyUAEUmSEkWZck/a5Vzx6y5pEalHShQRKOWKX91XRaRe6Ya7GtFIriJSr5QoaiTqIcRFRGpFVU8FRN2eoO6rIlKvlCjyiKs9Qb2XRKQeqeopj0raEzQgn4g0KpUo8ih3OAz1aBKRRqZEkUe57QkakE9EGpkSRQHltCdoQD4RaWRKFBFQjyYRaWRKFBFRjyYRaVTq9SQiIkUpUYiISFFKFCIiUpQShYiIFKVEISIiRSlRiIhIUebuSccQOTN7DXihzNUGAq/HEE610hoXpDc2xVW+tMamuMpXaWz7uPvu+WY0ZKKohJktdPfWpOPIlda4IL2xKa7ypTU2xVW+OGJT1ZOIiBSlRCEiIkUpUfzDjKQDKCCtcUF6Y1Nc5UtrbIqrfJHHpjYKEREpSiUKEREpSolCRESKaqpEYWafMbOnzKzLzAp2HzOzY8zsGTNbZmYXZk0famaPhdNvN7PtI4prNzO7z8yWhj/751nmSDNbnPXaaGYnhPNmmtnzWfNG1iqucLnOrH3fnTU9luNVamxmNtLMOsLf+RNmdkrWvEiPWaG/maz5fcJjsCw8JkOy5k0Jpz9jZkdXE0cFcf1/M1sSHp/7zWyfrHl5f681imuimb2Wtf+zs+adFf7el5rZWVHGVWJsP8iK61kzW5s1L85jdqOZvWpmTxaYb2Z2bRj3E2Z2aNa86o6ZuzfNCzgQOABoB1oLLNMbWA7sC2wP/Bk4KJz3S+DU8P31wJciius7wIXh+wuB/+hh+d2ANcCO4eeZwMkxHK+S4gLWF5gey/EqNTZgf2C/8P2ewMvArlEfs2J/M1nLnAtcH74/Fbg9fH9QuHwfYGi4nd41jOvIrL+jL2XiKvZ7rVFcE4Hr8qy7G/Bc+LN/+L5/LWPLWf4rwI1xH7Nw2x8FDgWeLDD/U8DvAAMOAx6L6pg1VYnC3Z9292d6WGw0sMzdn3P3d4HbgOPNzICPA7PC5W4CTogotOPD7ZW63ZOB37n7OxHtv5By49oq5uNVUmzu/qy7Lw3fvwS8CuS987RKef9misQ7CxgXHqPjgdvcfZO7Pw8sC7dXk7jc/YGsv6P5wKCI9l1VXEUcDdzn7mvc/Q3gPuCYBGObAPwiwv0X5O4PElwgFnI88HMPzAd2NbP3EcExa6pEUaK9gBezPq8Mpw0A1rr7lpzpUfgnd385fP934J96WP5Uuv9xXhEWN39gZn1qHFdfM1toZvMz1WHEe7zKiQ0AMxtNcIW4PGtyVMes0N9M3mXCY/ImwTEqZd0448r2BYIr0ox8v9daxnVS+PuZZWZ7l7lu3LERVtMNBeZlTY7rmJWiUOxVH7OGexSqmc0F3ptn1kXu/utax5NRLK7sD+7uZlawz3J4hTAcuDdr8hSCk+X2BH2oLwAuq2Fc+7j7KjPbF5hnZn8hOBFWJeJj9t/AWe7eFU6u+Jg1IjM7HWgFPpY1udvv1d2X599C5P4H+IW7bzKzcwhKYx+v0b5LdSowy907s6Ylecxi03CJwt2PqnITq4C9sz4PCqetJijKbRdeEWamVx2Xmb1iZu9z95fDk9qrRTb1r8Cv3H1z1rYzV9abzOy/gH+vZVzuvir8+ZyZtQOHALOp4nhFFZuZ7QL8luBCYX7Wtis+ZnkU+pvJt8xKM9sOeA/B31Qp68YZF2Z2FEHy/Zi7b8pML/B7jeKk12Nc7r466+NPCdqkMuuOzVm3PYKYSo4ty6nAl7MnxHjMSlEo9qqPmaqeuvsjsJ8FPXa2J/hjuNuDVqEHCNoHAM4Coiqh3B1ur5TtdqsTDU+UmXaBE4C8vSLiiMvM+meqbcxsIHAEsCTm41VqbNsDvyKot52VMy/KY5b3b6ZIvCcD88JjdDdwqgW9ooYC+wELqoilrLjM7BDgBuA4d381a3re32sN43pf1sfjgKfD9/cC48P4+gPj2bZ0HXtsYXwfJGgY7siaFucxK8XdwJlh76fDgDfDC6Lqj1lcLfRpfAEnEtTPbQJeAe4Np+8J3JO13KeAZwmuBC7Kmr4vwT/xMuAOoE9EcQ0A7geWAnOB3cLprcBPs5YbQnB10Ctn/XnAXwhOdjcDO9cqLuDwcN9/Dn9+Ie7jVUZspwObgcVZr5FxHLN8fzMEVVnHhe/7hsdgWXhM9s1a96JwvWeAT0b8N99TXHPD/4XM8bm7p99rjeK6Engq3P8DwAez1v18eByXAZ+LMq5SYgs/TwWuylkv7mP2C4Kee5sJzmNfACYDk8P5BkwP4/4LWT07qz1mGsJDRESKUtWTiIgUpUQhIiJFKVGIiEhRShQiIlKUEoWIiBSlRCESMzPb24KRancLP/cPPw9JNjKR0ihRiMTM3V8E/hO4Kpx0FTDD3VckFpRIGXQfhUgNmFkLsAi4EfgiwY1/m4uvJZIODTfWk0gauftmM/sa8HtgvJKE1BNVPYnUzicJhmA4OOlARMqhRCFSAxY8avUTBE8e+385g96JpJoShUjMwhFq/xM4393/BlwNfDfZqERKp0QhEr8vAn9z9/vCzz8GDjSzjxVZRyQ11OtJRESKUolCRESKUqIQEZGilChERKQoJQoRESlKiUJERIpSohARkaKUKEREpKj/BfufHVHns9ceAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.674014610512526e-05\n",
            "Is model correct?\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2pJ3mzr4GI5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0WElR74Gmx"
      },
      "source": [
        "plt.style.use(['ggplot'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5hAvVay4I9t"
      },
      "source": [
        "X = 2 * np.random.rand(100,1)\n",
        "y = 4 +3 * X+np.random.randn(100,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Rtkeryel4LZp",
        "outputId": "de3106e3-f43c-40d1-ac46-51ac4b770490"
      },
      "source": [
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp_uccC-4Xi0"
      },
      "source": [
        "Аналитически"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl6CdC2z4M6O",
        "outputId": "d89f30b6-3e3c-403d-e921-4f66641073d4"
      },
      "source": [
        "X_b = np.c_[np.ones((100,1)),X]\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "print(theta_best)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.05364333]\n",
            " [2.95679361]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1uImP674PU-",
        "outputId": "8cd22ad8-bc8a-40e3-9390-ebf3d27e5fed"
      },
      "source": [
        "X_new = np.array([[0],[2]])\n",
        "X_new_b = np.c_[np.ones((2,1)),X_new]\n",
        "y_predict = X_new_b.dot(theta_best)\n",
        "y_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.05364333],\n",
              "       [9.96723054]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "KuqKhjwN4Rsb",
        "outputId": "3e8e8753-63a9-4b51-c5bd-dc5349ce4c77"
      },
      "source": [
        "plt.plot(X_new,y_predict,'r-')\n",
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([0,2,0,15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 2.0, 0.0, 15.0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrByuUEz4nIz"
      },
      "source": [
        "Градиентный спуск"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQI-DpsV4UUp"
      },
      "source": [
        "def  cal_cost(theta,X,y):\n",
        "    '''\n",
        "    \n",
        "    Calculates the cost for given X and Y. The following shows and example of a single dimensional X\n",
        "    theta = Vector of thetas \n",
        "    X     = Row of X's np.zeros((2,j))\n",
        "    y     = Actual y's np.zeros((2,1))\n",
        "    \n",
        "    where:\n",
        "        j is the no of features\n",
        "    '''\n",
        "    \n",
        "    m = len(y)\n",
        "    \n",
        "    predictions = X.dot(theta)\n",
        "    cost = (1/2*m) * np.sum(np.square(predictions-y))\n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5EGdPcd4t5u"
      },
      "source": [
        "def gradient_descent(X,y,theta,learning_rate=0.01,iterations=100):\n",
        "    '''\n",
        "    X    = Matrix of X with added bias units\n",
        "    y    = Vector of Y\n",
        "    theta=Vector of thetas np.random.randn(j,1)\n",
        "    learning_rate \n",
        "    iterations = no of iterations\n",
        "    \n",
        "    Returns the final theta vector and array of cost history over no of iterations\n",
        "    '''\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "    theta_history = np.zeros((iterations,2))\n",
        "    for it in range(iterations):\n",
        "        \n",
        "        prediction = np.dot(X,theta)\n",
        "        \n",
        "        theta = theta -(1/m)*learning_rate*( X.T.dot((prediction - y)))\n",
        "        theta_history[it,:] =theta.T\n",
        "        cost_history[it]  = cal_cost(theta,X,y)\n",
        "        \n",
        "    return theta, cost_history, theta_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwmgm0Uq6ECN"
      },
      "source": [
        "def stocashtic_gradient_descent(X,y,theta,learning_rate=0.01,iterations=10):\n",
        "    '''\n",
        "    X    = Matrix of X with added bias units\n",
        "    y    = Vector of Y\n",
        "    theta=Vector of thetas np.random.randn(j,1)\n",
        "    learning_rate \n",
        "    iterations = no of iterations\n",
        "    \n",
        "    Returns the final theta vector and array of cost history over no of iterations\n",
        "    '''\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "    \n",
        "    \n",
        "    for it in range(iterations):\n",
        "        cost =0.0\n",
        "        for i in range(m):\n",
        "            rand_ind = np.random.randint(0,m)\n",
        "            X_i = X[rand_ind,:].reshape(1,X.shape[1])\n",
        "            y_i = y[rand_ind].reshape(1,1)\n",
        "            prediction = np.dot(X_i,theta)\n",
        "\n",
        "            theta = theta -(1/m)*learning_rate*( X_i.T.dot((prediction - y_i)))\n",
        "            cost += cal_cost(theta,X_i,y_i)\n",
        "        cost_history[it]  = cost\n",
        "        \n",
        "    return theta, cost_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "SJQ01Uxl6I9H",
        "outputId": "faf0850a-5ac1-4c4b-b0f7-b28aae2c0670"
      },
      "source": [
        "lr =0.5\n",
        "n_iter = 50\n",
        "\n",
        "theta = np.random.randn(2,1)\n",
        "\n",
        "X_b = np.c_[np.ones((len(X),1)),X]\n",
        "theta,cost_history = stocashtic_gradient_descent(X_b,y,theta,lr,n_iter)\n",
        "\n",
        "\n",
        "print('Theta0:          {:0.3f},\\nTheta1:          {:0.3f}'.format(theta[0][0],theta[1][0]))\n",
        "print('Final cost/MSE:  {:0.3f}'.format(cost_history[-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fbec67fc59c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstocashtic_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "ZD-kH7qD6XYn",
        "outputId": "19c04e66-0ffa-4077-cfd1-267977214114"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "ax.set_ylabel('{J(Theta)}',rotation=0)\n",
        "ax.set_xlabel('{Iterations}')\n",
        "theta = np.random.randn(2,1)\n",
        "\n",
        "_=ax.plot(range(n_iter),cost_history,'b.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGvap76P6e-p"
      },
      "source": [
        "def minibatch_gradient_descent(X,y,theta,learning_rate=0.01,iterations=10,batch_size =20):\n",
        "    '''\n",
        "    X    = Matrix of X without added bias units\n",
        "    y    = Vector of Y\n",
        "    theta=Vector of thetas np.random.randn(j,1)\n",
        "    learning_rate \n",
        "    iterations = no of iterations\n",
        "    \n",
        "    Returns the final theta vector and array of cost history over no of iterations\n",
        "    '''\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "    n_batches = int(m/batch_size)\n",
        "    \n",
        "    for it in range(iterations):\n",
        "        cost =0.0\n",
        "        indices = np.random.permutation(m)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "        for i in range(0,m,batch_size):\n",
        "            X_i = X[i:i+batch_size]\n",
        "            y_i = y[i:i+batch_size]\n",
        "            \n",
        "            X_i = np.c_[np.ones(len(X_i)),X_i]\n",
        "           \n",
        "            prediction = np.dot(X_i,theta)\n",
        "\n",
        "            theta = theta -(1/m)*learning_rate*( X_i.T.dot((prediction - y_i)))\n",
        "            cost += cal_cost(theta,X_i,y_i)\n",
        "        cost_history[it]  = cost\n",
        "        \n",
        "    return theta, cost_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fNyzHn466fac",
        "outputId": "7fff7000-cefd-4664-b384-5994ce01addc"
      },
      "source": [
        "lr =0.1\n",
        "n_iter = 200\n",
        "\n",
        "theta = np.random.randn(2,1)\n",
        "\n",
        "\n",
        "theta,cost_history = minibatch_gradient_descent(X,y,theta,lr,n_iter)\n",
        "\n",
        "\n",
        "print('Theta0:          {:0.3f},\\nTheta1:          {:0.3f}'.format(theta[0][0],theta[1][0]))\n",
        "print('Final cost/MSE:  {:0.3f}'.format(cost_history[-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a10ae2e1fd3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "QmlisFx06hDc",
        "outputId": "d6841e44-8cb4-4558-f495-5e54f6218436"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "ax.set_ylabel('{J(Theta)}',rotation=0)\n",
        "ax.set_xlabel('{Iterations}')\n",
        "theta = np.random.randn(2,1)\n",
        "\n",
        "_=ax.plot(range(n_iter),cost_history,'b.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNz90vqU_GEd"
      },
      "source": [
        "# sin GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_znxyMWB_HEp"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQjWqTbW_Qf0",
        "outputId": "90c33069-03d1-49ff-9c61-11b59c06e9f1"
      },
      "source": [
        "torch.manual_seed(111)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f95b1e93550>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nglbm-5m_Sqv"
      },
      "source": [
        "train_data_length = 1024\n",
        "train_data = torch.zeros((train_data_length, 2))\n",
        "train_data[:, 0] = 2 * math.pi * torch.rand(train_data_length)\n",
        "train_data[:, 1] = torch.sin(train_data[:, 0])\n",
        "train_labels = torch.zeros(train_data_length)\n",
        "train_set = [\n",
        "    (train_data[i], train_labels[i]) for i in range(train_data_length)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hisIqZbiAmGn",
        "outputId": "518462fb-f72f-4d91-d8ac-43151c023464"
      },
      "source": [
        "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f952b57e990>]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXXUW0ZJBB_5"
      },
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNYq9HkdCYvB"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2GwNUtTCgAC"
      },
      "source": [
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5SEyALSD2yh"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "generator = Generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WTbhigOJBWs"
      },
      "source": [
        "lr = 0.001\n",
        "num_epochs = 400\n",
        "loss_function = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvx8IbBfJVc5"
      },
      "source": [
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "LIoRtAAVM42x",
        "outputId": "3895209f-79a8-4c4c-bce1-64718930f3f3"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for n, (real_samples, _) in enumerate(train_loader):\n",
        "        # Данные для обучения дискриминатора\n",
        "        real_samples_labels = torch.ones((batch_size, 1))\n",
        "        latent_space_samples = torch.randn((batch_size, 2))\n",
        "        generated_samples = generator(latent_space_samples)\n",
        "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
        "        all_samples = torch.cat((real_samples, generated_samples))\n",
        "        all_samples_labels = torch.cat(\n",
        "            (real_samples_labels, generated_samples_labels))\n",
        "\n",
        "        # Обучение дискриминатора\n",
        "        discriminator.zero_grad()\n",
        "        output_discriminator = discriminator(all_samples)\n",
        "        loss_discriminator = loss_function(\n",
        "            output_discriminator, all_samples_labels)\n",
        "        loss_discriminator.backward()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "        # Данные для обучения генератора\n",
        "        latent_space_samples = torch.randn((batch_size, 2))\n",
        "\n",
        "        # Обучение генератора\n",
        "        generator.zero_grad()\n",
        "        generated_samples = generator(latent_space_samples)\n",
        "        output_discriminator_generated = discriminator(generated_samples)\n",
        "        loss_generator = loss_function(\n",
        "            output_discriminator_generated, real_samples_labels)\n",
        "        loss_generator.backward()\n",
        "        optimizer_generator.step()\n",
        "\n",
        "        # Выводим значения функций потерь\n",
        "        if epoch % 10 == 0 and n == batch_size - 1:\n",
        "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
        "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss D.: 0.21308739483356476\n",
            "Epoch: 0 Loss G.: 1.7989580631256104\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-dd81dfea6165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         loss_generator = loss_function(\n\u001b[1;32m     28\u001b[0m             output_discriminator_generated, real_samples_labels)\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XCyuEpcNmNM"
      },
      "source": [
        "latent_space_samples = torch.randn(100, 2)\n",
        "generated_samples = generator(latent_space_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWuBakMNsFY"
      },
      "source": [
        "generated_samples = generated_samples.detach()\n",
        "plt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yotYq2M0DfO"
      },
      "source": [
        "# Крестики Нолики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4CfiL5u0Gok"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPk9hHot0HRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f37ccc-1f01-4841-a39a-990466fecfaf"
      },
      "source": [
        "torch.manual_seed(111)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f01d6bf26f0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAP5qhvq0HUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "f6e3244c-0be1-4549-f24b-84111df4ef7d"
      },
      "source": [
        "train_data_length = 1024\n",
        "train_data = torch.zeros((train_data_length, 9))\n",
        "\n",
        "\n",
        "#train_data[:, 0] = 2 * math.pi * torch.rand(train_data_length)\n",
        "#train_data[:, 1] = torch.sin(train_data[:, 0])\n",
        "#train_labels = torch.zeros(train_data_length)\n",
        "#train_set = [\n",
        "    (train_data[i], train_labels[i]) for i in range(train_data_length)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-9a8861c5b69d>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    (train_data[i], train_labels[i]) for i in range(train_data_length)]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zisonsw0Hbp"
      },
      "source": [
        "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhwkiGat0Hgw"
      },
      "source": [
        " 0 0 0\n",
        " 0 1 0\n",
        " 0 1 1\n",
        "\n",
        " if a[1]==a[2]==a[3] or a[1]==a[4]==a[7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gwDqCM25xdp"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "BOARD_ROWS = 3\n",
        "BOARD_COLS = 3\n",
        "BOARD_SIZE = BOARD_ROWS * BOARD_COLS\n",
        "\n",
        "class State:\n",
        "    def __init__(self):\n",
        "        # the board is represented by a n * n array,\n",
        "        # 1 represents chessman of the player who moves first,\n",
        "        # -1 represents chessman of another player\n",
        "        # 0 represents empty position\n",
        "        self.data = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
        "        self.winner = None\n",
        "        self.hashVal = None\n",
        "        self.end = None\n",
        "\n",
        "    # calculate the hash value for one state, it's unique\n",
        "    def getHash(self):\n",
        "        if self.hashVal is None:\n",
        "            self.hashVal = 0\n",
        "            for i in self.data.reshape(BOARD_ROWS * BOARD_COLS):\n",
        "                if i == -1:\n",
        "                    i = 2\n",
        "                self.hashVal = self.hashVal * 3 + i\n",
        "        return int(self.hashVal)\n",
        "\n",
        "    # determine whether a player has won the game, or it's a tie\n",
        "    def isEnd(self):\n",
        "        if self.end is not None:\n",
        "            return self.end\n",
        "        results = []\n",
        "        # check row\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            results.append(np.sum(self.data[i, :]))\n",
        "        # check columns\n",
        "        for i in range(0, BOARD_COLS):\n",
        "            results.append(np.sum(self.data[:, i]))\n",
        "\n",
        "        # check diagonals\n",
        "        results.append(0)\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            results[-1] += self.data[i, i]\n",
        "        results.append(0)\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            results[-1] += self.data[i, BOARD_ROWS - 1 - i]\n",
        "\n",
        "        for result in results:\n",
        "            if result == 3:\n",
        "                self.winner = 1\n",
        "                self.end = True\n",
        "                return self.end\n",
        "            if result == -3:\n",
        "                self.winner = -1\n",
        "                self.end = True\n",
        "                return self.end\n",
        "\n",
        "        # whether it's a tie\n",
        "        sum = np.sum(np.abs(self.data))\n",
        "        if sum == BOARD_ROWS * BOARD_COLS:\n",
        "            self.winner = 0\n",
        "            self.end = True\n",
        "            return self.end\n",
        "\n",
        "        # game is still going on\n",
        "        self.end = False\n",
        "        return self.end\n",
        "\n",
        "    # symbol 1 or -1\n",
        "    # put chessman symbol in position (i, j)\n",
        "    def nextState(self, i, j, symbol):\n",
        "        newState = State()\n",
        "        newState.data = np.copy(self.data)\n",
        "        newState.data[i, j] = symbol\n",
        "        return newState\n",
        "\n",
        "    # print the board\n",
        "    def show(self):\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                if self.data[i, j] == 1:\n",
        "                    token = '*'\n",
        "                if self.data[i, j] == 0:\n",
        "                    token = '0'\n",
        "                if self.data[i, j] == -1:\n",
        "                    token = 'x'\n",
        "                out += token + ' | '\n",
        "            print(out)\n",
        "        print('-------------')\n",
        "\n",
        "def getAllStatesImpl(currentState, currentSymbol, allStates):\n",
        "    for i in range(0, BOARD_ROWS):\n",
        "        for j in range(0, BOARD_COLS):\n",
        "            if currentState.data[i][j] == 0:\n",
        "                newState = currentState.nextState(i, j, currentSymbol)\n",
        "                newHash = newState.getHash()\n",
        "                if newHash not in allStates.keys():\n",
        "                    isEnd = newState.isEnd()\n",
        "                    allStates[newHash] = (newState, isEnd)\n",
        "                    if not isEnd:\n",
        "                        getAllStatesImpl(newState, -currentSymbol, allStates)\n",
        "\n",
        "def getAllStates():\n",
        "    currentSymbol = 1\n",
        "    currentState = State()\n",
        "    allStates = dict()\n",
        "    allStates[currentState.getHash()] = (currentState, currentState.isEnd())\n",
        "    getAllStatesImpl(currentState, currentSymbol, allStates)\n",
        "    return allStates\n",
        "\n",
        "# all possible board configurations\n",
        "allStates = getAllStates()\n",
        "\n",
        "class Judger:\n",
        "    # @player1: player who will move first, its chessman will be 1\n",
        "    # @player2: another player with chessman -1\n",
        "    # @feedback: if True, both players will receive rewards when game is end\n",
        "    def __init__(self, player1, player2, feedback=True):\n",
        "        self.p1 = player1\n",
        "        self.p2 = player2\n",
        "        self.feedback = feedback\n",
        "        self.currentPlayer = None\n",
        "        self.p1Symbol = 1\n",
        "        self.p2Symbol = -1\n",
        "        self.p1.setSymbol(self.p1Symbol)\n",
        "        self.p2.setSymbol(self.p2Symbol)\n",
        "        self.currentState = State()\n",
        "        self.allStates = allStates\n",
        "\n",
        "    # give reward to two players\n",
        "    def giveReward(self):\n",
        "        if self.currentState.winner == self.p1Symbol:\n",
        "            self.p1.feedReward(1)\n",
        "            self.p2.feedReward(0)\n",
        "        elif self.currentState.winner == self.p2Symbol:\n",
        "            self.p1.feedReward(0)\n",
        "            self.p2.feedReward(1)\n",
        "        else:\n",
        "            self.p1.feedReward(0.1)\n",
        "            self.p2.feedReward(0.5)\n",
        "\n",
        "    def feedCurrentState(self):\n",
        "        self.p1.feedState(self.currentState)\n",
        "        self.p2.feedState(self.currentState)\n",
        "\n",
        "    def reset(self):\n",
        "        self.p1.reset()\n",
        "        self.p2.reset()\n",
        "        self.currentState = State()\n",
        "        self.currentPlayer = None\n",
        "\n",
        "    # @show: if True, print each board during the game\n",
        "    def play(self, show=False):\n",
        "        self.reset()\n",
        "        self.feedCurrentState()\n",
        "        while True:\n",
        "            # set current player\n",
        "            if self.currentPlayer == self.p1:\n",
        "                self.currentPlayer = self.p2\n",
        "            else:\n",
        "                self.currentPlayer = self.p1\n",
        "            if show:\n",
        "                self.currentState.show()\n",
        "            [i, j, symbol] = self.currentPlayer.takeAction()\n",
        "            self.currentState = self.currentState.nextState(i, j, symbol)\n",
        "            hashValue = self.currentState.getHash()\n",
        "            self.currentState, isEnd = self.allStates[hashValue]\n",
        "            self.feedCurrentState()\n",
        "            if isEnd:\n",
        "                if self.feedback:\n",
        "                    self.giveReward()\n",
        "                return self.currentState.winner\n",
        "\n",
        "# AI player\n",
        "class Player:\n",
        "    # @stepSize: step size to update estimations\n",
        "    # @exploreRate: possibility to explore\n",
        "    def __init__(self, stepSize = 0.1, exploreRate=0.1):\n",
        "        self.allStates = allStates\n",
        "        self.estimations = dict()\n",
        "        self.stepSize = stepSize\n",
        "        self.exploreRate = exploreRate\n",
        "        self.states = []\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def setSymbol(self, symbol):\n",
        "        self.symbol = symbol\n",
        "        for hash in self.allStates.keys():\n",
        "            (state, isEnd) = self.allStates[hash]\n",
        "            if isEnd:\n",
        "                if state.winner == self.symbol:\n",
        "                    self.estimations[hash] = 1.0\n",
        "                else:\n",
        "                    self.estimations[hash] = 0\n",
        "            else:\n",
        "                self.estimations[hash] = 0.5\n",
        "\n",
        "    # accept a state\n",
        "    def feedState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # update estimation according to reward\n",
        "    def feedReward(self, reward):\n",
        "        if len(self.states) == 0:\n",
        "            return\n",
        "        self.states = [state.getHash() for state in self.states]\n",
        "        target = reward\n",
        "        for latestState in reversed(self.states):\n",
        "            value = self.estimations[latestState] + self.stepSize * (target - self.estimations[latestState])\n",
        "            self.estimations[latestState] = value\n",
        "            target = value\n",
        "        self.states = []\n",
        "\n",
        "    # determine next action\n",
        "    def takeAction(self):\n",
        "        state = self.states[-1]\n",
        "        nextStates = []\n",
        "        nextPositions = []\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                if state.data[i, j] == 0:\n",
        "                    nextPositions.append([i, j])\n",
        "                    nextStates.append(state.nextState(i, j, self.symbol).getHash())\n",
        "        if np.random.binomial(1, self.exploreRate):\n",
        "            np.random.shuffle(nextPositions)\n",
        "            # Not sure if truncating is the best way to deal with exploratory step\n",
        "            # Maybe it's better to only skip this step rather than forget all the history\n",
        "            self.states = []\n",
        "            action = nextPositions[0]\n",
        "            action.append(self.symbol)\n",
        "            return action\n",
        "\n",
        "        values = []\n",
        "        for hash, pos in zip(nextStates, nextPositions):\n",
        "            values.append((self.estimations[hash], pos))\n",
        "        np.random.shuffle(values)\n",
        "        values.sort(key=lambda x: x[0], reverse=True)\n",
        "        action = values[0][1]\n",
        "        action.append(self.symbol)\n",
        "        return action\n",
        "\n",
        "    def savePolicy(self):\n",
        "        fw = open('optimal_policy_' + str(self.symbol), 'wb')\n",
        "        pickle.dump(self.estimations, fw)\n",
        "        fw.close()\n",
        "\n",
        "    def loadPolicy(self):\n",
        "        fr = open('optimal_policy_' + str(self.symbol),'rb')\n",
        "        self.estimations = pickle.load(fr)\n",
        "        fr.close()\n",
        "\n",
        "# human interface\n",
        "# input a number to put a chessman\n",
        "# | 1 | 2 | 3 |\n",
        "# | 4 | 5 | 6 |\n",
        "# | 7 | 8 | 9 |\n",
        "class HumanPlayer:\n",
        "    def __init__(self, stepSize = 0.1, exploreRate=0.1):\n",
        "        self.symbol = None\n",
        "        self.currentState = None\n",
        "        return\n",
        "    def reset(self):\n",
        "        return\n",
        "    def setSymbol(self, symbol):\n",
        "        self.symbol = symbol\n",
        "        return\n",
        "    def feedState(self, state):\n",
        "        self.currentState = state\n",
        "        return\n",
        "    def feedReward(self, reward):\n",
        "        return\n",
        "    def takeAction(self):\n",
        "        data = int(input(\"Input your position:\"))\n",
        "        data -= 1\n",
        "        i = data // int(BOARD_COLS)\n",
        "        j = data % BOARD_COLS\n",
        "        if self.currentState.data[i, j] != 0:\n",
        "            return self.takeAction()\n",
        "        return (i, j, self.symbol)\n",
        "\n",
        "def train(epochs=20000):\n",
        "    player1 = Player()\n",
        "    player2 = Player()\n",
        "    judger = Judger(player1, player2)\n",
        "    player1Win = 0.0\n",
        "    player2Win = 0.0\n",
        "    for i in range(0, epochs):\n",
        "        print(\"Epoch\", i)\n",
        "        winner = judger.play()\n",
        "        if winner == 1:\n",
        "            player1Win += 1\n",
        "        if winner == -1:\n",
        "            player2Win += 1\n",
        "        judger.reset()\n",
        "    print(player1Win / epochs)\n",
        "    print(player2Win / epochs)\n",
        "    player1.savePolicy()\n",
        "    player2.savePolicy()\n",
        "\n",
        "def compete(turns=500):\n",
        "    player1 = Player(exploreRate=0)\n",
        "    player2 = Player(exploreRate=0)\n",
        "    judger = Judger(player1, player2, False)\n",
        "    player1.loadPolicy()\n",
        "    player2.loadPolicy()\n",
        "    player1Win = 0.0\n",
        "    player2Win = 0.0\n",
        "    for i in range(0, turns):\n",
        "        print(\"Epoch\", i)\n",
        "        winner = judger.play()\n",
        "        if winner == 1:\n",
        "            player1Win += 1\n",
        "        if winner == -1:\n",
        "            player2Win += 1\n",
        "        judger.reset()\n",
        "    print(player1Win / turns)\n",
        "    print(player2Win / turns)\n",
        "\n",
        "def play():\n",
        "    while True:\n",
        "        player1 = Player(exploreRate=0)\n",
        "        player2 = HumanPlayer()\n",
        "        judger = Judger(player1, player2, False)\n",
        "        player1.loadPolicy()\n",
        "        winner = judger.play(True)\n",
        "        if winner == player2.symbol:\n",
        "            print(\"Win!\")\n",
        "        elif winner == player1.symbol:\n",
        "            print(\"Lose!\")\n",
        "        else:\n",
        "            print(\"Tie!\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc6GNOsQ9f7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28764532-ee58-4696-ebce-7a0138c1292a"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 15002\n",
            "Epoch 15003\n",
            "Epoch 15004\n",
            "Epoch 15005\n",
            "Epoch 15006\n",
            "Epoch 15007\n",
            "Epoch 15008\n",
            "Epoch 15009\n",
            "Epoch 15010\n",
            "Epoch 15011\n",
            "Epoch 15012\n",
            "Epoch 15013\n",
            "Epoch 15014\n",
            "Epoch 15015\n",
            "Epoch 15016\n",
            "Epoch 15017\n",
            "Epoch 15018\n",
            "Epoch 15019\n",
            "Epoch 15020\n",
            "Epoch 15021\n",
            "Epoch 15022\n",
            "Epoch 15023\n",
            "Epoch 15024\n",
            "Epoch 15025\n",
            "Epoch 15026\n",
            "Epoch 15027\n",
            "Epoch 15028\n",
            "Epoch 15029\n",
            "Epoch 15030\n",
            "Epoch 15031\n",
            "Epoch 15032\n",
            "Epoch 15033\n",
            "Epoch 15034\n",
            "Epoch 15035\n",
            "Epoch 15036\n",
            "Epoch 15037\n",
            "Epoch 15038\n",
            "Epoch 15039\n",
            "Epoch 15040\n",
            "Epoch 15041\n",
            "Epoch 15042\n",
            "Epoch 15043\n",
            "Epoch 15044\n",
            "Epoch 15045\n",
            "Epoch 15046\n",
            "Epoch 15047\n",
            "Epoch 15048\n",
            "Epoch 15049\n",
            "Epoch 15050\n",
            "Epoch 15051\n",
            "Epoch 15052\n",
            "Epoch 15053\n",
            "Epoch 15054\n",
            "Epoch 15055\n",
            "Epoch 15056\n",
            "Epoch 15057\n",
            "Epoch 15058\n",
            "Epoch 15059\n",
            "Epoch 15060\n",
            "Epoch 15061\n",
            "Epoch 15062\n",
            "Epoch 15063\n",
            "Epoch 15064\n",
            "Epoch 15065\n",
            "Epoch 15066\n",
            "Epoch 15067\n",
            "Epoch 15068\n",
            "Epoch 15069\n",
            "Epoch 15070\n",
            "Epoch 15071\n",
            "Epoch 15072\n",
            "Epoch 15073\n",
            "Epoch 15074\n",
            "Epoch 15075\n",
            "Epoch 15076\n",
            "Epoch 15077\n",
            "Epoch 15078\n",
            "Epoch 15079\n",
            "Epoch 15080\n",
            "Epoch 15081\n",
            "Epoch 15082\n",
            "Epoch 15083\n",
            "Epoch 15084\n",
            "Epoch 15085\n",
            "Epoch 15086\n",
            "Epoch 15087\n",
            "Epoch 15088\n",
            "Epoch 15089\n",
            "Epoch 15090\n",
            "Epoch 15091\n",
            "Epoch 15092\n",
            "Epoch 15093\n",
            "Epoch 15094\n",
            "Epoch 15095\n",
            "Epoch 15096\n",
            "Epoch 15097\n",
            "Epoch 15098\n",
            "Epoch 15099\n",
            "Epoch 15100\n",
            "Epoch 15101\n",
            "Epoch 15102\n",
            "Epoch 15103\n",
            "Epoch 15104\n",
            "Epoch 15105\n",
            "Epoch 15106\n",
            "Epoch 15107\n",
            "Epoch 15108\n",
            "Epoch 15109\n",
            "Epoch 15110\n",
            "Epoch 15111\n",
            "Epoch 15112\n",
            "Epoch 15113\n",
            "Epoch 15114\n",
            "Epoch 15115\n",
            "Epoch 15116\n",
            "Epoch 15117\n",
            "Epoch 15118\n",
            "Epoch 15119\n",
            "Epoch 15120\n",
            "Epoch 15121\n",
            "Epoch 15122\n",
            "Epoch 15123\n",
            "Epoch 15124\n",
            "Epoch 15125\n",
            "Epoch 15126\n",
            "Epoch 15127\n",
            "Epoch 15128\n",
            "Epoch 15129\n",
            "Epoch 15130\n",
            "Epoch 15131\n",
            "Epoch 15132\n",
            "Epoch 15133\n",
            "Epoch 15134\n",
            "Epoch 15135\n",
            "Epoch 15136\n",
            "Epoch 15137\n",
            "Epoch 15138\n",
            "Epoch 15139\n",
            "Epoch 15140\n",
            "Epoch 15141\n",
            "Epoch 15142\n",
            "Epoch 15143\n",
            "Epoch 15144\n",
            "Epoch 15145\n",
            "Epoch 15146\n",
            "Epoch 15147\n",
            "Epoch 15148\n",
            "Epoch 15149\n",
            "Epoch 15150\n",
            "Epoch 15151\n",
            "Epoch 15152\n",
            "Epoch 15153\n",
            "Epoch 15154\n",
            "Epoch 15155\n",
            "Epoch 15156\n",
            "Epoch 15157\n",
            "Epoch 15158\n",
            "Epoch 15159\n",
            "Epoch 15160\n",
            "Epoch 15161\n",
            "Epoch 15162\n",
            "Epoch 15163\n",
            "Epoch 15164\n",
            "Epoch 15165\n",
            "Epoch 15166\n",
            "Epoch 15167\n",
            "Epoch 15168\n",
            "Epoch 15169\n",
            "Epoch 15170\n",
            "Epoch 15171\n",
            "Epoch 15172\n",
            "Epoch 15173\n",
            "Epoch 15174\n",
            "Epoch 15175\n",
            "Epoch 15176\n",
            "Epoch 15177\n",
            "Epoch 15178\n",
            "Epoch 15179\n",
            "Epoch 15180\n",
            "Epoch 15181\n",
            "Epoch 15182\n",
            "Epoch 15183\n",
            "Epoch 15184\n",
            "Epoch 15185\n",
            "Epoch 15186\n",
            "Epoch 15187\n",
            "Epoch 15188\n",
            "Epoch 15189\n",
            "Epoch 15190\n",
            "Epoch 15191\n",
            "Epoch 15192\n",
            "Epoch 15193\n",
            "Epoch 15194\n",
            "Epoch 15195\n",
            "Epoch 15196\n",
            "Epoch 15197\n",
            "Epoch 15198\n",
            "Epoch 15199\n",
            "Epoch 15200\n",
            "Epoch 15201\n",
            "Epoch 15202\n",
            "Epoch 15203\n",
            "Epoch 15204\n",
            "Epoch 15205\n",
            "Epoch 15206\n",
            "Epoch 15207\n",
            "Epoch 15208\n",
            "Epoch 15209\n",
            "Epoch 15210\n",
            "Epoch 15211\n",
            "Epoch 15212\n",
            "Epoch 15213\n",
            "Epoch 15214\n",
            "Epoch 15215\n",
            "Epoch 15216\n",
            "Epoch 15217\n",
            "Epoch 15218\n",
            "Epoch 15219\n",
            "Epoch 15220\n",
            "Epoch 15221\n",
            "Epoch 15222\n",
            "Epoch 15223\n",
            "Epoch 15224\n",
            "Epoch 15225\n",
            "Epoch 15226\n",
            "Epoch 15227\n",
            "Epoch 15228\n",
            "Epoch 15229\n",
            "Epoch 15230\n",
            "Epoch 15231\n",
            "Epoch 15232\n",
            "Epoch 15233\n",
            "Epoch 15234\n",
            "Epoch 15235\n",
            "Epoch 15236\n",
            "Epoch 15237\n",
            "Epoch 15238\n",
            "Epoch 15239\n",
            "Epoch 15240\n",
            "Epoch 15241\n",
            "Epoch 15242\n",
            "Epoch 15243\n",
            "Epoch 15244\n",
            "Epoch 15245\n",
            "Epoch 15246\n",
            "Epoch 15247\n",
            "Epoch 15248\n",
            "Epoch 15249\n",
            "Epoch 15250\n",
            "Epoch 15251\n",
            "Epoch 15252\n",
            "Epoch 15253\n",
            "Epoch 15254\n",
            "Epoch 15255\n",
            "Epoch 15256\n",
            "Epoch 15257\n",
            "Epoch 15258\n",
            "Epoch 15259\n",
            "Epoch 15260\n",
            "Epoch 15261\n",
            "Epoch 15262\n",
            "Epoch 15263\n",
            "Epoch 15264\n",
            "Epoch 15265\n",
            "Epoch 15266\n",
            "Epoch 15267\n",
            "Epoch 15268\n",
            "Epoch 15269\n",
            "Epoch 15270\n",
            "Epoch 15271\n",
            "Epoch 15272\n",
            "Epoch 15273\n",
            "Epoch 15274\n",
            "Epoch 15275\n",
            "Epoch 15276\n",
            "Epoch 15277\n",
            "Epoch 15278\n",
            "Epoch 15279\n",
            "Epoch 15280\n",
            "Epoch 15281\n",
            "Epoch 15282\n",
            "Epoch 15283\n",
            "Epoch 15284\n",
            "Epoch 15285\n",
            "Epoch 15286\n",
            "Epoch 15287\n",
            "Epoch 15288\n",
            "Epoch 15289\n",
            "Epoch 15290\n",
            "Epoch 15291\n",
            "Epoch 15292\n",
            "Epoch 15293\n",
            "Epoch 15294\n",
            "Epoch 15295\n",
            "Epoch 15296\n",
            "Epoch 15297\n",
            "Epoch 15298\n",
            "Epoch 15299\n",
            "Epoch 15300\n",
            "Epoch 15301\n",
            "Epoch 15302\n",
            "Epoch 15303\n",
            "Epoch 15304\n",
            "Epoch 15305\n",
            "Epoch 15306\n",
            "Epoch 15307\n",
            "Epoch 15308\n",
            "Epoch 15309\n",
            "Epoch 15310\n",
            "Epoch 15311\n",
            "Epoch 15312\n",
            "Epoch 15313\n",
            "Epoch 15314\n",
            "Epoch 15315\n",
            "Epoch 15316\n",
            "Epoch 15317\n",
            "Epoch 15318\n",
            "Epoch 15319\n",
            "Epoch 15320\n",
            "Epoch 15321\n",
            "Epoch 15322\n",
            "Epoch 15323\n",
            "Epoch 15324\n",
            "Epoch 15325\n",
            "Epoch 15326\n",
            "Epoch 15327\n",
            "Epoch 15328\n",
            "Epoch 15329\n",
            "Epoch 15330\n",
            "Epoch 15331\n",
            "Epoch 15332\n",
            "Epoch 15333\n",
            "Epoch 15334\n",
            "Epoch 15335\n",
            "Epoch 15336\n",
            "Epoch 15337\n",
            "Epoch 15338\n",
            "Epoch 15339\n",
            "Epoch 15340\n",
            "Epoch 15341\n",
            "Epoch 15342\n",
            "Epoch 15343\n",
            "Epoch 15344\n",
            "Epoch 15345\n",
            "Epoch 15346\n",
            "Epoch 15347\n",
            "Epoch 15348\n",
            "Epoch 15349\n",
            "Epoch 15350\n",
            "Epoch 15351\n",
            "Epoch 15352\n",
            "Epoch 15353\n",
            "Epoch 15354\n",
            "Epoch 15355\n",
            "Epoch 15356\n",
            "Epoch 15357\n",
            "Epoch 15358\n",
            "Epoch 15359\n",
            "Epoch 15360\n",
            "Epoch 15361\n",
            "Epoch 15362\n",
            "Epoch 15363\n",
            "Epoch 15364\n",
            "Epoch 15365\n",
            "Epoch 15366\n",
            "Epoch 15367\n",
            "Epoch 15368\n",
            "Epoch 15369\n",
            "Epoch 15370\n",
            "Epoch 15371\n",
            "Epoch 15372\n",
            "Epoch 15373\n",
            "Epoch 15374\n",
            "Epoch 15375\n",
            "Epoch 15376\n",
            "Epoch 15377\n",
            "Epoch 15378\n",
            "Epoch 15379\n",
            "Epoch 15380\n",
            "Epoch 15381\n",
            "Epoch 15382\n",
            "Epoch 15383\n",
            "Epoch 15384\n",
            "Epoch 15385\n",
            "Epoch 15386\n",
            "Epoch 15387\n",
            "Epoch 15388\n",
            "Epoch 15389\n",
            "Epoch 15390\n",
            "Epoch 15391\n",
            "Epoch 15392\n",
            "Epoch 15393\n",
            "Epoch 15394\n",
            "Epoch 15395\n",
            "Epoch 15396\n",
            "Epoch 15397\n",
            "Epoch 15398\n",
            "Epoch 15399\n",
            "Epoch 15400\n",
            "Epoch 15401\n",
            "Epoch 15402\n",
            "Epoch 15403\n",
            "Epoch 15404\n",
            "Epoch 15405\n",
            "Epoch 15406\n",
            "Epoch 15407\n",
            "Epoch 15408\n",
            "Epoch 15409\n",
            "Epoch 15410\n",
            "Epoch 15411\n",
            "Epoch 15412\n",
            "Epoch 15413\n",
            "Epoch 15414\n",
            "Epoch 15415\n",
            "Epoch 15416\n",
            "Epoch 15417\n",
            "Epoch 15418\n",
            "Epoch 15419\n",
            "Epoch 15420\n",
            "Epoch 15421\n",
            "Epoch 15422\n",
            "Epoch 15423\n",
            "Epoch 15424\n",
            "Epoch 15425\n",
            "Epoch 15426\n",
            "Epoch 15427\n",
            "Epoch 15428\n",
            "Epoch 15429\n",
            "Epoch 15430\n",
            "Epoch 15431\n",
            "Epoch 15432\n",
            "Epoch 15433\n",
            "Epoch 15434\n",
            "Epoch 15435\n",
            "Epoch 15436\n",
            "Epoch 15437\n",
            "Epoch 15438\n",
            "Epoch 15439\n",
            "Epoch 15440\n",
            "Epoch 15441\n",
            "Epoch 15442\n",
            "Epoch 15443\n",
            "Epoch 15444\n",
            "Epoch 15445\n",
            "Epoch 15446\n",
            "Epoch 15447\n",
            "Epoch 15448\n",
            "Epoch 15449\n",
            "Epoch 15450\n",
            "Epoch 15451\n",
            "Epoch 15452\n",
            "Epoch 15453\n",
            "Epoch 15454\n",
            "Epoch 15455\n",
            "Epoch 15456\n",
            "Epoch 15457\n",
            "Epoch 15458\n",
            "Epoch 15459\n",
            "Epoch 15460\n",
            "Epoch 15461\n",
            "Epoch 15462\n",
            "Epoch 15463\n",
            "Epoch 15464\n",
            "Epoch 15465\n",
            "Epoch 15466\n",
            "Epoch 15467\n",
            "Epoch 15468\n",
            "Epoch 15469\n",
            "Epoch 15470\n",
            "Epoch 15471\n",
            "Epoch 15472\n",
            "Epoch 15473\n",
            "Epoch 15474\n",
            "Epoch 15475\n",
            "Epoch 15476\n",
            "Epoch 15477\n",
            "Epoch 15478\n",
            "Epoch 15479\n",
            "Epoch 15480\n",
            "Epoch 15481\n",
            "Epoch 15482\n",
            "Epoch 15483\n",
            "Epoch 15484\n",
            "Epoch 15485\n",
            "Epoch 15486\n",
            "Epoch 15487\n",
            "Epoch 15488\n",
            "Epoch 15489\n",
            "Epoch 15490\n",
            "Epoch 15491\n",
            "Epoch 15492\n",
            "Epoch 15493\n",
            "Epoch 15494\n",
            "Epoch 15495\n",
            "Epoch 15496\n",
            "Epoch 15497\n",
            "Epoch 15498\n",
            "Epoch 15499\n",
            "Epoch 15500\n",
            "Epoch 15501\n",
            "Epoch 15502\n",
            "Epoch 15503\n",
            "Epoch 15504\n",
            "Epoch 15505\n",
            "Epoch 15506\n",
            "Epoch 15507\n",
            "Epoch 15508\n",
            "Epoch 15509\n",
            "Epoch 15510\n",
            "Epoch 15511\n",
            "Epoch 15512\n",
            "Epoch 15513\n",
            "Epoch 15514\n",
            "Epoch 15515\n",
            "Epoch 15516\n",
            "Epoch 15517\n",
            "Epoch 15518\n",
            "Epoch 15519\n",
            "Epoch 15520\n",
            "Epoch 15521\n",
            "Epoch 15522\n",
            "Epoch 15523\n",
            "Epoch 15524\n",
            "Epoch 15525\n",
            "Epoch 15526\n",
            "Epoch 15527\n",
            "Epoch 15528\n",
            "Epoch 15529\n",
            "Epoch 15530\n",
            "Epoch 15531\n",
            "Epoch 15532\n",
            "Epoch 15533\n",
            "Epoch 15534\n",
            "Epoch 15535\n",
            "Epoch 15536\n",
            "Epoch 15537\n",
            "Epoch 15538\n",
            "Epoch 15539\n",
            "Epoch 15540\n",
            "Epoch 15541\n",
            "Epoch 15542\n",
            "Epoch 15543\n",
            "Epoch 15544\n",
            "Epoch 15545\n",
            "Epoch 15546\n",
            "Epoch 15547\n",
            "Epoch 15548\n",
            "Epoch 15549\n",
            "Epoch 15550\n",
            "Epoch 15551\n",
            "Epoch 15552\n",
            "Epoch 15553\n",
            "Epoch 15554\n",
            "Epoch 15555\n",
            "Epoch 15556\n",
            "Epoch 15557\n",
            "Epoch 15558\n",
            "Epoch 15559\n",
            "Epoch 15560\n",
            "Epoch 15561\n",
            "Epoch 15562\n",
            "Epoch 15563\n",
            "Epoch 15564\n",
            "Epoch 15565\n",
            "Epoch 15566\n",
            "Epoch 15567\n",
            "Epoch 15568\n",
            "Epoch 15569\n",
            "Epoch 15570\n",
            "Epoch 15571\n",
            "Epoch 15572\n",
            "Epoch 15573\n",
            "Epoch 15574\n",
            "Epoch 15575\n",
            "Epoch 15576\n",
            "Epoch 15577\n",
            "Epoch 15578\n",
            "Epoch 15579\n",
            "Epoch 15580\n",
            "Epoch 15581\n",
            "Epoch 15582\n",
            "Epoch 15583\n",
            "Epoch 15584\n",
            "Epoch 15585\n",
            "Epoch 15586\n",
            "Epoch 15587\n",
            "Epoch 15588\n",
            "Epoch 15589\n",
            "Epoch 15590\n",
            "Epoch 15591\n",
            "Epoch 15592\n",
            "Epoch 15593\n",
            "Epoch 15594\n",
            "Epoch 15595\n",
            "Epoch 15596\n",
            "Epoch 15597\n",
            "Epoch 15598\n",
            "Epoch 15599\n",
            "Epoch 15600\n",
            "Epoch 15601\n",
            "Epoch 15602\n",
            "Epoch 15603\n",
            "Epoch 15604\n",
            "Epoch 15605\n",
            "Epoch 15606\n",
            "Epoch 15607\n",
            "Epoch 15608\n",
            "Epoch 15609\n",
            "Epoch 15610\n",
            "Epoch 15611\n",
            "Epoch 15612\n",
            "Epoch 15613\n",
            "Epoch 15614\n",
            "Epoch 15615\n",
            "Epoch 15616\n",
            "Epoch 15617\n",
            "Epoch 15618\n",
            "Epoch 15619\n",
            "Epoch 15620\n",
            "Epoch 15621\n",
            "Epoch 15622\n",
            "Epoch 15623\n",
            "Epoch 15624\n",
            "Epoch 15625\n",
            "Epoch 15626\n",
            "Epoch 15627\n",
            "Epoch 15628\n",
            "Epoch 15629\n",
            "Epoch 15630\n",
            "Epoch 15631\n",
            "Epoch 15632\n",
            "Epoch 15633\n",
            "Epoch 15634\n",
            "Epoch 15635\n",
            "Epoch 15636\n",
            "Epoch 15637\n",
            "Epoch 15638\n",
            "Epoch 15639\n",
            "Epoch 15640\n",
            "Epoch 15641\n",
            "Epoch 15642\n",
            "Epoch 15643\n",
            "Epoch 15644\n",
            "Epoch 15645\n",
            "Epoch 15646\n",
            "Epoch 15647\n",
            "Epoch 15648\n",
            "Epoch 15649\n",
            "Epoch 15650\n",
            "Epoch 15651\n",
            "Epoch 15652\n",
            "Epoch 15653\n",
            "Epoch 15654\n",
            "Epoch 15655\n",
            "Epoch 15656\n",
            "Epoch 15657\n",
            "Epoch 15658\n",
            "Epoch 15659\n",
            "Epoch 15660\n",
            "Epoch 15661\n",
            "Epoch 15662\n",
            "Epoch 15663\n",
            "Epoch 15664\n",
            "Epoch 15665\n",
            "Epoch 15666\n",
            "Epoch 15667\n",
            "Epoch 15668\n",
            "Epoch 15669\n",
            "Epoch 15670\n",
            "Epoch 15671\n",
            "Epoch 15672\n",
            "Epoch 15673\n",
            "Epoch 15674\n",
            "Epoch 15675\n",
            "Epoch 15676\n",
            "Epoch 15677\n",
            "Epoch 15678\n",
            "Epoch 15679\n",
            "Epoch 15680\n",
            "Epoch 15681\n",
            "Epoch 15682\n",
            "Epoch 15683\n",
            "Epoch 15684\n",
            "Epoch 15685\n",
            "Epoch 15686\n",
            "Epoch 15687\n",
            "Epoch 15688\n",
            "Epoch 15689\n",
            "Epoch 15690\n",
            "Epoch 15691\n",
            "Epoch 15692\n",
            "Epoch 15693\n",
            "Epoch 15694\n",
            "Epoch 15695\n",
            "Epoch 15696\n",
            "Epoch 15697\n",
            "Epoch 15698\n",
            "Epoch 15699\n",
            "Epoch 15700\n",
            "Epoch 15701\n",
            "Epoch 15702\n",
            "Epoch 15703\n",
            "Epoch 15704\n",
            "Epoch 15705\n",
            "Epoch 15706\n",
            "Epoch 15707\n",
            "Epoch 15708\n",
            "Epoch 15709\n",
            "Epoch 15710\n",
            "Epoch 15711\n",
            "Epoch 15712\n",
            "Epoch 15713\n",
            "Epoch 15714\n",
            "Epoch 15715\n",
            "Epoch 15716\n",
            "Epoch 15717\n",
            "Epoch 15718\n",
            "Epoch 15719\n",
            "Epoch 15720\n",
            "Epoch 15721\n",
            "Epoch 15722\n",
            "Epoch 15723\n",
            "Epoch 15724\n",
            "Epoch 15725\n",
            "Epoch 15726\n",
            "Epoch 15727\n",
            "Epoch 15728\n",
            "Epoch 15729\n",
            "Epoch 15730\n",
            "Epoch 15731\n",
            "Epoch 15732\n",
            "Epoch 15733\n",
            "Epoch 15734\n",
            "Epoch 15735\n",
            "Epoch 15736\n",
            "Epoch 15737\n",
            "Epoch 15738\n",
            "Epoch 15739\n",
            "Epoch 15740\n",
            "Epoch 15741\n",
            "Epoch 15742\n",
            "Epoch 15743\n",
            "Epoch 15744\n",
            "Epoch 15745\n",
            "Epoch 15746\n",
            "Epoch 15747\n",
            "Epoch 15748\n",
            "Epoch 15749\n",
            "Epoch 15750\n",
            "Epoch 15751\n",
            "Epoch 15752\n",
            "Epoch 15753\n",
            "Epoch 15754\n",
            "Epoch 15755\n",
            "Epoch 15756\n",
            "Epoch 15757\n",
            "Epoch 15758\n",
            "Epoch 15759\n",
            "Epoch 15760\n",
            "Epoch 15761\n",
            "Epoch 15762\n",
            "Epoch 15763\n",
            "Epoch 15764\n",
            "Epoch 15765\n",
            "Epoch 15766\n",
            "Epoch 15767\n",
            "Epoch 15768\n",
            "Epoch 15769\n",
            "Epoch 15770\n",
            "Epoch 15771\n",
            "Epoch 15772\n",
            "Epoch 15773\n",
            "Epoch 15774\n",
            "Epoch 15775\n",
            "Epoch 15776\n",
            "Epoch 15777\n",
            "Epoch 15778\n",
            "Epoch 15779\n",
            "Epoch 15780\n",
            "Epoch 15781\n",
            "Epoch 15782\n",
            "Epoch 15783\n",
            "Epoch 15784\n",
            "Epoch 15785\n",
            "Epoch 15786\n",
            "Epoch 15787\n",
            "Epoch 15788\n",
            "Epoch 15789\n",
            "Epoch 15790\n",
            "Epoch 15791\n",
            "Epoch 15792\n",
            "Epoch 15793\n",
            "Epoch 15794\n",
            "Epoch 15795\n",
            "Epoch 15796\n",
            "Epoch 15797\n",
            "Epoch 15798\n",
            "Epoch 15799\n",
            "Epoch 15800\n",
            "Epoch 15801\n",
            "Epoch 15802\n",
            "Epoch 15803\n",
            "Epoch 15804\n",
            "Epoch 15805\n",
            "Epoch 15806\n",
            "Epoch 15807\n",
            "Epoch 15808\n",
            "Epoch 15809\n",
            "Epoch 15810\n",
            "Epoch 15811\n",
            "Epoch 15812\n",
            "Epoch 15813\n",
            "Epoch 15814\n",
            "Epoch 15815\n",
            "Epoch 15816\n",
            "Epoch 15817\n",
            "Epoch 15818\n",
            "Epoch 15819\n",
            "Epoch 15820\n",
            "Epoch 15821\n",
            "Epoch 15822\n",
            "Epoch 15823\n",
            "Epoch 15824\n",
            "Epoch 15825\n",
            "Epoch 15826\n",
            "Epoch 15827\n",
            "Epoch 15828\n",
            "Epoch 15829\n",
            "Epoch 15830\n",
            "Epoch 15831\n",
            "Epoch 15832\n",
            "Epoch 15833\n",
            "Epoch 15834\n",
            "Epoch 15835\n",
            "Epoch 15836\n",
            "Epoch 15837\n",
            "Epoch 15838\n",
            "Epoch 15839\n",
            "Epoch 15840\n",
            "Epoch 15841\n",
            "Epoch 15842\n",
            "Epoch 15843\n",
            "Epoch 15844\n",
            "Epoch 15845\n",
            "Epoch 15846\n",
            "Epoch 15847\n",
            "Epoch 15848\n",
            "Epoch 15849\n",
            "Epoch 15850\n",
            "Epoch 15851\n",
            "Epoch 15852\n",
            "Epoch 15853\n",
            "Epoch 15854\n",
            "Epoch 15855\n",
            "Epoch 15856\n",
            "Epoch 15857\n",
            "Epoch 15858\n",
            "Epoch 15859\n",
            "Epoch 15860\n",
            "Epoch 15861\n",
            "Epoch 15862\n",
            "Epoch 15863\n",
            "Epoch 15864\n",
            "Epoch 15865\n",
            "Epoch 15866\n",
            "Epoch 15867\n",
            "Epoch 15868\n",
            "Epoch 15869\n",
            "Epoch 15870\n",
            "Epoch 15871\n",
            "Epoch 15872\n",
            "Epoch 15873\n",
            "Epoch 15874\n",
            "Epoch 15875\n",
            "Epoch 15876\n",
            "Epoch 15877\n",
            "Epoch 15878\n",
            "Epoch 15879\n",
            "Epoch 15880\n",
            "Epoch 15881\n",
            "Epoch 15882\n",
            "Epoch 15883\n",
            "Epoch 15884\n",
            "Epoch 15885\n",
            "Epoch 15886\n",
            "Epoch 15887\n",
            "Epoch 15888\n",
            "Epoch 15889\n",
            "Epoch 15890\n",
            "Epoch 15891\n",
            "Epoch 15892\n",
            "Epoch 15893\n",
            "Epoch 15894\n",
            "Epoch 15895\n",
            "Epoch 15896\n",
            "Epoch 15897\n",
            "Epoch 15898\n",
            "Epoch 15899\n",
            "Epoch 15900\n",
            "Epoch 15901\n",
            "Epoch 15902\n",
            "Epoch 15903\n",
            "Epoch 15904\n",
            "Epoch 15905\n",
            "Epoch 15906\n",
            "Epoch 15907\n",
            "Epoch 15908\n",
            "Epoch 15909\n",
            "Epoch 15910\n",
            "Epoch 15911\n",
            "Epoch 15912\n",
            "Epoch 15913\n",
            "Epoch 15914\n",
            "Epoch 15915\n",
            "Epoch 15916\n",
            "Epoch 15917\n",
            "Epoch 15918\n",
            "Epoch 15919\n",
            "Epoch 15920\n",
            "Epoch 15921\n",
            "Epoch 15922\n",
            "Epoch 15923\n",
            "Epoch 15924\n",
            "Epoch 15925\n",
            "Epoch 15926\n",
            "Epoch 15927\n",
            "Epoch 15928\n",
            "Epoch 15929\n",
            "Epoch 15930\n",
            "Epoch 15931\n",
            "Epoch 15932\n",
            "Epoch 15933\n",
            "Epoch 15934\n",
            "Epoch 15935\n",
            "Epoch 15936\n",
            "Epoch 15937\n",
            "Epoch 15938\n",
            "Epoch 15939\n",
            "Epoch 15940\n",
            "Epoch 15941\n",
            "Epoch 15942\n",
            "Epoch 15943\n",
            "Epoch 15944\n",
            "Epoch 15945\n",
            "Epoch 15946\n",
            "Epoch 15947\n",
            "Epoch 15948\n",
            "Epoch 15949\n",
            "Epoch 15950\n",
            "Epoch 15951\n",
            "Epoch 15952\n",
            "Epoch 15953\n",
            "Epoch 15954\n",
            "Epoch 15955\n",
            "Epoch 15956\n",
            "Epoch 15957\n",
            "Epoch 15958\n",
            "Epoch 15959\n",
            "Epoch 15960\n",
            "Epoch 15961\n",
            "Epoch 15962\n",
            "Epoch 15963\n",
            "Epoch 15964\n",
            "Epoch 15965\n",
            "Epoch 15966\n",
            "Epoch 15967\n",
            "Epoch 15968\n",
            "Epoch 15969\n",
            "Epoch 15970\n",
            "Epoch 15971\n",
            "Epoch 15972\n",
            "Epoch 15973\n",
            "Epoch 15974\n",
            "Epoch 15975\n",
            "Epoch 15976\n",
            "Epoch 15977\n",
            "Epoch 15978\n",
            "Epoch 15979\n",
            "Epoch 15980\n",
            "Epoch 15981\n",
            "Epoch 15982\n",
            "Epoch 15983\n",
            "Epoch 15984\n",
            "Epoch 15985\n",
            "Epoch 15986\n",
            "Epoch 15987\n",
            "Epoch 15988\n",
            "Epoch 15989\n",
            "Epoch 15990\n",
            "Epoch 15991\n",
            "Epoch 15992\n",
            "Epoch 15993\n",
            "Epoch 15994\n",
            "Epoch 15995\n",
            "Epoch 15996\n",
            "Epoch 15997\n",
            "Epoch 15998\n",
            "Epoch 15999\n",
            "Epoch 16000\n",
            "Epoch 16001\n",
            "Epoch 16002\n",
            "Epoch 16003\n",
            "Epoch 16004\n",
            "Epoch 16005\n",
            "Epoch 16006\n",
            "Epoch 16007\n",
            "Epoch 16008\n",
            "Epoch 16009\n",
            "Epoch 16010\n",
            "Epoch 16011\n",
            "Epoch 16012\n",
            "Epoch 16013\n",
            "Epoch 16014\n",
            "Epoch 16015\n",
            "Epoch 16016\n",
            "Epoch 16017\n",
            "Epoch 16018\n",
            "Epoch 16019\n",
            "Epoch 16020\n",
            "Epoch 16021\n",
            "Epoch 16022\n",
            "Epoch 16023\n",
            "Epoch 16024\n",
            "Epoch 16025\n",
            "Epoch 16026\n",
            "Epoch 16027\n",
            "Epoch 16028\n",
            "Epoch 16029\n",
            "Epoch 16030\n",
            "Epoch 16031\n",
            "Epoch 16032\n",
            "Epoch 16033\n",
            "Epoch 16034\n",
            "Epoch 16035\n",
            "Epoch 16036\n",
            "Epoch 16037\n",
            "Epoch 16038\n",
            "Epoch 16039\n",
            "Epoch 16040\n",
            "Epoch 16041\n",
            "Epoch 16042\n",
            "Epoch 16043\n",
            "Epoch 16044\n",
            "Epoch 16045\n",
            "Epoch 16046\n",
            "Epoch 16047\n",
            "Epoch 16048\n",
            "Epoch 16049\n",
            "Epoch 16050\n",
            "Epoch 16051\n",
            "Epoch 16052\n",
            "Epoch 16053\n",
            "Epoch 16054\n",
            "Epoch 16055\n",
            "Epoch 16056\n",
            "Epoch 16057\n",
            "Epoch 16058\n",
            "Epoch 16059\n",
            "Epoch 16060\n",
            "Epoch 16061\n",
            "Epoch 16062\n",
            "Epoch 16063\n",
            "Epoch 16064\n",
            "Epoch 16065\n",
            "Epoch 16066\n",
            "Epoch 16067\n",
            "Epoch 16068\n",
            "Epoch 16069\n",
            "Epoch 16070\n",
            "Epoch 16071\n",
            "Epoch 16072\n",
            "Epoch 16073\n",
            "Epoch 16074\n",
            "Epoch 16075\n",
            "Epoch 16076\n",
            "Epoch 16077\n",
            "Epoch 16078\n",
            "Epoch 16079\n",
            "Epoch 16080\n",
            "Epoch 16081\n",
            "Epoch 16082\n",
            "Epoch 16083\n",
            "Epoch 16084\n",
            "Epoch 16085\n",
            "Epoch 16086\n",
            "Epoch 16087\n",
            "Epoch 16088\n",
            "Epoch 16089\n",
            "Epoch 16090\n",
            "Epoch 16091\n",
            "Epoch 16092\n",
            "Epoch 16093\n",
            "Epoch 16094\n",
            "Epoch 16095\n",
            "Epoch 16096\n",
            "Epoch 16097\n",
            "Epoch 16098\n",
            "Epoch 16099\n",
            "Epoch 16100\n",
            "Epoch 16101\n",
            "Epoch 16102\n",
            "Epoch 16103\n",
            "Epoch 16104\n",
            "Epoch 16105\n",
            "Epoch 16106\n",
            "Epoch 16107\n",
            "Epoch 16108\n",
            "Epoch 16109\n",
            "Epoch 16110\n",
            "Epoch 16111\n",
            "Epoch 16112\n",
            "Epoch 16113\n",
            "Epoch 16114\n",
            "Epoch 16115\n",
            "Epoch 16116\n",
            "Epoch 16117\n",
            "Epoch 16118\n",
            "Epoch 16119\n",
            "Epoch 16120\n",
            "Epoch 16121\n",
            "Epoch 16122\n",
            "Epoch 16123\n",
            "Epoch 16124\n",
            "Epoch 16125\n",
            "Epoch 16126\n",
            "Epoch 16127\n",
            "Epoch 16128\n",
            "Epoch 16129\n",
            "Epoch 16130\n",
            "Epoch 16131\n",
            "Epoch 16132\n",
            "Epoch 16133\n",
            "Epoch 16134\n",
            "Epoch 16135\n",
            "Epoch 16136\n",
            "Epoch 16137\n",
            "Epoch 16138\n",
            "Epoch 16139\n",
            "Epoch 16140\n",
            "Epoch 16141\n",
            "Epoch 16142\n",
            "Epoch 16143\n",
            "Epoch 16144\n",
            "Epoch 16145\n",
            "Epoch 16146\n",
            "Epoch 16147\n",
            "Epoch 16148\n",
            "Epoch 16149\n",
            "Epoch 16150\n",
            "Epoch 16151\n",
            "Epoch 16152\n",
            "Epoch 16153\n",
            "Epoch 16154\n",
            "Epoch 16155\n",
            "Epoch 16156\n",
            "Epoch 16157\n",
            "Epoch 16158\n",
            "Epoch 16159\n",
            "Epoch 16160\n",
            "Epoch 16161\n",
            "Epoch 16162\n",
            "Epoch 16163\n",
            "Epoch 16164\n",
            "Epoch 16165\n",
            "Epoch 16166\n",
            "Epoch 16167\n",
            "Epoch 16168\n",
            "Epoch 16169\n",
            "Epoch 16170\n",
            "Epoch 16171\n",
            "Epoch 16172\n",
            "Epoch 16173\n",
            "Epoch 16174\n",
            "Epoch 16175\n",
            "Epoch 16176\n",
            "Epoch 16177\n",
            "Epoch 16178\n",
            "Epoch 16179\n",
            "Epoch 16180\n",
            "Epoch 16181\n",
            "Epoch 16182\n",
            "Epoch 16183\n",
            "Epoch 16184\n",
            "Epoch 16185\n",
            "Epoch 16186\n",
            "Epoch 16187\n",
            "Epoch 16188\n",
            "Epoch 16189\n",
            "Epoch 16190\n",
            "Epoch 16191\n",
            "Epoch 16192\n",
            "Epoch 16193\n",
            "Epoch 16194\n",
            "Epoch 16195\n",
            "Epoch 16196\n",
            "Epoch 16197\n",
            "Epoch 16198\n",
            "Epoch 16199\n",
            "Epoch 16200\n",
            "Epoch 16201\n",
            "Epoch 16202\n",
            "Epoch 16203\n",
            "Epoch 16204\n",
            "Epoch 16205\n",
            "Epoch 16206\n",
            "Epoch 16207\n",
            "Epoch 16208\n",
            "Epoch 16209\n",
            "Epoch 16210\n",
            "Epoch 16211\n",
            "Epoch 16212\n",
            "Epoch 16213\n",
            "Epoch 16214\n",
            "Epoch 16215\n",
            "Epoch 16216\n",
            "Epoch 16217\n",
            "Epoch 16218\n",
            "Epoch 16219\n",
            "Epoch 16220\n",
            "Epoch 16221\n",
            "Epoch 16222\n",
            "Epoch 16223\n",
            "Epoch 16224\n",
            "Epoch 16225\n",
            "Epoch 16226\n",
            "Epoch 16227\n",
            "Epoch 16228\n",
            "Epoch 16229\n",
            "Epoch 16230\n",
            "Epoch 16231\n",
            "Epoch 16232\n",
            "Epoch 16233\n",
            "Epoch 16234\n",
            "Epoch 16235\n",
            "Epoch 16236\n",
            "Epoch 16237\n",
            "Epoch 16238\n",
            "Epoch 16239\n",
            "Epoch 16240\n",
            "Epoch 16241\n",
            "Epoch 16242\n",
            "Epoch 16243\n",
            "Epoch 16244\n",
            "Epoch 16245\n",
            "Epoch 16246\n",
            "Epoch 16247\n",
            "Epoch 16248\n",
            "Epoch 16249\n",
            "Epoch 16250\n",
            "Epoch 16251\n",
            "Epoch 16252\n",
            "Epoch 16253\n",
            "Epoch 16254\n",
            "Epoch 16255\n",
            "Epoch 16256\n",
            "Epoch 16257\n",
            "Epoch 16258\n",
            "Epoch 16259\n",
            "Epoch 16260\n",
            "Epoch 16261\n",
            "Epoch 16262\n",
            "Epoch 16263\n",
            "Epoch 16264\n",
            "Epoch 16265\n",
            "Epoch 16266\n",
            "Epoch 16267\n",
            "Epoch 16268\n",
            "Epoch 16269\n",
            "Epoch 16270\n",
            "Epoch 16271\n",
            "Epoch 16272\n",
            "Epoch 16273\n",
            "Epoch 16274\n",
            "Epoch 16275\n",
            "Epoch 16276\n",
            "Epoch 16277\n",
            "Epoch 16278\n",
            "Epoch 16279\n",
            "Epoch 16280\n",
            "Epoch 16281\n",
            "Epoch 16282\n",
            "Epoch 16283\n",
            "Epoch 16284\n",
            "Epoch 16285\n",
            "Epoch 16286\n",
            "Epoch 16287\n",
            "Epoch 16288\n",
            "Epoch 16289\n",
            "Epoch 16290\n",
            "Epoch 16291\n",
            "Epoch 16292\n",
            "Epoch 16293\n",
            "Epoch 16294\n",
            "Epoch 16295\n",
            "Epoch 16296\n",
            "Epoch 16297\n",
            "Epoch 16298\n",
            "Epoch 16299\n",
            "Epoch 16300\n",
            "Epoch 16301\n",
            "Epoch 16302\n",
            "Epoch 16303\n",
            "Epoch 16304\n",
            "Epoch 16305\n",
            "Epoch 16306\n",
            "Epoch 16307\n",
            "Epoch 16308\n",
            "Epoch 16309\n",
            "Epoch 16310\n",
            "Epoch 16311\n",
            "Epoch 16312\n",
            "Epoch 16313\n",
            "Epoch 16314\n",
            "Epoch 16315\n",
            "Epoch 16316\n",
            "Epoch 16317\n",
            "Epoch 16318\n",
            "Epoch 16319\n",
            "Epoch 16320\n",
            "Epoch 16321\n",
            "Epoch 16322\n",
            "Epoch 16323\n",
            "Epoch 16324\n",
            "Epoch 16325\n",
            "Epoch 16326\n",
            "Epoch 16327\n",
            "Epoch 16328\n",
            "Epoch 16329\n",
            "Epoch 16330\n",
            "Epoch 16331\n",
            "Epoch 16332\n",
            "Epoch 16333\n",
            "Epoch 16334\n",
            "Epoch 16335\n",
            "Epoch 16336\n",
            "Epoch 16337\n",
            "Epoch 16338\n",
            "Epoch 16339\n",
            "Epoch 16340\n",
            "Epoch 16341\n",
            "Epoch 16342\n",
            "Epoch 16343\n",
            "Epoch 16344\n",
            "Epoch 16345\n",
            "Epoch 16346\n",
            "Epoch 16347\n",
            "Epoch 16348\n",
            "Epoch 16349\n",
            "Epoch 16350\n",
            "Epoch 16351\n",
            "Epoch 16352\n",
            "Epoch 16353\n",
            "Epoch 16354\n",
            "Epoch 16355\n",
            "Epoch 16356\n",
            "Epoch 16357\n",
            "Epoch 16358\n",
            "Epoch 16359\n",
            "Epoch 16360\n",
            "Epoch 16361\n",
            "Epoch 16362\n",
            "Epoch 16363\n",
            "Epoch 16364\n",
            "Epoch 16365\n",
            "Epoch 16366\n",
            "Epoch 16367\n",
            "Epoch 16368\n",
            "Epoch 16369\n",
            "Epoch 16370\n",
            "Epoch 16371\n",
            "Epoch 16372\n",
            "Epoch 16373\n",
            "Epoch 16374\n",
            "Epoch 16375\n",
            "Epoch 16376\n",
            "Epoch 16377\n",
            "Epoch 16378\n",
            "Epoch 16379\n",
            "Epoch 16380\n",
            "Epoch 16381\n",
            "Epoch 16382\n",
            "Epoch 16383\n",
            "Epoch 16384\n",
            "Epoch 16385\n",
            "Epoch 16386\n",
            "Epoch 16387\n",
            "Epoch 16388\n",
            "Epoch 16389\n",
            "Epoch 16390\n",
            "Epoch 16391\n",
            "Epoch 16392\n",
            "Epoch 16393\n",
            "Epoch 16394\n",
            "Epoch 16395\n",
            "Epoch 16396\n",
            "Epoch 16397\n",
            "Epoch 16398\n",
            "Epoch 16399\n",
            "Epoch 16400\n",
            "Epoch 16401\n",
            "Epoch 16402\n",
            "Epoch 16403\n",
            "Epoch 16404\n",
            "Epoch 16405\n",
            "Epoch 16406\n",
            "Epoch 16407\n",
            "Epoch 16408\n",
            "Epoch 16409\n",
            "Epoch 16410\n",
            "Epoch 16411\n",
            "Epoch 16412\n",
            "Epoch 16413\n",
            "Epoch 16414\n",
            "Epoch 16415\n",
            "Epoch 16416\n",
            "Epoch 16417\n",
            "Epoch 16418\n",
            "Epoch 16419\n",
            "Epoch 16420\n",
            "Epoch 16421\n",
            "Epoch 16422\n",
            "Epoch 16423\n",
            "Epoch 16424\n",
            "Epoch 16425\n",
            "Epoch 16426\n",
            "Epoch 16427\n",
            "Epoch 16428\n",
            "Epoch 16429\n",
            "Epoch 16430\n",
            "Epoch 16431\n",
            "Epoch 16432\n",
            "Epoch 16433\n",
            "Epoch 16434\n",
            "Epoch 16435\n",
            "Epoch 16436\n",
            "Epoch 16437\n",
            "Epoch 16438\n",
            "Epoch 16439\n",
            "Epoch 16440\n",
            "Epoch 16441\n",
            "Epoch 16442\n",
            "Epoch 16443\n",
            "Epoch 16444\n",
            "Epoch 16445\n",
            "Epoch 16446\n",
            "Epoch 16447\n",
            "Epoch 16448\n",
            "Epoch 16449\n",
            "Epoch 16450\n",
            "Epoch 16451\n",
            "Epoch 16452\n",
            "Epoch 16453\n",
            "Epoch 16454\n",
            "Epoch 16455\n",
            "Epoch 16456\n",
            "Epoch 16457\n",
            "Epoch 16458\n",
            "Epoch 16459\n",
            "Epoch 16460\n",
            "Epoch 16461\n",
            "Epoch 16462\n",
            "Epoch 16463\n",
            "Epoch 16464\n",
            "Epoch 16465\n",
            "Epoch 16466\n",
            "Epoch 16467\n",
            "Epoch 16468\n",
            "Epoch 16469\n",
            "Epoch 16470\n",
            "Epoch 16471\n",
            "Epoch 16472\n",
            "Epoch 16473\n",
            "Epoch 16474\n",
            "Epoch 16475\n",
            "Epoch 16476\n",
            "Epoch 16477\n",
            "Epoch 16478\n",
            "Epoch 16479\n",
            "Epoch 16480\n",
            "Epoch 16481\n",
            "Epoch 16482\n",
            "Epoch 16483\n",
            "Epoch 16484\n",
            "Epoch 16485\n",
            "Epoch 16486\n",
            "Epoch 16487\n",
            "Epoch 16488\n",
            "Epoch 16489\n",
            "Epoch 16490\n",
            "Epoch 16491\n",
            "Epoch 16492\n",
            "Epoch 16493\n",
            "Epoch 16494\n",
            "Epoch 16495\n",
            "Epoch 16496\n",
            "Epoch 16497\n",
            "Epoch 16498\n",
            "Epoch 16499\n",
            "Epoch 16500\n",
            "Epoch 16501\n",
            "Epoch 16502\n",
            "Epoch 16503\n",
            "Epoch 16504\n",
            "Epoch 16505\n",
            "Epoch 16506\n",
            "Epoch 16507\n",
            "Epoch 16508\n",
            "Epoch 16509\n",
            "Epoch 16510\n",
            "Epoch 16511\n",
            "Epoch 16512\n",
            "Epoch 16513\n",
            "Epoch 16514\n",
            "Epoch 16515\n",
            "Epoch 16516\n",
            "Epoch 16517\n",
            "Epoch 16518\n",
            "Epoch 16519\n",
            "Epoch 16520\n",
            "Epoch 16521\n",
            "Epoch 16522\n",
            "Epoch 16523\n",
            "Epoch 16524\n",
            "Epoch 16525\n",
            "Epoch 16526\n",
            "Epoch 16527\n",
            "Epoch 16528\n",
            "Epoch 16529\n",
            "Epoch 16530\n",
            "Epoch 16531\n",
            "Epoch 16532\n",
            "Epoch 16533\n",
            "Epoch 16534\n",
            "Epoch 16535\n",
            "Epoch 16536\n",
            "Epoch 16537\n",
            "Epoch 16538\n",
            "Epoch 16539\n",
            "Epoch 16540\n",
            "Epoch 16541\n",
            "Epoch 16542\n",
            "Epoch 16543\n",
            "Epoch 16544\n",
            "Epoch 16545\n",
            "Epoch 16546\n",
            "Epoch 16547\n",
            "Epoch 16548\n",
            "Epoch 16549\n",
            "Epoch 16550\n",
            "Epoch 16551\n",
            "Epoch 16552\n",
            "Epoch 16553\n",
            "Epoch 16554\n",
            "Epoch 16555\n",
            "Epoch 16556\n",
            "Epoch 16557\n",
            "Epoch 16558\n",
            "Epoch 16559\n",
            "Epoch 16560\n",
            "Epoch 16561\n",
            "Epoch 16562\n",
            "Epoch 16563\n",
            "Epoch 16564\n",
            "Epoch 16565\n",
            "Epoch 16566\n",
            "Epoch 16567\n",
            "Epoch 16568\n",
            "Epoch 16569\n",
            "Epoch 16570\n",
            "Epoch 16571\n",
            "Epoch 16572\n",
            "Epoch 16573\n",
            "Epoch 16574\n",
            "Epoch 16575\n",
            "Epoch 16576\n",
            "Epoch 16577\n",
            "Epoch 16578\n",
            "Epoch 16579\n",
            "Epoch 16580\n",
            "Epoch 16581\n",
            "Epoch 16582\n",
            "Epoch 16583\n",
            "Epoch 16584\n",
            "Epoch 16585\n",
            "Epoch 16586\n",
            "Epoch 16587\n",
            "Epoch 16588\n",
            "Epoch 16589\n",
            "Epoch 16590\n",
            "Epoch 16591\n",
            "Epoch 16592\n",
            "Epoch 16593\n",
            "Epoch 16594\n",
            "Epoch 16595\n",
            "Epoch 16596\n",
            "Epoch 16597\n",
            "Epoch 16598\n",
            "Epoch 16599\n",
            "Epoch 16600\n",
            "Epoch 16601\n",
            "Epoch 16602\n",
            "Epoch 16603\n",
            "Epoch 16604\n",
            "Epoch 16605\n",
            "Epoch 16606\n",
            "Epoch 16607\n",
            "Epoch 16608\n",
            "Epoch 16609\n",
            "Epoch 16610\n",
            "Epoch 16611\n",
            "Epoch 16612\n",
            "Epoch 16613\n",
            "Epoch 16614\n",
            "Epoch 16615\n",
            "Epoch 16616\n",
            "Epoch 16617\n",
            "Epoch 16618\n",
            "Epoch 16619\n",
            "Epoch 16620\n",
            "Epoch 16621\n",
            "Epoch 16622\n",
            "Epoch 16623\n",
            "Epoch 16624\n",
            "Epoch 16625\n",
            "Epoch 16626\n",
            "Epoch 16627\n",
            "Epoch 16628\n",
            "Epoch 16629\n",
            "Epoch 16630\n",
            "Epoch 16631\n",
            "Epoch 16632\n",
            "Epoch 16633\n",
            "Epoch 16634\n",
            "Epoch 16635\n",
            "Epoch 16636\n",
            "Epoch 16637\n",
            "Epoch 16638\n",
            "Epoch 16639\n",
            "Epoch 16640\n",
            "Epoch 16641\n",
            "Epoch 16642\n",
            "Epoch 16643\n",
            "Epoch 16644\n",
            "Epoch 16645\n",
            "Epoch 16646\n",
            "Epoch 16647\n",
            "Epoch 16648\n",
            "Epoch 16649\n",
            "Epoch 16650\n",
            "Epoch 16651\n",
            "Epoch 16652\n",
            "Epoch 16653\n",
            "Epoch 16654\n",
            "Epoch 16655\n",
            "Epoch 16656\n",
            "Epoch 16657\n",
            "Epoch 16658\n",
            "Epoch 16659\n",
            "Epoch 16660\n",
            "Epoch 16661\n",
            "Epoch 16662\n",
            "Epoch 16663\n",
            "Epoch 16664\n",
            "Epoch 16665\n",
            "Epoch 16666\n",
            "Epoch 16667\n",
            "Epoch 16668\n",
            "Epoch 16669\n",
            "Epoch 16670\n",
            "Epoch 16671\n",
            "Epoch 16672\n",
            "Epoch 16673\n",
            "Epoch 16674\n",
            "Epoch 16675\n",
            "Epoch 16676\n",
            "Epoch 16677\n",
            "Epoch 16678\n",
            "Epoch 16679\n",
            "Epoch 16680\n",
            "Epoch 16681\n",
            "Epoch 16682\n",
            "Epoch 16683\n",
            "Epoch 16684\n",
            "Epoch 16685\n",
            "Epoch 16686\n",
            "Epoch 16687\n",
            "Epoch 16688\n",
            "Epoch 16689\n",
            "Epoch 16690\n",
            "Epoch 16691\n",
            "Epoch 16692\n",
            "Epoch 16693\n",
            "Epoch 16694\n",
            "Epoch 16695\n",
            "Epoch 16696\n",
            "Epoch 16697\n",
            "Epoch 16698\n",
            "Epoch 16699\n",
            "Epoch 16700\n",
            "Epoch 16701\n",
            "Epoch 16702\n",
            "Epoch 16703\n",
            "Epoch 16704\n",
            "Epoch 16705\n",
            "Epoch 16706\n",
            "Epoch 16707\n",
            "Epoch 16708\n",
            "Epoch 16709\n",
            "Epoch 16710\n",
            "Epoch 16711\n",
            "Epoch 16712\n",
            "Epoch 16713\n",
            "Epoch 16714\n",
            "Epoch 16715\n",
            "Epoch 16716\n",
            "Epoch 16717\n",
            "Epoch 16718\n",
            "Epoch 16719\n",
            "Epoch 16720\n",
            "Epoch 16721\n",
            "Epoch 16722\n",
            "Epoch 16723\n",
            "Epoch 16724\n",
            "Epoch 16725\n",
            "Epoch 16726\n",
            "Epoch 16727\n",
            "Epoch 16728\n",
            "Epoch 16729\n",
            "Epoch 16730\n",
            "Epoch 16731\n",
            "Epoch 16732\n",
            "Epoch 16733\n",
            "Epoch 16734\n",
            "Epoch 16735\n",
            "Epoch 16736\n",
            "Epoch 16737\n",
            "Epoch 16738\n",
            "Epoch 16739\n",
            "Epoch 16740\n",
            "Epoch 16741\n",
            "Epoch 16742\n",
            "Epoch 16743\n",
            "Epoch 16744\n",
            "Epoch 16745\n",
            "Epoch 16746\n",
            "Epoch 16747\n",
            "Epoch 16748\n",
            "Epoch 16749\n",
            "Epoch 16750\n",
            "Epoch 16751\n",
            "Epoch 16752\n",
            "Epoch 16753\n",
            "Epoch 16754\n",
            "Epoch 16755\n",
            "Epoch 16756\n",
            "Epoch 16757\n",
            "Epoch 16758\n",
            "Epoch 16759\n",
            "Epoch 16760\n",
            "Epoch 16761\n",
            "Epoch 16762\n",
            "Epoch 16763\n",
            "Epoch 16764\n",
            "Epoch 16765\n",
            "Epoch 16766\n",
            "Epoch 16767\n",
            "Epoch 16768\n",
            "Epoch 16769\n",
            "Epoch 16770\n",
            "Epoch 16771\n",
            "Epoch 16772\n",
            "Epoch 16773\n",
            "Epoch 16774\n",
            "Epoch 16775\n",
            "Epoch 16776\n",
            "Epoch 16777\n",
            "Epoch 16778\n",
            "Epoch 16779\n",
            "Epoch 16780\n",
            "Epoch 16781\n",
            "Epoch 16782\n",
            "Epoch 16783\n",
            "Epoch 16784\n",
            "Epoch 16785\n",
            "Epoch 16786\n",
            "Epoch 16787\n",
            "Epoch 16788\n",
            "Epoch 16789\n",
            "Epoch 16790\n",
            "Epoch 16791\n",
            "Epoch 16792\n",
            "Epoch 16793\n",
            "Epoch 16794\n",
            "Epoch 16795\n",
            "Epoch 16796\n",
            "Epoch 16797\n",
            "Epoch 16798\n",
            "Epoch 16799\n",
            "Epoch 16800\n",
            "Epoch 16801\n",
            "Epoch 16802\n",
            "Epoch 16803\n",
            "Epoch 16804\n",
            "Epoch 16805\n",
            "Epoch 16806\n",
            "Epoch 16807\n",
            "Epoch 16808\n",
            "Epoch 16809\n",
            "Epoch 16810\n",
            "Epoch 16811\n",
            "Epoch 16812\n",
            "Epoch 16813\n",
            "Epoch 16814\n",
            "Epoch 16815\n",
            "Epoch 16816\n",
            "Epoch 16817\n",
            "Epoch 16818\n",
            "Epoch 16819\n",
            "Epoch 16820\n",
            "Epoch 16821\n",
            "Epoch 16822\n",
            "Epoch 16823\n",
            "Epoch 16824\n",
            "Epoch 16825\n",
            "Epoch 16826\n",
            "Epoch 16827\n",
            "Epoch 16828\n",
            "Epoch 16829\n",
            "Epoch 16830\n",
            "Epoch 16831\n",
            "Epoch 16832\n",
            "Epoch 16833\n",
            "Epoch 16834\n",
            "Epoch 16835\n",
            "Epoch 16836\n",
            "Epoch 16837\n",
            "Epoch 16838\n",
            "Epoch 16839\n",
            "Epoch 16840\n",
            "Epoch 16841\n",
            "Epoch 16842\n",
            "Epoch 16843\n",
            "Epoch 16844\n",
            "Epoch 16845\n",
            "Epoch 16846\n",
            "Epoch 16847\n",
            "Epoch 16848\n",
            "Epoch 16849\n",
            "Epoch 16850\n",
            "Epoch 16851\n",
            "Epoch 16852\n",
            "Epoch 16853\n",
            "Epoch 16854\n",
            "Epoch 16855\n",
            "Epoch 16856\n",
            "Epoch 16857\n",
            "Epoch 16858\n",
            "Epoch 16859\n",
            "Epoch 16860\n",
            "Epoch 16861\n",
            "Epoch 16862\n",
            "Epoch 16863\n",
            "Epoch 16864\n",
            "Epoch 16865\n",
            "Epoch 16866\n",
            "Epoch 16867\n",
            "Epoch 16868\n",
            "Epoch 16869\n",
            "Epoch 16870\n",
            "Epoch 16871\n",
            "Epoch 16872\n",
            "Epoch 16873\n",
            "Epoch 16874\n",
            "Epoch 16875\n",
            "Epoch 16876\n",
            "Epoch 16877\n",
            "Epoch 16878\n",
            "Epoch 16879\n",
            "Epoch 16880\n",
            "Epoch 16881\n",
            "Epoch 16882\n",
            "Epoch 16883\n",
            "Epoch 16884\n",
            "Epoch 16885\n",
            "Epoch 16886\n",
            "Epoch 16887\n",
            "Epoch 16888\n",
            "Epoch 16889\n",
            "Epoch 16890\n",
            "Epoch 16891\n",
            "Epoch 16892\n",
            "Epoch 16893\n",
            "Epoch 16894\n",
            "Epoch 16895\n",
            "Epoch 16896\n",
            "Epoch 16897\n",
            "Epoch 16898\n",
            "Epoch 16899\n",
            "Epoch 16900\n",
            "Epoch 16901\n",
            "Epoch 16902\n",
            "Epoch 16903\n",
            "Epoch 16904\n",
            "Epoch 16905\n",
            "Epoch 16906\n",
            "Epoch 16907\n",
            "Epoch 16908\n",
            "Epoch 16909\n",
            "Epoch 16910\n",
            "Epoch 16911\n",
            "Epoch 16912\n",
            "Epoch 16913\n",
            "Epoch 16914\n",
            "Epoch 16915\n",
            "Epoch 16916\n",
            "Epoch 16917\n",
            "Epoch 16918\n",
            "Epoch 16919\n",
            "Epoch 16920\n",
            "Epoch 16921\n",
            "Epoch 16922\n",
            "Epoch 16923\n",
            "Epoch 16924\n",
            "Epoch 16925\n",
            "Epoch 16926\n",
            "Epoch 16927\n",
            "Epoch 16928\n",
            "Epoch 16929\n",
            "Epoch 16930\n",
            "Epoch 16931\n",
            "Epoch 16932\n",
            "Epoch 16933\n",
            "Epoch 16934\n",
            "Epoch 16935\n",
            "Epoch 16936\n",
            "Epoch 16937\n",
            "Epoch 16938\n",
            "Epoch 16939\n",
            "Epoch 16940\n",
            "Epoch 16941\n",
            "Epoch 16942\n",
            "Epoch 16943\n",
            "Epoch 16944\n",
            "Epoch 16945\n",
            "Epoch 16946\n",
            "Epoch 16947\n",
            "Epoch 16948\n",
            "Epoch 16949\n",
            "Epoch 16950\n",
            "Epoch 16951\n",
            "Epoch 16952\n",
            "Epoch 16953\n",
            "Epoch 16954\n",
            "Epoch 16955\n",
            "Epoch 16956\n",
            "Epoch 16957\n",
            "Epoch 16958\n",
            "Epoch 16959\n",
            "Epoch 16960\n",
            "Epoch 16961\n",
            "Epoch 16962\n",
            "Epoch 16963\n",
            "Epoch 16964\n",
            "Epoch 16965\n",
            "Epoch 16966\n",
            "Epoch 16967\n",
            "Epoch 16968\n",
            "Epoch 16969\n",
            "Epoch 16970\n",
            "Epoch 16971\n",
            "Epoch 16972\n",
            "Epoch 16973\n",
            "Epoch 16974\n",
            "Epoch 16975\n",
            "Epoch 16976\n",
            "Epoch 16977\n",
            "Epoch 16978\n",
            "Epoch 16979\n",
            "Epoch 16980\n",
            "Epoch 16981\n",
            "Epoch 16982\n",
            "Epoch 16983\n",
            "Epoch 16984\n",
            "Epoch 16985\n",
            "Epoch 16986\n",
            "Epoch 16987\n",
            "Epoch 16988\n",
            "Epoch 16989\n",
            "Epoch 16990\n",
            "Epoch 16991\n",
            "Epoch 16992\n",
            "Epoch 16993\n",
            "Epoch 16994\n",
            "Epoch 16995\n",
            "Epoch 16996\n",
            "Epoch 16997\n",
            "Epoch 16998\n",
            "Epoch 16999\n",
            "Epoch 17000\n",
            "Epoch 17001\n",
            "Epoch 17002\n",
            "Epoch 17003\n",
            "Epoch 17004\n",
            "Epoch 17005\n",
            "Epoch 17006\n",
            "Epoch 17007\n",
            "Epoch 17008\n",
            "Epoch 17009\n",
            "Epoch 17010\n",
            "Epoch 17011\n",
            "Epoch 17012\n",
            "Epoch 17013\n",
            "Epoch 17014\n",
            "Epoch 17015\n",
            "Epoch 17016\n",
            "Epoch 17017\n",
            "Epoch 17018\n",
            "Epoch 17019\n",
            "Epoch 17020\n",
            "Epoch 17021\n",
            "Epoch 17022\n",
            "Epoch 17023\n",
            "Epoch 17024\n",
            "Epoch 17025\n",
            "Epoch 17026\n",
            "Epoch 17027\n",
            "Epoch 17028\n",
            "Epoch 17029\n",
            "Epoch 17030\n",
            "Epoch 17031\n",
            "Epoch 17032\n",
            "Epoch 17033\n",
            "Epoch 17034\n",
            "Epoch 17035\n",
            "Epoch 17036\n",
            "Epoch 17037\n",
            "Epoch 17038\n",
            "Epoch 17039\n",
            "Epoch 17040\n",
            "Epoch 17041\n",
            "Epoch 17042\n",
            "Epoch 17043\n",
            "Epoch 17044\n",
            "Epoch 17045\n",
            "Epoch 17046\n",
            "Epoch 17047\n",
            "Epoch 17048\n",
            "Epoch 17049\n",
            "Epoch 17050\n",
            "Epoch 17051\n",
            "Epoch 17052\n",
            "Epoch 17053\n",
            "Epoch 17054\n",
            "Epoch 17055\n",
            "Epoch 17056\n",
            "Epoch 17057\n",
            "Epoch 17058\n",
            "Epoch 17059\n",
            "Epoch 17060\n",
            "Epoch 17061\n",
            "Epoch 17062\n",
            "Epoch 17063\n",
            "Epoch 17064\n",
            "Epoch 17065\n",
            "Epoch 17066\n",
            "Epoch 17067\n",
            "Epoch 17068\n",
            "Epoch 17069\n",
            "Epoch 17070\n",
            "Epoch 17071\n",
            "Epoch 17072\n",
            "Epoch 17073\n",
            "Epoch 17074\n",
            "Epoch 17075\n",
            "Epoch 17076\n",
            "Epoch 17077\n",
            "Epoch 17078\n",
            "Epoch 17079\n",
            "Epoch 17080\n",
            "Epoch 17081\n",
            "Epoch 17082\n",
            "Epoch 17083\n",
            "Epoch 17084\n",
            "Epoch 17085\n",
            "Epoch 17086\n",
            "Epoch 17087\n",
            "Epoch 17088\n",
            "Epoch 17089\n",
            "Epoch 17090\n",
            "Epoch 17091\n",
            "Epoch 17092\n",
            "Epoch 17093\n",
            "Epoch 17094\n",
            "Epoch 17095\n",
            "Epoch 17096\n",
            "Epoch 17097\n",
            "Epoch 17098\n",
            "Epoch 17099\n",
            "Epoch 17100\n",
            "Epoch 17101\n",
            "Epoch 17102\n",
            "Epoch 17103\n",
            "Epoch 17104\n",
            "Epoch 17105\n",
            "Epoch 17106\n",
            "Epoch 17107\n",
            "Epoch 17108\n",
            "Epoch 17109\n",
            "Epoch 17110\n",
            "Epoch 17111\n",
            "Epoch 17112\n",
            "Epoch 17113\n",
            "Epoch 17114\n",
            "Epoch 17115\n",
            "Epoch 17116\n",
            "Epoch 17117\n",
            "Epoch 17118\n",
            "Epoch 17119\n",
            "Epoch 17120\n",
            "Epoch 17121\n",
            "Epoch 17122\n",
            "Epoch 17123\n",
            "Epoch 17124\n",
            "Epoch 17125\n",
            "Epoch 17126\n",
            "Epoch 17127\n",
            "Epoch 17128\n",
            "Epoch 17129\n",
            "Epoch 17130\n",
            "Epoch 17131\n",
            "Epoch 17132\n",
            "Epoch 17133\n",
            "Epoch 17134\n",
            "Epoch 17135\n",
            "Epoch 17136\n",
            "Epoch 17137\n",
            "Epoch 17138\n",
            "Epoch 17139\n",
            "Epoch 17140\n",
            "Epoch 17141\n",
            "Epoch 17142\n",
            "Epoch 17143\n",
            "Epoch 17144\n",
            "Epoch 17145\n",
            "Epoch 17146\n",
            "Epoch 17147\n",
            "Epoch 17148\n",
            "Epoch 17149\n",
            "Epoch 17150\n",
            "Epoch 17151\n",
            "Epoch 17152\n",
            "Epoch 17153\n",
            "Epoch 17154\n",
            "Epoch 17155\n",
            "Epoch 17156\n",
            "Epoch 17157\n",
            "Epoch 17158\n",
            "Epoch 17159\n",
            "Epoch 17160\n",
            "Epoch 17161\n",
            "Epoch 17162\n",
            "Epoch 17163\n",
            "Epoch 17164\n",
            "Epoch 17165\n",
            "Epoch 17166\n",
            "Epoch 17167\n",
            "Epoch 17168\n",
            "Epoch 17169\n",
            "Epoch 17170\n",
            "Epoch 17171\n",
            "Epoch 17172\n",
            "Epoch 17173\n",
            "Epoch 17174\n",
            "Epoch 17175\n",
            "Epoch 17176\n",
            "Epoch 17177\n",
            "Epoch 17178\n",
            "Epoch 17179\n",
            "Epoch 17180\n",
            "Epoch 17181\n",
            "Epoch 17182\n",
            "Epoch 17183\n",
            "Epoch 17184\n",
            "Epoch 17185\n",
            "Epoch 17186\n",
            "Epoch 17187\n",
            "Epoch 17188\n",
            "Epoch 17189\n",
            "Epoch 17190\n",
            "Epoch 17191\n",
            "Epoch 17192\n",
            "Epoch 17193\n",
            "Epoch 17194\n",
            "Epoch 17195\n",
            "Epoch 17196\n",
            "Epoch 17197\n",
            "Epoch 17198\n",
            "Epoch 17199\n",
            "Epoch 17200\n",
            "Epoch 17201\n",
            "Epoch 17202\n",
            "Epoch 17203\n",
            "Epoch 17204\n",
            "Epoch 17205\n",
            "Epoch 17206\n",
            "Epoch 17207\n",
            "Epoch 17208\n",
            "Epoch 17209\n",
            "Epoch 17210\n",
            "Epoch 17211\n",
            "Epoch 17212\n",
            "Epoch 17213\n",
            "Epoch 17214\n",
            "Epoch 17215\n",
            "Epoch 17216\n",
            "Epoch 17217\n",
            "Epoch 17218\n",
            "Epoch 17219\n",
            "Epoch 17220\n",
            "Epoch 17221\n",
            "Epoch 17222\n",
            "Epoch 17223\n",
            "Epoch 17224\n",
            "Epoch 17225\n",
            "Epoch 17226\n",
            "Epoch 17227\n",
            "Epoch 17228\n",
            "Epoch 17229\n",
            "Epoch 17230\n",
            "Epoch 17231\n",
            "Epoch 17232\n",
            "Epoch 17233\n",
            "Epoch 17234\n",
            "Epoch 17235\n",
            "Epoch 17236\n",
            "Epoch 17237\n",
            "Epoch 17238\n",
            "Epoch 17239\n",
            "Epoch 17240\n",
            "Epoch 17241\n",
            "Epoch 17242\n",
            "Epoch 17243\n",
            "Epoch 17244\n",
            "Epoch 17245\n",
            "Epoch 17246\n",
            "Epoch 17247\n",
            "Epoch 17248\n",
            "Epoch 17249\n",
            "Epoch 17250\n",
            "Epoch 17251\n",
            "Epoch 17252\n",
            "Epoch 17253\n",
            "Epoch 17254\n",
            "Epoch 17255\n",
            "Epoch 17256\n",
            "Epoch 17257\n",
            "Epoch 17258\n",
            "Epoch 17259\n",
            "Epoch 17260\n",
            "Epoch 17261\n",
            "Epoch 17262\n",
            "Epoch 17263\n",
            "Epoch 17264\n",
            "Epoch 17265\n",
            "Epoch 17266\n",
            "Epoch 17267\n",
            "Epoch 17268\n",
            "Epoch 17269\n",
            "Epoch 17270\n",
            "Epoch 17271\n",
            "Epoch 17272\n",
            "Epoch 17273\n",
            "Epoch 17274\n",
            "Epoch 17275\n",
            "Epoch 17276\n",
            "Epoch 17277\n",
            "Epoch 17278\n",
            "Epoch 17279\n",
            "Epoch 17280\n",
            "Epoch 17281\n",
            "Epoch 17282\n",
            "Epoch 17283\n",
            "Epoch 17284\n",
            "Epoch 17285\n",
            "Epoch 17286\n",
            "Epoch 17287\n",
            "Epoch 17288\n",
            "Epoch 17289\n",
            "Epoch 17290\n",
            "Epoch 17291\n",
            "Epoch 17292\n",
            "Epoch 17293\n",
            "Epoch 17294\n",
            "Epoch 17295\n",
            "Epoch 17296\n",
            "Epoch 17297\n",
            "Epoch 17298\n",
            "Epoch 17299\n",
            "Epoch 17300\n",
            "Epoch 17301\n",
            "Epoch 17302\n",
            "Epoch 17303\n",
            "Epoch 17304\n",
            "Epoch 17305\n",
            "Epoch 17306\n",
            "Epoch 17307\n",
            "Epoch 17308\n",
            "Epoch 17309\n",
            "Epoch 17310\n",
            "Epoch 17311\n",
            "Epoch 17312\n",
            "Epoch 17313\n",
            "Epoch 17314\n",
            "Epoch 17315\n",
            "Epoch 17316\n",
            "Epoch 17317\n",
            "Epoch 17318\n",
            "Epoch 17319\n",
            "Epoch 17320\n",
            "Epoch 17321\n",
            "Epoch 17322\n",
            "Epoch 17323\n",
            "Epoch 17324\n",
            "Epoch 17325\n",
            "Epoch 17326\n",
            "Epoch 17327\n",
            "Epoch 17328\n",
            "Epoch 17329\n",
            "Epoch 17330\n",
            "Epoch 17331\n",
            "Epoch 17332\n",
            "Epoch 17333\n",
            "Epoch 17334\n",
            "Epoch 17335\n",
            "Epoch 17336\n",
            "Epoch 17337\n",
            "Epoch 17338\n",
            "Epoch 17339\n",
            "Epoch 17340\n",
            "Epoch 17341\n",
            "Epoch 17342\n",
            "Epoch 17343\n",
            "Epoch 17344\n",
            "Epoch 17345\n",
            "Epoch 17346\n",
            "Epoch 17347\n",
            "Epoch 17348\n",
            "Epoch 17349\n",
            "Epoch 17350\n",
            "Epoch 17351\n",
            "Epoch 17352\n",
            "Epoch 17353\n",
            "Epoch 17354\n",
            "Epoch 17355\n",
            "Epoch 17356\n",
            "Epoch 17357\n",
            "Epoch 17358\n",
            "Epoch 17359\n",
            "Epoch 17360\n",
            "Epoch 17361\n",
            "Epoch 17362\n",
            "Epoch 17363\n",
            "Epoch 17364\n",
            "Epoch 17365\n",
            "Epoch 17366\n",
            "Epoch 17367\n",
            "Epoch 17368\n",
            "Epoch 17369\n",
            "Epoch 17370\n",
            "Epoch 17371\n",
            "Epoch 17372\n",
            "Epoch 17373\n",
            "Epoch 17374\n",
            "Epoch 17375\n",
            "Epoch 17376\n",
            "Epoch 17377\n",
            "Epoch 17378\n",
            "Epoch 17379\n",
            "Epoch 17380\n",
            "Epoch 17381\n",
            "Epoch 17382\n",
            "Epoch 17383\n",
            "Epoch 17384\n",
            "Epoch 17385\n",
            "Epoch 17386\n",
            "Epoch 17387\n",
            "Epoch 17388\n",
            "Epoch 17389\n",
            "Epoch 17390\n",
            "Epoch 17391\n",
            "Epoch 17392\n",
            "Epoch 17393\n",
            "Epoch 17394\n",
            "Epoch 17395\n",
            "Epoch 17396\n",
            "Epoch 17397\n",
            "Epoch 17398\n",
            "Epoch 17399\n",
            "Epoch 17400\n",
            "Epoch 17401\n",
            "Epoch 17402\n",
            "Epoch 17403\n",
            "Epoch 17404\n",
            "Epoch 17405\n",
            "Epoch 17406\n",
            "Epoch 17407\n",
            "Epoch 17408\n",
            "Epoch 17409\n",
            "Epoch 17410\n",
            "Epoch 17411\n",
            "Epoch 17412\n",
            "Epoch 17413\n",
            "Epoch 17414\n",
            "Epoch 17415\n",
            "Epoch 17416\n",
            "Epoch 17417\n",
            "Epoch 17418\n",
            "Epoch 17419\n",
            "Epoch 17420\n",
            "Epoch 17421\n",
            "Epoch 17422\n",
            "Epoch 17423\n",
            "Epoch 17424\n",
            "Epoch 17425\n",
            "Epoch 17426\n",
            "Epoch 17427\n",
            "Epoch 17428\n",
            "Epoch 17429\n",
            "Epoch 17430\n",
            "Epoch 17431\n",
            "Epoch 17432\n",
            "Epoch 17433\n",
            "Epoch 17434\n",
            "Epoch 17435\n",
            "Epoch 17436\n",
            "Epoch 17437\n",
            "Epoch 17438\n",
            "Epoch 17439\n",
            "Epoch 17440\n",
            "Epoch 17441\n",
            "Epoch 17442\n",
            "Epoch 17443\n",
            "Epoch 17444\n",
            "Epoch 17445\n",
            "Epoch 17446\n",
            "Epoch 17447\n",
            "Epoch 17448\n",
            "Epoch 17449\n",
            "Epoch 17450\n",
            "Epoch 17451\n",
            "Epoch 17452\n",
            "Epoch 17453\n",
            "Epoch 17454\n",
            "Epoch 17455\n",
            "Epoch 17456\n",
            "Epoch 17457\n",
            "Epoch 17458\n",
            "Epoch 17459\n",
            "Epoch 17460\n",
            "Epoch 17461\n",
            "Epoch 17462\n",
            "Epoch 17463\n",
            "Epoch 17464\n",
            "Epoch 17465\n",
            "Epoch 17466\n",
            "Epoch 17467\n",
            "Epoch 17468\n",
            "Epoch 17469\n",
            "Epoch 17470\n",
            "Epoch 17471\n",
            "Epoch 17472\n",
            "Epoch 17473\n",
            "Epoch 17474\n",
            "Epoch 17475\n",
            "Epoch 17476\n",
            "Epoch 17477\n",
            "Epoch 17478\n",
            "Epoch 17479\n",
            "Epoch 17480\n",
            "Epoch 17481\n",
            "Epoch 17482\n",
            "Epoch 17483\n",
            "Epoch 17484\n",
            "Epoch 17485\n",
            "Epoch 17486\n",
            "Epoch 17487\n",
            "Epoch 17488\n",
            "Epoch 17489\n",
            "Epoch 17490\n",
            "Epoch 17491\n",
            "Epoch 17492\n",
            "Epoch 17493\n",
            "Epoch 17494\n",
            "Epoch 17495\n",
            "Epoch 17496\n",
            "Epoch 17497\n",
            "Epoch 17498\n",
            "Epoch 17499\n",
            "Epoch 17500\n",
            "Epoch 17501\n",
            "Epoch 17502\n",
            "Epoch 17503\n",
            "Epoch 17504\n",
            "Epoch 17505\n",
            "Epoch 17506\n",
            "Epoch 17507\n",
            "Epoch 17508\n",
            "Epoch 17509\n",
            "Epoch 17510\n",
            "Epoch 17511\n",
            "Epoch 17512\n",
            "Epoch 17513\n",
            "Epoch 17514\n",
            "Epoch 17515\n",
            "Epoch 17516\n",
            "Epoch 17517\n",
            "Epoch 17518\n",
            "Epoch 17519\n",
            "Epoch 17520\n",
            "Epoch 17521\n",
            "Epoch 17522\n",
            "Epoch 17523\n",
            "Epoch 17524\n",
            "Epoch 17525\n",
            "Epoch 17526\n",
            "Epoch 17527\n",
            "Epoch 17528\n",
            "Epoch 17529\n",
            "Epoch 17530\n",
            "Epoch 17531\n",
            "Epoch 17532\n",
            "Epoch 17533\n",
            "Epoch 17534\n",
            "Epoch 17535\n",
            "Epoch 17536\n",
            "Epoch 17537\n",
            "Epoch 17538\n",
            "Epoch 17539\n",
            "Epoch 17540\n",
            "Epoch 17541\n",
            "Epoch 17542\n",
            "Epoch 17543\n",
            "Epoch 17544\n",
            "Epoch 17545\n",
            "Epoch 17546\n",
            "Epoch 17547\n",
            "Epoch 17548\n",
            "Epoch 17549\n",
            "Epoch 17550\n",
            "Epoch 17551\n",
            "Epoch 17552\n",
            "Epoch 17553\n",
            "Epoch 17554\n",
            "Epoch 17555\n",
            "Epoch 17556\n",
            "Epoch 17557\n",
            "Epoch 17558\n",
            "Epoch 17559\n",
            "Epoch 17560\n",
            "Epoch 17561\n",
            "Epoch 17562\n",
            "Epoch 17563\n",
            "Epoch 17564\n",
            "Epoch 17565\n",
            "Epoch 17566\n",
            "Epoch 17567\n",
            "Epoch 17568\n",
            "Epoch 17569\n",
            "Epoch 17570\n",
            "Epoch 17571\n",
            "Epoch 17572\n",
            "Epoch 17573\n",
            "Epoch 17574\n",
            "Epoch 17575\n",
            "Epoch 17576\n",
            "Epoch 17577\n",
            "Epoch 17578\n",
            "Epoch 17579\n",
            "Epoch 17580\n",
            "Epoch 17581\n",
            "Epoch 17582\n",
            "Epoch 17583\n",
            "Epoch 17584\n",
            "Epoch 17585\n",
            "Epoch 17586\n",
            "Epoch 17587\n",
            "Epoch 17588\n",
            "Epoch 17589\n",
            "Epoch 17590\n",
            "Epoch 17591\n",
            "Epoch 17592\n",
            "Epoch 17593\n",
            "Epoch 17594\n",
            "Epoch 17595\n",
            "Epoch 17596\n",
            "Epoch 17597\n",
            "Epoch 17598\n",
            "Epoch 17599\n",
            "Epoch 17600\n",
            "Epoch 17601\n",
            "Epoch 17602\n",
            "Epoch 17603\n",
            "Epoch 17604\n",
            "Epoch 17605\n",
            "Epoch 17606\n",
            "Epoch 17607\n",
            "Epoch 17608\n",
            "Epoch 17609\n",
            "Epoch 17610\n",
            "Epoch 17611\n",
            "Epoch 17612\n",
            "Epoch 17613\n",
            "Epoch 17614\n",
            "Epoch 17615\n",
            "Epoch 17616\n",
            "Epoch 17617\n",
            "Epoch 17618\n",
            "Epoch 17619\n",
            "Epoch 17620\n",
            "Epoch 17621\n",
            "Epoch 17622\n",
            "Epoch 17623\n",
            "Epoch 17624\n",
            "Epoch 17625\n",
            "Epoch 17626\n",
            "Epoch 17627\n",
            "Epoch 17628\n",
            "Epoch 17629\n",
            "Epoch 17630\n",
            "Epoch 17631\n",
            "Epoch 17632\n",
            "Epoch 17633\n",
            "Epoch 17634\n",
            "Epoch 17635\n",
            "Epoch 17636\n",
            "Epoch 17637\n",
            "Epoch 17638\n",
            "Epoch 17639\n",
            "Epoch 17640\n",
            "Epoch 17641\n",
            "Epoch 17642\n",
            "Epoch 17643\n",
            "Epoch 17644\n",
            "Epoch 17645\n",
            "Epoch 17646\n",
            "Epoch 17647\n",
            "Epoch 17648\n",
            "Epoch 17649\n",
            "Epoch 17650\n",
            "Epoch 17651\n",
            "Epoch 17652\n",
            "Epoch 17653\n",
            "Epoch 17654\n",
            "Epoch 17655\n",
            "Epoch 17656\n",
            "Epoch 17657\n",
            "Epoch 17658\n",
            "Epoch 17659\n",
            "Epoch 17660\n",
            "Epoch 17661\n",
            "Epoch 17662\n",
            "Epoch 17663\n",
            "Epoch 17664\n",
            "Epoch 17665\n",
            "Epoch 17666\n",
            "Epoch 17667\n",
            "Epoch 17668\n",
            "Epoch 17669\n",
            "Epoch 17670\n",
            "Epoch 17671\n",
            "Epoch 17672\n",
            "Epoch 17673\n",
            "Epoch 17674\n",
            "Epoch 17675\n",
            "Epoch 17676\n",
            "Epoch 17677\n",
            "Epoch 17678\n",
            "Epoch 17679\n",
            "Epoch 17680\n",
            "Epoch 17681\n",
            "Epoch 17682\n",
            "Epoch 17683\n",
            "Epoch 17684\n",
            "Epoch 17685\n",
            "Epoch 17686\n",
            "Epoch 17687\n",
            "Epoch 17688\n",
            "Epoch 17689\n",
            "Epoch 17690\n",
            "Epoch 17691\n",
            "Epoch 17692\n",
            "Epoch 17693\n",
            "Epoch 17694\n",
            "Epoch 17695\n",
            "Epoch 17696\n",
            "Epoch 17697\n",
            "Epoch 17698\n",
            "Epoch 17699\n",
            "Epoch 17700\n",
            "Epoch 17701\n",
            "Epoch 17702\n",
            "Epoch 17703\n",
            "Epoch 17704\n",
            "Epoch 17705\n",
            "Epoch 17706\n",
            "Epoch 17707\n",
            "Epoch 17708\n",
            "Epoch 17709\n",
            "Epoch 17710\n",
            "Epoch 17711\n",
            "Epoch 17712\n",
            "Epoch 17713\n",
            "Epoch 17714\n",
            "Epoch 17715\n",
            "Epoch 17716\n",
            "Epoch 17717\n",
            "Epoch 17718\n",
            "Epoch 17719\n",
            "Epoch 17720\n",
            "Epoch 17721\n",
            "Epoch 17722\n",
            "Epoch 17723\n",
            "Epoch 17724\n",
            "Epoch 17725\n",
            "Epoch 17726\n",
            "Epoch 17727\n",
            "Epoch 17728\n",
            "Epoch 17729\n",
            "Epoch 17730\n",
            "Epoch 17731\n",
            "Epoch 17732\n",
            "Epoch 17733\n",
            "Epoch 17734\n",
            "Epoch 17735\n",
            "Epoch 17736\n",
            "Epoch 17737\n",
            "Epoch 17738\n",
            "Epoch 17739\n",
            "Epoch 17740\n",
            "Epoch 17741\n",
            "Epoch 17742\n",
            "Epoch 17743\n",
            "Epoch 17744\n",
            "Epoch 17745\n",
            "Epoch 17746\n",
            "Epoch 17747\n",
            "Epoch 17748\n",
            "Epoch 17749\n",
            "Epoch 17750\n",
            "Epoch 17751\n",
            "Epoch 17752\n",
            "Epoch 17753\n",
            "Epoch 17754\n",
            "Epoch 17755\n",
            "Epoch 17756\n",
            "Epoch 17757\n",
            "Epoch 17758\n",
            "Epoch 17759\n",
            "Epoch 17760\n",
            "Epoch 17761\n",
            "Epoch 17762\n",
            "Epoch 17763\n",
            "Epoch 17764\n",
            "Epoch 17765\n",
            "Epoch 17766\n",
            "Epoch 17767\n",
            "Epoch 17768\n",
            "Epoch 17769\n",
            "Epoch 17770\n",
            "Epoch 17771\n",
            "Epoch 17772\n",
            "Epoch 17773\n",
            "Epoch 17774\n",
            "Epoch 17775\n",
            "Epoch 17776\n",
            "Epoch 17777\n",
            "Epoch 17778\n",
            "Epoch 17779\n",
            "Epoch 17780\n",
            "Epoch 17781\n",
            "Epoch 17782\n",
            "Epoch 17783\n",
            "Epoch 17784\n",
            "Epoch 17785\n",
            "Epoch 17786\n",
            "Epoch 17787\n",
            "Epoch 17788\n",
            "Epoch 17789\n",
            "Epoch 17790\n",
            "Epoch 17791\n",
            "Epoch 17792\n",
            "Epoch 17793\n",
            "Epoch 17794\n",
            "Epoch 17795\n",
            "Epoch 17796\n",
            "Epoch 17797\n",
            "Epoch 17798\n",
            "Epoch 17799\n",
            "Epoch 17800\n",
            "Epoch 17801\n",
            "Epoch 17802\n",
            "Epoch 17803\n",
            "Epoch 17804\n",
            "Epoch 17805\n",
            "Epoch 17806\n",
            "Epoch 17807\n",
            "Epoch 17808\n",
            "Epoch 17809\n",
            "Epoch 17810\n",
            "Epoch 17811\n",
            "Epoch 17812\n",
            "Epoch 17813\n",
            "Epoch 17814\n",
            "Epoch 17815\n",
            "Epoch 17816\n",
            "Epoch 17817\n",
            "Epoch 17818\n",
            "Epoch 17819\n",
            "Epoch 17820\n",
            "Epoch 17821\n",
            "Epoch 17822\n",
            "Epoch 17823\n",
            "Epoch 17824\n",
            "Epoch 17825\n",
            "Epoch 17826\n",
            "Epoch 17827\n",
            "Epoch 17828\n",
            "Epoch 17829\n",
            "Epoch 17830\n",
            "Epoch 17831\n",
            "Epoch 17832\n",
            "Epoch 17833\n",
            "Epoch 17834\n",
            "Epoch 17835\n",
            "Epoch 17836\n",
            "Epoch 17837\n",
            "Epoch 17838\n",
            "Epoch 17839\n",
            "Epoch 17840\n",
            "Epoch 17841\n",
            "Epoch 17842\n",
            "Epoch 17843\n",
            "Epoch 17844\n",
            "Epoch 17845\n",
            "Epoch 17846\n",
            "Epoch 17847\n",
            "Epoch 17848\n",
            "Epoch 17849\n",
            "Epoch 17850\n",
            "Epoch 17851\n",
            "Epoch 17852\n",
            "Epoch 17853\n",
            "Epoch 17854\n",
            "Epoch 17855\n",
            "Epoch 17856\n",
            "Epoch 17857\n",
            "Epoch 17858\n",
            "Epoch 17859\n",
            "Epoch 17860\n",
            "Epoch 17861\n",
            "Epoch 17862\n",
            "Epoch 17863\n",
            "Epoch 17864\n",
            "Epoch 17865\n",
            "Epoch 17866\n",
            "Epoch 17867\n",
            "Epoch 17868\n",
            "Epoch 17869\n",
            "Epoch 17870\n",
            "Epoch 17871\n",
            "Epoch 17872\n",
            "Epoch 17873\n",
            "Epoch 17874\n",
            "Epoch 17875\n",
            "Epoch 17876\n",
            "Epoch 17877\n",
            "Epoch 17878\n",
            "Epoch 17879\n",
            "Epoch 17880\n",
            "Epoch 17881\n",
            "Epoch 17882\n",
            "Epoch 17883\n",
            "Epoch 17884\n",
            "Epoch 17885\n",
            "Epoch 17886\n",
            "Epoch 17887\n",
            "Epoch 17888\n",
            "Epoch 17889\n",
            "Epoch 17890\n",
            "Epoch 17891\n",
            "Epoch 17892\n",
            "Epoch 17893\n",
            "Epoch 17894\n",
            "Epoch 17895\n",
            "Epoch 17896\n",
            "Epoch 17897\n",
            "Epoch 17898\n",
            "Epoch 17899\n",
            "Epoch 17900\n",
            "Epoch 17901\n",
            "Epoch 17902\n",
            "Epoch 17903\n",
            "Epoch 17904\n",
            "Epoch 17905\n",
            "Epoch 17906\n",
            "Epoch 17907\n",
            "Epoch 17908\n",
            "Epoch 17909\n",
            "Epoch 17910\n",
            "Epoch 17911\n",
            "Epoch 17912\n",
            "Epoch 17913\n",
            "Epoch 17914\n",
            "Epoch 17915\n",
            "Epoch 17916\n",
            "Epoch 17917\n",
            "Epoch 17918\n",
            "Epoch 17919\n",
            "Epoch 17920\n",
            "Epoch 17921\n",
            "Epoch 17922\n",
            "Epoch 17923\n",
            "Epoch 17924\n",
            "Epoch 17925\n",
            "Epoch 17926\n",
            "Epoch 17927\n",
            "Epoch 17928\n",
            "Epoch 17929\n",
            "Epoch 17930\n",
            "Epoch 17931\n",
            "Epoch 17932\n",
            "Epoch 17933\n",
            "Epoch 17934\n",
            "Epoch 17935\n",
            "Epoch 17936\n",
            "Epoch 17937\n",
            "Epoch 17938\n",
            "Epoch 17939\n",
            "Epoch 17940\n",
            "Epoch 17941\n",
            "Epoch 17942\n",
            "Epoch 17943\n",
            "Epoch 17944\n",
            "Epoch 17945\n",
            "Epoch 17946\n",
            "Epoch 17947\n",
            "Epoch 17948\n",
            "Epoch 17949\n",
            "Epoch 17950\n",
            "Epoch 17951\n",
            "Epoch 17952\n",
            "Epoch 17953\n",
            "Epoch 17954\n",
            "Epoch 17955\n",
            "Epoch 17956\n",
            "Epoch 17957\n",
            "Epoch 17958\n",
            "Epoch 17959\n",
            "Epoch 17960\n",
            "Epoch 17961\n",
            "Epoch 17962\n",
            "Epoch 17963\n",
            "Epoch 17964\n",
            "Epoch 17965\n",
            "Epoch 17966\n",
            "Epoch 17967\n",
            "Epoch 17968\n",
            "Epoch 17969\n",
            "Epoch 17970\n",
            "Epoch 17971\n",
            "Epoch 17972\n",
            "Epoch 17973\n",
            "Epoch 17974\n",
            "Epoch 17975\n",
            "Epoch 17976\n",
            "Epoch 17977\n",
            "Epoch 17978\n",
            "Epoch 17979\n",
            "Epoch 17980\n",
            "Epoch 17981\n",
            "Epoch 17982\n",
            "Epoch 17983\n",
            "Epoch 17984\n",
            "Epoch 17985\n",
            "Epoch 17986\n",
            "Epoch 17987\n",
            "Epoch 17988\n",
            "Epoch 17989\n",
            "Epoch 17990\n",
            "Epoch 17991\n",
            "Epoch 17992\n",
            "Epoch 17993\n",
            "Epoch 17994\n",
            "Epoch 17995\n",
            "Epoch 17996\n",
            "Epoch 17997\n",
            "Epoch 17998\n",
            "Epoch 17999\n",
            "Epoch 18000\n",
            "Epoch 18001\n",
            "Epoch 18002\n",
            "Epoch 18003\n",
            "Epoch 18004\n",
            "Epoch 18005\n",
            "Epoch 18006\n",
            "Epoch 18007\n",
            "Epoch 18008\n",
            "Epoch 18009\n",
            "Epoch 18010\n",
            "Epoch 18011\n",
            "Epoch 18012\n",
            "Epoch 18013\n",
            "Epoch 18014\n",
            "Epoch 18015\n",
            "Epoch 18016\n",
            "Epoch 18017\n",
            "Epoch 18018\n",
            "Epoch 18019\n",
            "Epoch 18020\n",
            "Epoch 18021\n",
            "Epoch 18022\n",
            "Epoch 18023\n",
            "Epoch 18024\n",
            "Epoch 18025\n",
            "Epoch 18026\n",
            "Epoch 18027\n",
            "Epoch 18028\n",
            "Epoch 18029\n",
            "Epoch 18030\n",
            "Epoch 18031\n",
            "Epoch 18032\n",
            "Epoch 18033\n",
            "Epoch 18034\n",
            "Epoch 18035\n",
            "Epoch 18036\n",
            "Epoch 18037\n",
            "Epoch 18038\n",
            "Epoch 18039\n",
            "Epoch 18040\n",
            "Epoch 18041\n",
            "Epoch 18042\n",
            "Epoch 18043\n",
            "Epoch 18044\n",
            "Epoch 18045\n",
            "Epoch 18046\n",
            "Epoch 18047\n",
            "Epoch 18048\n",
            "Epoch 18049\n",
            "Epoch 18050\n",
            "Epoch 18051\n",
            "Epoch 18052\n",
            "Epoch 18053\n",
            "Epoch 18054\n",
            "Epoch 18055\n",
            "Epoch 18056\n",
            "Epoch 18057\n",
            "Epoch 18058\n",
            "Epoch 18059\n",
            "Epoch 18060\n",
            "Epoch 18061\n",
            "Epoch 18062\n",
            "Epoch 18063\n",
            "Epoch 18064\n",
            "Epoch 18065\n",
            "Epoch 18066\n",
            "Epoch 18067\n",
            "Epoch 18068\n",
            "Epoch 18069\n",
            "Epoch 18070\n",
            "Epoch 18071\n",
            "Epoch 18072\n",
            "Epoch 18073\n",
            "Epoch 18074\n",
            "Epoch 18075\n",
            "Epoch 18076\n",
            "Epoch 18077\n",
            "Epoch 18078\n",
            "Epoch 18079\n",
            "Epoch 18080\n",
            "Epoch 18081\n",
            "Epoch 18082\n",
            "Epoch 18083\n",
            "Epoch 18084\n",
            "Epoch 18085\n",
            "Epoch 18086\n",
            "Epoch 18087\n",
            "Epoch 18088\n",
            "Epoch 18089\n",
            "Epoch 18090\n",
            "Epoch 18091\n",
            "Epoch 18092\n",
            "Epoch 18093\n",
            "Epoch 18094\n",
            "Epoch 18095\n",
            "Epoch 18096\n",
            "Epoch 18097\n",
            "Epoch 18098\n",
            "Epoch 18099\n",
            "Epoch 18100\n",
            "Epoch 18101\n",
            "Epoch 18102\n",
            "Epoch 18103\n",
            "Epoch 18104\n",
            "Epoch 18105\n",
            "Epoch 18106\n",
            "Epoch 18107\n",
            "Epoch 18108\n",
            "Epoch 18109\n",
            "Epoch 18110\n",
            "Epoch 18111\n",
            "Epoch 18112\n",
            "Epoch 18113\n",
            "Epoch 18114\n",
            "Epoch 18115\n",
            "Epoch 18116\n",
            "Epoch 18117\n",
            "Epoch 18118\n",
            "Epoch 18119\n",
            "Epoch 18120\n",
            "Epoch 18121\n",
            "Epoch 18122\n",
            "Epoch 18123\n",
            "Epoch 18124\n",
            "Epoch 18125\n",
            "Epoch 18126\n",
            "Epoch 18127\n",
            "Epoch 18128\n",
            "Epoch 18129\n",
            "Epoch 18130\n",
            "Epoch 18131\n",
            "Epoch 18132\n",
            "Epoch 18133\n",
            "Epoch 18134\n",
            "Epoch 18135\n",
            "Epoch 18136\n",
            "Epoch 18137\n",
            "Epoch 18138\n",
            "Epoch 18139\n",
            "Epoch 18140\n",
            "Epoch 18141\n",
            "Epoch 18142\n",
            "Epoch 18143\n",
            "Epoch 18144\n",
            "Epoch 18145\n",
            "Epoch 18146\n",
            "Epoch 18147\n",
            "Epoch 18148\n",
            "Epoch 18149\n",
            "Epoch 18150\n",
            "Epoch 18151\n",
            "Epoch 18152\n",
            "Epoch 18153\n",
            "Epoch 18154\n",
            "Epoch 18155\n",
            "Epoch 18156\n",
            "Epoch 18157\n",
            "Epoch 18158\n",
            "Epoch 18159\n",
            "Epoch 18160\n",
            "Epoch 18161\n",
            "Epoch 18162\n",
            "Epoch 18163\n",
            "Epoch 18164\n",
            "Epoch 18165\n",
            "Epoch 18166\n",
            "Epoch 18167\n",
            "Epoch 18168\n",
            "Epoch 18169\n",
            "Epoch 18170\n",
            "Epoch 18171\n",
            "Epoch 18172\n",
            "Epoch 18173\n",
            "Epoch 18174\n",
            "Epoch 18175\n",
            "Epoch 18176\n",
            "Epoch 18177\n",
            "Epoch 18178\n",
            "Epoch 18179\n",
            "Epoch 18180\n",
            "Epoch 18181\n",
            "Epoch 18182\n",
            "Epoch 18183\n",
            "Epoch 18184\n",
            "Epoch 18185\n",
            "Epoch 18186\n",
            "Epoch 18187\n",
            "Epoch 18188\n",
            "Epoch 18189\n",
            "Epoch 18190\n",
            "Epoch 18191\n",
            "Epoch 18192\n",
            "Epoch 18193\n",
            "Epoch 18194\n",
            "Epoch 18195\n",
            "Epoch 18196\n",
            "Epoch 18197\n",
            "Epoch 18198\n",
            "Epoch 18199\n",
            "Epoch 18200\n",
            "Epoch 18201\n",
            "Epoch 18202\n",
            "Epoch 18203\n",
            "Epoch 18204\n",
            "Epoch 18205\n",
            "Epoch 18206\n",
            "Epoch 18207\n",
            "Epoch 18208\n",
            "Epoch 18209\n",
            "Epoch 18210\n",
            "Epoch 18211\n",
            "Epoch 18212\n",
            "Epoch 18213\n",
            "Epoch 18214\n",
            "Epoch 18215\n",
            "Epoch 18216\n",
            "Epoch 18217\n",
            "Epoch 18218\n",
            "Epoch 18219\n",
            "Epoch 18220\n",
            "Epoch 18221\n",
            "Epoch 18222\n",
            "Epoch 18223\n",
            "Epoch 18224\n",
            "Epoch 18225\n",
            "Epoch 18226\n",
            "Epoch 18227\n",
            "Epoch 18228\n",
            "Epoch 18229\n",
            "Epoch 18230\n",
            "Epoch 18231\n",
            "Epoch 18232\n",
            "Epoch 18233\n",
            "Epoch 18234\n",
            "Epoch 18235\n",
            "Epoch 18236\n",
            "Epoch 18237\n",
            "Epoch 18238\n",
            "Epoch 18239\n",
            "Epoch 18240\n",
            "Epoch 18241\n",
            "Epoch 18242\n",
            "Epoch 18243\n",
            "Epoch 18244\n",
            "Epoch 18245\n",
            "Epoch 18246\n",
            "Epoch 18247\n",
            "Epoch 18248\n",
            "Epoch 18249\n",
            "Epoch 18250\n",
            "Epoch 18251\n",
            "Epoch 18252\n",
            "Epoch 18253\n",
            "Epoch 18254\n",
            "Epoch 18255\n",
            "Epoch 18256\n",
            "Epoch 18257\n",
            "Epoch 18258\n",
            "Epoch 18259\n",
            "Epoch 18260\n",
            "Epoch 18261\n",
            "Epoch 18262\n",
            "Epoch 18263\n",
            "Epoch 18264\n",
            "Epoch 18265\n",
            "Epoch 18266\n",
            "Epoch 18267\n",
            "Epoch 18268\n",
            "Epoch 18269\n",
            "Epoch 18270\n",
            "Epoch 18271\n",
            "Epoch 18272\n",
            "Epoch 18273\n",
            "Epoch 18274\n",
            "Epoch 18275\n",
            "Epoch 18276\n",
            "Epoch 18277\n",
            "Epoch 18278\n",
            "Epoch 18279\n",
            "Epoch 18280\n",
            "Epoch 18281\n",
            "Epoch 18282\n",
            "Epoch 18283\n",
            "Epoch 18284\n",
            "Epoch 18285\n",
            "Epoch 18286\n",
            "Epoch 18287\n",
            "Epoch 18288\n",
            "Epoch 18289\n",
            "Epoch 18290\n",
            "Epoch 18291\n",
            "Epoch 18292\n",
            "Epoch 18293\n",
            "Epoch 18294\n",
            "Epoch 18295\n",
            "Epoch 18296\n",
            "Epoch 18297\n",
            "Epoch 18298\n",
            "Epoch 18299\n",
            "Epoch 18300\n",
            "Epoch 18301\n",
            "Epoch 18302\n",
            "Epoch 18303\n",
            "Epoch 18304\n",
            "Epoch 18305\n",
            "Epoch 18306\n",
            "Epoch 18307\n",
            "Epoch 18308\n",
            "Epoch 18309\n",
            "Epoch 18310\n",
            "Epoch 18311\n",
            "Epoch 18312\n",
            "Epoch 18313\n",
            "Epoch 18314\n",
            "Epoch 18315\n",
            "Epoch 18316\n",
            "Epoch 18317\n",
            "Epoch 18318\n",
            "Epoch 18319\n",
            "Epoch 18320\n",
            "Epoch 18321\n",
            "Epoch 18322\n",
            "Epoch 18323\n",
            "Epoch 18324\n",
            "Epoch 18325\n",
            "Epoch 18326\n",
            "Epoch 18327\n",
            "Epoch 18328\n",
            "Epoch 18329\n",
            "Epoch 18330\n",
            "Epoch 18331\n",
            "Epoch 18332\n",
            "Epoch 18333\n",
            "Epoch 18334\n",
            "Epoch 18335\n",
            "Epoch 18336\n",
            "Epoch 18337\n",
            "Epoch 18338\n",
            "Epoch 18339\n",
            "Epoch 18340\n",
            "Epoch 18341\n",
            "Epoch 18342\n",
            "Epoch 18343\n",
            "Epoch 18344\n",
            "Epoch 18345\n",
            "Epoch 18346\n",
            "Epoch 18347\n",
            "Epoch 18348\n",
            "Epoch 18349\n",
            "Epoch 18350\n",
            "Epoch 18351\n",
            "Epoch 18352\n",
            "Epoch 18353\n",
            "Epoch 18354\n",
            "Epoch 18355\n",
            "Epoch 18356\n",
            "Epoch 18357\n",
            "Epoch 18358\n",
            "Epoch 18359\n",
            "Epoch 18360\n",
            "Epoch 18361\n",
            "Epoch 18362\n",
            "Epoch 18363\n",
            "Epoch 18364\n",
            "Epoch 18365\n",
            "Epoch 18366\n",
            "Epoch 18367\n",
            "Epoch 18368\n",
            "Epoch 18369\n",
            "Epoch 18370\n",
            "Epoch 18371\n",
            "Epoch 18372\n",
            "Epoch 18373\n",
            "Epoch 18374\n",
            "Epoch 18375\n",
            "Epoch 18376\n",
            "Epoch 18377\n",
            "Epoch 18378\n",
            "Epoch 18379\n",
            "Epoch 18380\n",
            "Epoch 18381\n",
            "Epoch 18382\n",
            "Epoch 18383\n",
            "Epoch 18384\n",
            "Epoch 18385\n",
            "Epoch 18386\n",
            "Epoch 18387\n",
            "Epoch 18388\n",
            "Epoch 18389\n",
            "Epoch 18390\n",
            "Epoch 18391\n",
            "Epoch 18392\n",
            "Epoch 18393\n",
            "Epoch 18394\n",
            "Epoch 18395\n",
            "Epoch 18396\n",
            "Epoch 18397\n",
            "Epoch 18398\n",
            "Epoch 18399\n",
            "Epoch 18400\n",
            "Epoch 18401\n",
            "Epoch 18402\n",
            "Epoch 18403\n",
            "Epoch 18404\n",
            "Epoch 18405\n",
            "Epoch 18406\n",
            "Epoch 18407\n",
            "Epoch 18408\n",
            "Epoch 18409\n",
            "Epoch 18410\n",
            "Epoch 18411\n",
            "Epoch 18412\n",
            "Epoch 18413\n",
            "Epoch 18414\n",
            "Epoch 18415\n",
            "Epoch 18416\n",
            "Epoch 18417\n",
            "Epoch 18418\n",
            "Epoch 18419\n",
            "Epoch 18420\n",
            "Epoch 18421\n",
            "Epoch 18422\n",
            "Epoch 18423\n",
            "Epoch 18424\n",
            "Epoch 18425\n",
            "Epoch 18426\n",
            "Epoch 18427\n",
            "Epoch 18428\n",
            "Epoch 18429\n",
            "Epoch 18430\n",
            "Epoch 18431\n",
            "Epoch 18432\n",
            "Epoch 18433\n",
            "Epoch 18434\n",
            "Epoch 18435\n",
            "Epoch 18436\n",
            "Epoch 18437\n",
            "Epoch 18438\n",
            "Epoch 18439\n",
            "Epoch 18440\n",
            "Epoch 18441\n",
            "Epoch 18442\n",
            "Epoch 18443\n",
            "Epoch 18444\n",
            "Epoch 18445\n",
            "Epoch 18446\n",
            "Epoch 18447\n",
            "Epoch 18448\n",
            "Epoch 18449\n",
            "Epoch 18450\n",
            "Epoch 18451\n",
            "Epoch 18452\n",
            "Epoch 18453\n",
            "Epoch 18454\n",
            "Epoch 18455\n",
            "Epoch 18456\n",
            "Epoch 18457\n",
            "Epoch 18458\n",
            "Epoch 18459\n",
            "Epoch 18460\n",
            "Epoch 18461\n",
            "Epoch 18462\n",
            "Epoch 18463\n",
            "Epoch 18464\n",
            "Epoch 18465\n",
            "Epoch 18466\n",
            "Epoch 18467\n",
            "Epoch 18468\n",
            "Epoch 18469\n",
            "Epoch 18470\n",
            "Epoch 18471\n",
            "Epoch 18472\n",
            "Epoch 18473\n",
            "Epoch 18474\n",
            "Epoch 18475\n",
            "Epoch 18476\n",
            "Epoch 18477\n",
            "Epoch 18478\n",
            "Epoch 18479\n",
            "Epoch 18480\n",
            "Epoch 18481\n",
            "Epoch 18482\n",
            "Epoch 18483\n",
            "Epoch 18484\n",
            "Epoch 18485\n",
            "Epoch 18486\n",
            "Epoch 18487\n",
            "Epoch 18488\n",
            "Epoch 18489\n",
            "Epoch 18490\n",
            "Epoch 18491\n",
            "Epoch 18492\n",
            "Epoch 18493\n",
            "Epoch 18494\n",
            "Epoch 18495\n",
            "Epoch 18496\n",
            "Epoch 18497\n",
            "Epoch 18498\n",
            "Epoch 18499\n",
            "Epoch 18500\n",
            "Epoch 18501\n",
            "Epoch 18502\n",
            "Epoch 18503\n",
            "Epoch 18504\n",
            "Epoch 18505\n",
            "Epoch 18506\n",
            "Epoch 18507\n",
            "Epoch 18508\n",
            "Epoch 18509\n",
            "Epoch 18510\n",
            "Epoch 18511\n",
            "Epoch 18512\n",
            "Epoch 18513\n",
            "Epoch 18514\n",
            "Epoch 18515\n",
            "Epoch 18516\n",
            "Epoch 18517\n",
            "Epoch 18518\n",
            "Epoch 18519\n",
            "Epoch 18520\n",
            "Epoch 18521\n",
            "Epoch 18522\n",
            "Epoch 18523\n",
            "Epoch 18524\n",
            "Epoch 18525\n",
            "Epoch 18526\n",
            "Epoch 18527\n",
            "Epoch 18528\n",
            "Epoch 18529\n",
            "Epoch 18530\n",
            "Epoch 18531\n",
            "Epoch 18532\n",
            "Epoch 18533\n",
            "Epoch 18534\n",
            "Epoch 18535\n",
            "Epoch 18536\n",
            "Epoch 18537\n",
            "Epoch 18538\n",
            "Epoch 18539\n",
            "Epoch 18540\n",
            "Epoch 18541\n",
            "Epoch 18542\n",
            "Epoch 18543\n",
            "Epoch 18544\n",
            "Epoch 18545\n",
            "Epoch 18546\n",
            "Epoch 18547\n",
            "Epoch 18548\n",
            "Epoch 18549\n",
            "Epoch 18550\n",
            "Epoch 18551\n",
            "Epoch 18552\n",
            "Epoch 18553\n",
            "Epoch 18554\n",
            "Epoch 18555\n",
            "Epoch 18556\n",
            "Epoch 18557\n",
            "Epoch 18558\n",
            "Epoch 18559\n",
            "Epoch 18560\n",
            "Epoch 18561\n",
            "Epoch 18562\n",
            "Epoch 18563\n",
            "Epoch 18564\n",
            "Epoch 18565\n",
            "Epoch 18566\n",
            "Epoch 18567\n",
            "Epoch 18568\n",
            "Epoch 18569\n",
            "Epoch 18570\n",
            "Epoch 18571\n",
            "Epoch 18572\n",
            "Epoch 18573\n",
            "Epoch 18574\n",
            "Epoch 18575\n",
            "Epoch 18576\n",
            "Epoch 18577\n",
            "Epoch 18578\n",
            "Epoch 18579\n",
            "Epoch 18580\n",
            "Epoch 18581\n",
            "Epoch 18582\n",
            "Epoch 18583\n",
            "Epoch 18584\n",
            "Epoch 18585\n",
            "Epoch 18586\n",
            "Epoch 18587\n",
            "Epoch 18588\n",
            "Epoch 18589\n",
            "Epoch 18590\n",
            "Epoch 18591\n",
            "Epoch 18592\n",
            "Epoch 18593\n",
            "Epoch 18594\n",
            "Epoch 18595\n",
            "Epoch 18596\n",
            "Epoch 18597\n",
            "Epoch 18598\n",
            "Epoch 18599\n",
            "Epoch 18600\n",
            "Epoch 18601\n",
            "Epoch 18602\n",
            "Epoch 18603\n",
            "Epoch 18604\n",
            "Epoch 18605\n",
            "Epoch 18606\n",
            "Epoch 18607\n",
            "Epoch 18608\n",
            "Epoch 18609\n",
            "Epoch 18610\n",
            "Epoch 18611\n",
            "Epoch 18612\n",
            "Epoch 18613\n",
            "Epoch 18614\n",
            "Epoch 18615\n",
            "Epoch 18616\n",
            "Epoch 18617\n",
            "Epoch 18618\n",
            "Epoch 18619\n",
            "Epoch 18620\n",
            "Epoch 18621\n",
            "Epoch 18622\n",
            "Epoch 18623\n",
            "Epoch 18624\n",
            "Epoch 18625\n",
            "Epoch 18626\n",
            "Epoch 18627\n",
            "Epoch 18628\n",
            "Epoch 18629\n",
            "Epoch 18630\n",
            "Epoch 18631\n",
            "Epoch 18632\n",
            "Epoch 18633\n",
            "Epoch 18634\n",
            "Epoch 18635\n",
            "Epoch 18636\n",
            "Epoch 18637\n",
            "Epoch 18638\n",
            "Epoch 18639\n",
            "Epoch 18640\n",
            "Epoch 18641\n",
            "Epoch 18642\n",
            "Epoch 18643\n",
            "Epoch 18644\n",
            "Epoch 18645\n",
            "Epoch 18646\n",
            "Epoch 18647\n",
            "Epoch 18648\n",
            "Epoch 18649\n",
            "Epoch 18650\n",
            "Epoch 18651\n",
            "Epoch 18652\n",
            "Epoch 18653\n",
            "Epoch 18654\n",
            "Epoch 18655\n",
            "Epoch 18656\n",
            "Epoch 18657\n",
            "Epoch 18658\n",
            "Epoch 18659\n",
            "Epoch 18660\n",
            "Epoch 18661\n",
            "Epoch 18662\n",
            "Epoch 18663\n",
            "Epoch 18664\n",
            "Epoch 18665\n",
            "Epoch 18666\n",
            "Epoch 18667\n",
            "Epoch 18668\n",
            "Epoch 18669\n",
            "Epoch 18670\n",
            "Epoch 18671\n",
            "Epoch 18672\n",
            "Epoch 18673\n",
            "Epoch 18674\n",
            "Epoch 18675\n",
            "Epoch 18676\n",
            "Epoch 18677\n",
            "Epoch 18678\n",
            "Epoch 18679\n",
            "Epoch 18680\n",
            "Epoch 18681\n",
            "Epoch 18682\n",
            "Epoch 18683\n",
            "Epoch 18684\n",
            "Epoch 18685\n",
            "Epoch 18686\n",
            "Epoch 18687\n",
            "Epoch 18688\n",
            "Epoch 18689\n",
            "Epoch 18690\n",
            "Epoch 18691\n",
            "Epoch 18692\n",
            "Epoch 18693\n",
            "Epoch 18694\n",
            "Epoch 18695\n",
            "Epoch 18696\n",
            "Epoch 18697\n",
            "Epoch 18698\n",
            "Epoch 18699\n",
            "Epoch 18700\n",
            "Epoch 18701\n",
            "Epoch 18702\n",
            "Epoch 18703\n",
            "Epoch 18704\n",
            "Epoch 18705\n",
            "Epoch 18706\n",
            "Epoch 18707\n",
            "Epoch 18708\n",
            "Epoch 18709\n",
            "Epoch 18710\n",
            "Epoch 18711\n",
            "Epoch 18712\n",
            "Epoch 18713\n",
            "Epoch 18714\n",
            "Epoch 18715\n",
            "Epoch 18716\n",
            "Epoch 18717\n",
            "Epoch 18718\n",
            "Epoch 18719\n",
            "Epoch 18720\n",
            "Epoch 18721\n",
            "Epoch 18722\n",
            "Epoch 18723\n",
            "Epoch 18724\n",
            "Epoch 18725\n",
            "Epoch 18726\n",
            "Epoch 18727\n",
            "Epoch 18728\n",
            "Epoch 18729\n",
            "Epoch 18730\n",
            "Epoch 18731\n",
            "Epoch 18732\n",
            "Epoch 18733\n",
            "Epoch 18734\n",
            "Epoch 18735\n",
            "Epoch 18736\n",
            "Epoch 18737\n",
            "Epoch 18738\n",
            "Epoch 18739\n",
            "Epoch 18740\n",
            "Epoch 18741\n",
            "Epoch 18742\n",
            "Epoch 18743\n",
            "Epoch 18744\n",
            "Epoch 18745\n",
            "Epoch 18746\n",
            "Epoch 18747\n",
            "Epoch 18748\n",
            "Epoch 18749\n",
            "Epoch 18750\n",
            "Epoch 18751\n",
            "Epoch 18752\n",
            "Epoch 18753\n",
            "Epoch 18754\n",
            "Epoch 18755\n",
            "Epoch 18756\n",
            "Epoch 18757\n",
            "Epoch 18758\n",
            "Epoch 18759\n",
            "Epoch 18760\n",
            "Epoch 18761\n",
            "Epoch 18762\n",
            "Epoch 18763\n",
            "Epoch 18764\n",
            "Epoch 18765\n",
            "Epoch 18766\n",
            "Epoch 18767\n",
            "Epoch 18768\n",
            "Epoch 18769\n",
            "Epoch 18770\n",
            "Epoch 18771\n",
            "Epoch 18772\n",
            "Epoch 18773\n",
            "Epoch 18774\n",
            "Epoch 18775\n",
            "Epoch 18776\n",
            "Epoch 18777\n",
            "Epoch 18778\n",
            "Epoch 18779\n",
            "Epoch 18780\n",
            "Epoch 18781\n",
            "Epoch 18782\n",
            "Epoch 18783\n",
            "Epoch 18784\n",
            "Epoch 18785\n",
            "Epoch 18786\n",
            "Epoch 18787\n",
            "Epoch 18788\n",
            "Epoch 18789\n",
            "Epoch 18790\n",
            "Epoch 18791\n",
            "Epoch 18792\n",
            "Epoch 18793\n",
            "Epoch 18794\n",
            "Epoch 18795\n",
            "Epoch 18796\n",
            "Epoch 18797\n",
            "Epoch 18798\n",
            "Epoch 18799\n",
            "Epoch 18800\n",
            "Epoch 18801\n",
            "Epoch 18802\n",
            "Epoch 18803\n",
            "Epoch 18804\n",
            "Epoch 18805\n",
            "Epoch 18806\n",
            "Epoch 18807\n",
            "Epoch 18808\n",
            "Epoch 18809\n",
            "Epoch 18810\n",
            "Epoch 18811\n",
            "Epoch 18812\n",
            "Epoch 18813\n",
            "Epoch 18814\n",
            "Epoch 18815\n",
            "Epoch 18816\n",
            "Epoch 18817\n",
            "Epoch 18818\n",
            "Epoch 18819\n",
            "Epoch 18820\n",
            "Epoch 18821\n",
            "Epoch 18822\n",
            "Epoch 18823\n",
            "Epoch 18824\n",
            "Epoch 18825\n",
            "Epoch 18826\n",
            "Epoch 18827\n",
            "Epoch 18828\n",
            "Epoch 18829\n",
            "Epoch 18830\n",
            "Epoch 18831\n",
            "Epoch 18832\n",
            "Epoch 18833\n",
            "Epoch 18834\n",
            "Epoch 18835\n",
            "Epoch 18836\n",
            "Epoch 18837\n",
            "Epoch 18838\n",
            "Epoch 18839\n",
            "Epoch 18840\n",
            "Epoch 18841\n",
            "Epoch 18842\n",
            "Epoch 18843\n",
            "Epoch 18844\n",
            "Epoch 18845\n",
            "Epoch 18846\n",
            "Epoch 18847\n",
            "Epoch 18848\n",
            "Epoch 18849\n",
            "Epoch 18850\n",
            "Epoch 18851\n",
            "Epoch 18852\n",
            "Epoch 18853\n",
            "Epoch 18854\n",
            "Epoch 18855\n",
            "Epoch 18856\n",
            "Epoch 18857\n",
            "Epoch 18858\n",
            "Epoch 18859\n",
            "Epoch 18860\n",
            "Epoch 18861\n",
            "Epoch 18862\n",
            "Epoch 18863\n",
            "Epoch 18864\n",
            "Epoch 18865\n",
            "Epoch 18866\n",
            "Epoch 18867\n",
            "Epoch 18868\n",
            "Epoch 18869\n",
            "Epoch 18870\n",
            "Epoch 18871\n",
            "Epoch 18872\n",
            "Epoch 18873\n",
            "Epoch 18874\n",
            "Epoch 18875\n",
            "Epoch 18876\n",
            "Epoch 18877\n",
            "Epoch 18878\n",
            "Epoch 18879\n",
            "Epoch 18880\n",
            "Epoch 18881\n",
            "Epoch 18882\n",
            "Epoch 18883\n",
            "Epoch 18884\n",
            "Epoch 18885\n",
            "Epoch 18886\n",
            "Epoch 18887\n",
            "Epoch 18888\n",
            "Epoch 18889\n",
            "Epoch 18890\n",
            "Epoch 18891\n",
            "Epoch 18892\n",
            "Epoch 18893\n",
            "Epoch 18894\n",
            "Epoch 18895\n",
            "Epoch 18896\n",
            "Epoch 18897\n",
            "Epoch 18898\n",
            "Epoch 18899\n",
            "Epoch 18900\n",
            "Epoch 18901\n",
            "Epoch 18902\n",
            "Epoch 18903\n",
            "Epoch 18904\n",
            "Epoch 18905\n",
            "Epoch 18906\n",
            "Epoch 18907\n",
            "Epoch 18908\n",
            "Epoch 18909\n",
            "Epoch 18910\n",
            "Epoch 18911\n",
            "Epoch 18912\n",
            "Epoch 18913\n",
            "Epoch 18914\n",
            "Epoch 18915\n",
            "Epoch 18916\n",
            "Epoch 18917\n",
            "Epoch 18918\n",
            "Epoch 18919\n",
            "Epoch 18920\n",
            "Epoch 18921\n",
            "Epoch 18922\n",
            "Epoch 18923\n",
            "Epoch 18924\n",
            "Epoch 18925\n",
            "Epoch 18926\n",
            "Epoch 18927\n",
            "Epoch 18928\n",
            "Epoch 18929\n",
            "Epoch 18930\n",
            "Epoch 18931\n",
            "Epoch 18932\n",
            "Epoch 18933\n",
            "Epoch 18934\n",
            "Epoch 18935\n",
            "Epoch 18936\n",
            "Epoch 18937\n",
            "Epoch 18938\n",
            "Epoch 18939\n",
            "Epoch 18940\n",
            "Epoch 18941\n",
            "Epoch 18942\n",
            "Epoch 18943\n",
            "Epoch 18944\n",
            "Epoch 18945\n",
            "Epoch 18946\n",
            "Epoch 18947\n",
            "Epoch 18948\n",
            "Epoch 18949\n",
            "Epoch 18950\n",
            "Epoch 18951\n",
            "Epoch 18952\n",
            "Epoch 18953\n",
            "Epoch 18954\n",
            "Epoch 18955\n",
            "Epoch 18956\n",
            "Epoch 18957\n",
            "Epoch 18958\n",
            "Epoch 18959\n",
            "Epoch 18960\n",
            "Epoch 18961\n",
            "Epoch 18962\n",
            "Epoch 18963\n",
            "Epoch 18964\n",
            "Epoch 18965\n",
            "Epoch 18966\n",
            "Epoch 18967\n",
            "Epoch 18968\n",
            "Epoch 18969\n",
            "Epoch 18970\n",
            "Epoch 18971\n",
            "Epoch 18972\n",
            "Epoch 18973\n",
            "Epoch 18974\n",
            "Epoch 18975\n",
            "Epoch 18976\n",
            "Epoch 18977\n",
            "Epoch 18978\n",
            "Epoch 18979\n",
            "Epoch 18980\n",
            "Epoch 18981\n",
            "Epoch 18982\n",
            "Epoch 18983\n",
            "Epoch 18984\n",
            "Epoch 18985\n",
            "Epoch 18986\n",
            "Epoch 18987\n",
            "Epoch 18988\n",
            "Epoch 18989\n",
            "Epoch 18990\n",
            "Epoch 18991\n",
            "Epoch 18992\n",
            "Epoch 18993\n",
            "Epoch 18994\n",
            "Epoch 18995\n",
            "Epoch 18996\n",
            "Epoch 18997\n",
            "Epoch 18998\n",
            "Epoch 18999\n",
            "Epoch 19000\n",
            "Epoch 19001\n",
            "Epoch 19002\n",
            "Epoch 19003\n",
            "Epoch 19004\n",
            "Epoch 19005\n",
            "Epoch 19006\n",
            "Epoch 19007\n",
            "Epoch 19008\n",
            "Epoch 19009\n",
            "Epoch 19010\n",
            "Epoch 19011\n",
            "Epoch 19012\n",
            "Epoch 19013\n",
            "Epoch 19014\n",
            "Epoch 19015\n",
            "Epoch 19016\n",
            "Epoch 19017\n",
            "Epoch 19018\n",
            "Epoch 19019\n",
            "Epoch 19020\n",
            "Epoch 19021\n",
            "Epoch 19022\n",
            "Epoch 19023\n",
            "Epoch 19024\n",
            "Epoch 19025\n",
            "Epoch 19026\n",
            "Epoch 19027\n",
            "Epoch 19028\n",
            "Epoch 19029\n",
            "Epoch 19030\n",
            "Epoch 19031\n",
            "Epoch 19032\n",
            "Epoch 19033\n",
            "Epoch 19034\n",
            "Epoch 19035\n",
            "Epoch 19036\n",
            "Epoch 19037\n",
            "Epoch 19038\n",
            "Epoch 19039\n",
            "Epoch 19040\n",
            "Epoch 19041\n",
            "Epoch 19042\n",
            "Epoch 19043\n",
            "Epoch 19044\n",
            "Epoch 19045\n",
            "Epoch 19046\n",
            "Epoch 19047\n",
            "Epoch 19048\n",
            "Epoch 19049\n",
            "Epoch 19050\n",
            "Epoch 19051\n",
            "Epoch 19052\n",
            "Epoch 19053\n",
            "Epoch 19054\n",
            "Epoch 19055\n",
            "Epoch 19056\n",
            "Epoch 19057\n",
            "Epoch 19058\n",
            "Epoch 19059\n",
            "Epoch 19060\n",
            "Epoch 19061\n",
            "Epoch 19062\n",
            "Epoch 19063\n",
            "Epoch 19064\n",
            "Epoch 19065\n",
            "Epoch 19066\n",
            "Epoch 19067\n",
            "Epoch 19068\n",
            "Epoch 19069\n",
            "Epoch 19070\n",
            "Epoch 19071\n",
            "Epoch 19072\n",
            "Epoch 19073\n",
            "Epoch 19074\n",
            "Epoch 19075\n",
            "Epoch 19076\n",
            "Epoch 19077\n",
            "Epoch 19078\n",
            "Epoch 19079\n",
            "Epoch 19080\n",
            "Epoch 19081\n",
            "Epoch 19082\n",
            "Epoch 19083\n",
            "Epoch 19084\n",
            "Epoch 19085\n",
            "Epoch 19086\n",
            "Epoch 19087\n",
            "Epoch 19088\n",
            "Epoch 19089\n",
            "Epoch 19090\n",
            "Epoch 19091\n",
            "Epoch 19092\n",
            "Epoch 19093\n",
            "Epoch 19094\n",
            "Epoch 19095\n",
            "Epoch 19096\n",
            "Epoch 19097\n",
            "Epoch 19098\n",
            "Epoch 19099\n",
            "Epoch 19100\n",
            "Epoch 19101\n",
            "Epoch 19102\n",
            "Epoch 19103\n",
            "Epoch 19104\n",
            "Epoch 19105\n",
            "Epoch 19106\n",
            "Epoch 19107\n",
            "Epoch 19108\n",
            "Epoch 19109\n",
            "Epoch 19110\n",
            "Epoch 19111\n",
            "Epoch 19112\n",
            "Epoch 19113\n",
            "Epoch 19114\n",
            "Epoch 19115\n",
            "Epoch 19116\n",
            "Epoch 19117\n",
            "Epoch 19118\n",
            "Epoch 19119\n",
            "Epoch 19120\n",
            "Epoch 19121\n",
            "Epoch 19122\n",
            "Epoch 19123\n",
            "Epoch 19124\n",
            "Epoch 19125\n",
            "Epoch 19126\n",
            "Epoch 19127\n",
            "Epoch 19128\n",
            "Epoch 19129\n",
            "Epoch 19130\n",
            "Epoch 19131\n",
            "Epoch 19132\n",
            "Epoch 19133\n",
            "Epoch 19134\n",
            "Epoch 19135\n",
            "Epoch 19136\n",
            "Epoch 19137\n",
            "Epoch 19138\n",
            "Epoch 19139\n",
            "Epoch 19140\n",
            "Epoch 19141\n",
            "Epoch 19142\n",
            "Epoch 19143\n",
            "Epoch 19144\n",
            "Epoch 19145\n",
            "Epoch 19146\n",
            "Epoch 19147\n",
            "Epoch 19148\n",
            "Epoch 19149\n",
            "Epoch 19150\n",
            "Epoch 19151\n",
            "Epoch 19152\n",
            "Epoch 19153\n",
            "Epoch 19154\n",
            "Epoch 19155\n",
            "Epoch 19156\n",
            "Epoch 19157\n",
            "Epoch 19158\n",
            "Epoch 19159\n",
            "Epoch 19160\n",
            "Epoch 19161\n",
            "Epoch 19162\n",
            "Epoch 19163\n",
            "Epoch 19164\n",
            "Epoch 19165\n",
            "Epoch 19166\n",
            "Epoch 19167\n",
            "Epoch 19168\n",
            "Epoch 19169\n",
            "Epoch 19170\n",
            "Epoch 19171\n",
            "Epoch 19172\n",
            "Epoch 19173\n",
            "Epoch 19174\n",
            "Epoch 19175\n",
            "Epoch 19176\n",
            "Epoch 19177\n",
            "Epoch 19178\n",
            "Epoch 19179\n",
            "Epoch 19180\n",
            "Epoch 19181\n",
            "Epoch 19182\n",
            "Epoch 19183\n",
            "Epoch 19184\n",
            "Epoch 19185\n",
            "Epoch 19186\n",
            "Epoch 19187\n",
            "Epoch 19188\n",
            "Epoch 19189\n",
            "Epoch 19190\n",
            "Epoch 19191\n",
            "Epoch 19192\n",
            "Epoch 19193\n",
            "Epoch 19194\n",
            "Epoch 19195\n",
            "Epoch 19196\n",
            "Epoch 19197\n",
            "Epoch 19198\n",
            "Epoch 19199\n",
            "Epoch 19200\n",
            "Epoch 19201\n",
            "Epoch 19202\n",
            "Epoch 19203\n",
            "Epoch 19204\n",
            "Epoch 19205\n",
            "Epoch 19206\n",
            "Epoch 19207\n",
            "Epoch 19208\n",
            "Epoch 19209\n",
            "Epoch 19210\n",
            "Epoch 19211\n",
            "Epoch 19212\n",
            "Epoch 19213\n",
            "Epoch 19214\n",
            "Epoch 19215\n",
            "Epoch 19216\n",
            "Epoch 19217\n",
            "Epoch 19218\n",
            "Epoch 19219\n",
            "Epoch 19220\n",
            "Epoch 19221\n",
            "Epoch 19222\n",
            "Epoch 19223\n",
            "Epoch 19224\n",
            "Epoch 19225\n",
            "Epoch 19226\n",
            "Epoch 19227\n",
            "Epoch 19228\n",
            "Epoch 19229\n",
            "Epoch 19230\n",
            "Epoch 19231\n",
            "Epoch 19232\n",
            "Epoch 19233\n",
            "Epoch 19234\n",
            "Epoch 19235\n",
            "Epoch 19236\n",
            "Epoch 19237\n",
            "Epoch 19238\n",
            "Epoch 19239\n",
            "Epoch 19240\n",
            "Epoch 19241\n",
            "Epoch 19242\n",
            "Epoch 19243\n",
            "Epoch 19244\n",
            "Epoch 19245\n",
            "Epoch 19246\n",
            "Epoch 19247\n",
            "Epoch 19248\n",
            "Epoch 19249\n",
            "Epoch 19250\n",
            "Epoch 19251\n",
            "Epoch 19252\n",
            "Epoch 19253\n",
            "Epoch 19254\n",
            "Epoch 19255\n",
            "Epoch 19256\n",
            "Epoch 19257\n",
            "Epoch 19258\n",
            "Epoch 19259\n",
            "Epoch 19260\n",
            "Epoch 19261\n",
            "Epoch 19262\n",
            "Epoch 19263\n",
            "Epoch 19264\n",
            "Epoch 19265\n",
            "Epoch 19266\n",
            "Epoch 19267\n",
            "Epoch 19268\n",
            "Epoch 19269\n",
            "Epoch 19270\n",
            "Epoch 19271\n",
            "Epoch 19272\n",
            "Epoch 19273\n",
            "Epoch 19274\n",
            "Epoch 19275\n",
            "Epoch 19276\n",
            "Epoch 19277\n",
            "Epoch 19278\n",
            "Epoch 19279\n",
            "Epoch 19280\n",
            "Epoch 19281\n",
            "Epoch 19282\n",
            "Epoch 19283\n",
            "Epoch 19284\n",
            "Epoch 19285\n",
            "Epoch 19286\n",
            "Epoch 19287\n",
            "Epoch 19288\n",
            "Epoch 19289\n",
            "Epoch 19290\n",
            "Epoch 19291\n",
            "Epoch 19292\n",
            "Epoch 19293\n",
            "Epoch 19294\n",
            "Epoch 19295\n",
            "Epoch 19296\n",
            "Epoch 19297\n",
            "Epoch 19298\n",
            "Epoch 19299\n",
            "Epoch 19300\n",
            "Epoch 19301\n",
            "Epoch 19302\n",
            "Epoch 19303\n",
            "Epoch 19304\n",
            "Epoch 19305\n",
            "Epoch 19306\n",
            "Epoch 19307\n",
            "Epoch 19308\n",
            "Epoch 19309\n",
            "Epoch 19310\n",
            "Epoch 19311\n",
            "Epoch 19312\n",
            "Epoch 19313\n",
            "Epoch 19314\n",
            "Epoch 19315\n",
            "Epoch 19316\n",
            "Epoch 19317\n",
            "Epoch 19318\n",
            "Epoch 19319\n",
            "Epoch 19320\n",
            "Epoch 19321\n",
            "Epoch 19322\n",
            "Epoch 19323\n",
            "Epoch 19324\n",
            "Epoch 19325\n",
            "Epoch 19326\n",
            "Epoch 19327\n",
            "Epoch 19328\n",
            "Epoch 19329\n",
            "Epoch 19330\n",
            "Epoch 19331\n",
            "Epoch 19332\n",
            "Epoch 19333\n",
            "Epoch 19334\n",
            "Epoch 19335\n",
            "Epoch 19336\n",
            "Epoch 19337\n",
            "Epoch 19338\n",
            "Epoch 19339\n",
            "Epoch 19340\n",
            "Epoch 19341\n",
            "Epoch 19342\n",
            "Epoch 19343\n",
            "Epoch 19344\n",
            "Epoch 19345\n",
            "Epoch 19346\n",
            "Epoch 19347\n",
            "Epoch 19348\n",
            "Epoch 19349\n",
            "Epoch 19350\n",
            "Epoch 19351\n",
            "Epoch 19352\n",
            "Epoch 19353\n",
            "Epoch 19354\n",
            "Epoch 19355\n",
            "Epoch 19356\n",
            "Epoch 19357\n",
            "Epoch 19358\n",
            "Epoch 19359\n",
            "Epoch 19360\n",
            "Epoch 19361\n",
            "Epoch 19362\n",
            "Epoch 19363\n",
            "Epoch 19364\n",
            "Epoch 19365\n",
            "Epoch 19366\n",
            "Epoch 19367\n",
            "Epoch 19368\n",
            "Epoch 19369\n",
            "Epoch 19370\n",
            "Epoch 19371\n",
            "Epoch 19372\n",
            "Epoch 19373\n",
            "Epoch 19374\n",
            "Epoch 19375\n",
            "Epoch 19376\n",
            "Epoch 19377\n",
            "Epoch 19378\n",
            "Epoch 19379\n",
            "Epoch 19380\n",
            "Epoch 19381\n",
            "Epoch 19382\n",
            "Epoch 19383\n",
            "Epoch 19384\n",
            "Epoch 19385\n",
            "Epoch 19386\n",
            "Epoch 19387\n",
            "Epoch 19388\n",
            "Epoch 19389\n",
            "Epoch 19390\n",
            "Epoch 19391\n",
            "Epoch 19392\n",
            "Epoch 19393\n",
            "Epoch 19394\n",
            "Epoch 19395\n",
            "Epoch 19396\n",
            "Epoch 19397\n",
            "Epoch 19398\n",
            "Epoch 19399\n",
            "Epoch 19400\n",
            "Epoch 19401\n",
            "Epoch 19402\n",
            "Epoch 19403\n",
            "Epoch 19404\n",
            "Epoch 19405\n",
            "Epoch 19406\n",
            "Epoch 19407\n",
            "Epoch 19408\n",
            "Epoch 19409\n",
            "Epoch 19410\n",
            "Epoch 19411\n",
            "Epoch 19412\n",
            "Epoch 19413\n",
            "Epoch 19414\n",
            "Epoch 19415\n",
            "Epoch 19416\n",
            "Epoch 19417\n",
            "Epoch 19418\n",
            "Epoch 19419\n",
            "Epoch 19420\n",
            "Epoch 19421\n",
            "Epoch 19422\n",
            "Epoch 19423\n",
            "Epoch 19424\n",
            "Epoch 19425\n",
            "Epoch 19426\n",
            "Epoch 19427\n",
            "Epoch 19428\n",
            "Epoch 19429\n",
            "Epoch 19430\n",
            "Epoch 19431\n",
            "Epoch 19432\n",
            "Epoch 19433\n",
            "Epoch 19434\n",
            "Epoch 19435\n",
            "Epoch 19436\n",
            "Epoch 19437\n",
            "Epoch 19438\n",
            "Epoch 19439\n",
            "Epoch 19440\n",
            "Epoch 19441\n",
            "Epoch 19442\n",
            "Epoch 19443\n",
            "Epoch 19444\n",
            "Epoch 19445\n",
            "Epoch 19446\n",
            "Epoch 19447\n",
            "Epoch 19448\n",
            "Epoch 19449\n",
            "Epoch 19450\n",
            "Epoch 19451\n",
            "Epoch 19452\n",
            "Epoch 19453\n",
            "Epoch 19454\n",
            "Epoch 19455\n",
            "Epoch 19456\n",
            "Epoch 19457\n",
            "Epoch 19458\n",
            "Epoch 19459\n",
            "Epoch 19460\n",
            "Epoch 19461\n",
            "Epoch 19462\n",
            "Epoch 19463\n",
            "Epoch 19464\n",
            "Epoch 19465\n",
            "Epoch 19466\n",
            "Epoch 19467\n",
            "Epoch 19468\n",
            "Epoch 19469\n",
            "Epoch 19470\n",
            "Epoch 19471\n",
            "Epoch 19472\n",
            "Epoch 19473\n",
            "Epoch 19474\n",
            "Epoch 19475\n",
            "Epoch 19476\n",
            "Epoch 19477\n",
            "Epoch 19478\n",
            "Epoch 19479\n",
            "Epoch 19480\n",
            "Epoch 19481\n",
            "Epoch 19482\n",
            "Epoch 19483\n",
            "Epoch 19484\n",
            "Epoch 19485\n",
            "Epoch 19486\n",
            "Epoch 19487\n",
            "Epoch 19488\n",
            "Epoch 19489\n",
            "Epoch 19490\n",
            "Epoch 19491\n",
            "Epoch 19492\n",
            "Epoch 19493\n",
            "Epoch 19494\n",
            "Epoch 19495\n",
            "Epoch 19496\n",
            "Epoch 19497\n",
            "Epoch 19498\n",
            "Epoch 19499\n",
            "Epoch 19500\n",
            "Epoch 19501\n",
            "Epoch 19502\n",
            "Epoch 19503\n",
            "Epoch 19504\n",
            "Epoch 19505\n",
            "Epoch 19506\n",
            "Epoch 19507\n",
            "Epoch 19508\n",
            "Epoch 19509\n",
            "Epoch 19510\n",
            "Epoch 19511\n",
            "Epoch 19512\n",
            "Epoch 19513\n",
            "Epoch 19514\n",
            "Epoch 19515\n",
            "Epoch 19516\n",
            "Epoch 19517\n",
            "Epoch 19518\n",
            "Epoch 19519\n",
            "Epoch 19520\n",
            "Epoch 19521\n",
            "Epoch 19522\n",
            "Epoch 19523\n",
            "Epoch 19524\n",
            "Epoch 19525\n",
            "Epoch 19526\n",
            "Epoch 19527\n",
            "Epoch 19528\n",
            "Epoch 19529\n",
            "Epoch 19530\n",
            "Epoch 19531\n",
            "Epoch 19532\n",
            "Epoch 19533\n",
            "Epoch 19534\n",
            "Epoch 19535\n",
            "Epoch 19536\n",
            "Epoch 19537\n",
            "Epoch 19538\n",
            "Epoch 19539\n",
            "Epoch 19540\n",
            "Epoch 19541\n",
            "Epoch 19542\n",
            "Epoch 19543\n",
            "Epoch 19544\n",
            "Epoch 19545\n",
            "Epoch 19546\n",
            "Epoch 19547\n",
            "Epoch 19548\n",
            "Epoch 19549\n",
            "Epoch 19550\n",
            "Epoch 19551\n",
            "Epoch 19552\n",
            "Epoch 19553\n",
            "Epoch 19554\n",
            "Epoch 19555\n",
            "Epoch 19556\n",
            "Epoch 19557\n",
            "Epoch 19558\n",
            "Epoch 19559\n",
            "Epoch 19560\n",
            "Epoch 19561\n",
            "Epoch 19562\n",
            "Epoch 19563\n",
            "Epoch 19564\n",
            "Epoch 19565\n",
            "Epoch 19566\n",
            "Epoch 19567\n",
            "Epoch 19568\n",
            "Epoch 19569\n",
            "Epoch 19570\n",
            "Epoch 19571\n",
            "Epoch 19572\n",
            "Epoch 19573\n",
            "Epoch 19574\n",
            "Epoch 19575\n",
            "Epoch 19576\n",
            "Epoch 19577\n",
            "Epoch 19578\n",
            "Epoch 19579\n",
            "Epoch 19580\n",
            "Epoch 19581\n",
            "Epoch 19582\n",
            "Epoch 19583\n",
            "Epoch 19584\n",
            "Epoch 19585\n",
            "Epoch 19586\n",
            "Epoch 19587\n",
            "Epoch 19588\n",
            "Epoch 19589\n",
            "Epoch 19590\n",
            "Epoch 19591\n",
            "Epoch 19592\n",
            "Epoch 19593\n",
            "Epoch 19594\n",
            "Epoch 19595\n",
            "Epoch 19596\n",
            "Epoch 19597\n",
            "Epoch 19598\n",
            "Epoch 19599\n",
            "Epoch 19600\n",
            "Epoch 19601\n",
            "Epoch 19602\n",
            "Epoch 19603\n",
            "Epoch 19604\n",
            "Epoch 19605\n",
            "Epoch 19606\n",
            "Epoch 19607\n",
            "Epoch 19608\n",
            "Epoch 19609\n",
            "Epoch 19610\n",
            "Epoch 19611\n",
            "Epoch 19612\n",
            "Epoch 19613\n",
            "Epoch 19614\n",
            "Epoch 19615\n",
            "Epoch 19616\n",
            "Epoch 19617\n",
            "Epoch 19618\n",
            "Epoch 19619\n",
            "Epoch 19620\n",
            "Epoch 19621\n",
            "Epoch 19622\n",
            "Epoch 19623\n",
            "Epoch 19624\n",
            "Epoch 19625\n",
            "Epoch 19626\n",
            "Epoch 19627\n",
            "Epoch 19628\n",
            "Epoch 19629\n",
            "Epoch 19630\n",
            "Epoch 19631\n",
            "Epoch 19632\n",
            "Epoch 19633\n",
            "Epoch 19634\n",
            "Epoch 19635\n",
            "Epoch 19636\n",
            "Epoch 19637\n",
            "Epoch 19638\n",
            "Epoch 19639\n",
            "Epoch 19640\n",
            "Epoch 19641\n",
            "Epoch 19642\n",
            "Epoch 19643\n",
            "Epoch 19644\n",
            "Epoch 19645\n",
            "Epoch 19646\n",
            "Epoch 19647\n",
            "Epoch 19648\n",
            "Epoch 19649\n",
            "Epoch 19650\n",
            "Epoch 19651\n",
            "Epoch 19652\n",
            "Epoch 19653\n",
            "Epoch 19654\n",
            "Epoch 19655\n",
            "Epoch 19656\n",
            "Epoch 19657\n",
            "Epoch 19658\n",
            "Epoch 19659\n",
            "Epoch 19660\n",
            "Epoch 19661\n",
            "Epoch 19662\n",
            "Epoch 19663\n",
            "Epoch 19664\n",
            "Epoch 19665\n",
            "Epoch 19666\n",
            "Epoch 19667\n",
            "Epoch 19668\n",
            "Epoch 19669\n",
            "Epoch 19670\n",
            "Epoch 19671\n",
            "Epoch 19672\n",
            "Epoch 19673\n",
            "Epoch 19674\n",
            "Epoch 19675\n",
            "Epoch 19676\n",
            "Epoch 19677\n",
            "Epoch 19678\n",
            "Epoch 19679\n",
            "Epoch 19680\n",
            "Epoch 19681\n",
            "Epoch 19682\n",
            "Epoch 19683\n",
            "Epoch 19684\n",
            "Epoch 19685\n",
            "Epoch 19686\n",
            "Epoch 19687\n",
            "Epoch 19688\n",
            "Epoch 19689\n",
            "Epoch 19690\n",
            "Epoch 19691\n",
            "Epoch 19692\n",
            "Epoch 19693\n",
            "Epoch 19694\n",
            "Epoch 19695\n",
            "Epoch 19696\n",
            "Epoch 19697\n",
            "Epoch 19698\n",
            "Epoch 19699\n",
            "Epoch 19700\n",
            "Epoch 19701\n",
            "Epoch 19702\n",
            "Epoch 19703\n",
            "Epoch 19704\n",
            "Epoch 19705\n",
            "Epoch 19706\n",
            "Epoch 19707\n",
            "Epoch 19708\n",
            "Epoch 19709\n",
            "Epoch 19710\n",
            "Epoch 19711\n",
            "Epoch 19712\n",
            "Epoch 19713\n",
            "Epoch 19714\n",
            "Epoch 19715\n",
            "Epoch 19716\n",
            "Epoch 19717\n",
            "Epoch 19718\n",
            "Epoch 19719\n",
            "Epoch 19720\n",
            "Epoch 19721\n",
            "Epoch 19722\n",
            "Epoch 19723\n",
            "Epoch 19724\n",
            "Epoch 19725\n",
            "Epoch 19726\n",
            "Epoch 19727\n",
            "Epoch 19728\n",
            "Epoch 19729\n",
            "Epoch 19730\n",
            "Epoch 19731\n",
            "Epoch 19732\n",
            "Epoch 19733\n",
            "Epoch 19734\n",
            "Epoch 19735\n",
            "Epoch 19736\n",
            "Epoch 19737\n",
            "Epoch 19738\n",
            "Epoch 19739\n",
            "Epoch 19740\n",
            "Epoch 19741\n",
            "Epoch 19742\n",
            "Epoch 19743\n",
            "Epoch 19744\n",
            "Epoch 19745\n",
            "Epoch 19746\n",
            "Epoch 19747\n",
            "Epoch 19748\n",
            "Epoch 19749\n",
            "Epoch 19750\n",
            "Epoch 19751\n",
            "Epoch 19752\n",
            "Epoch 19753\n",
            "Epoch 19754\n",
            "Epoch 19755\n",
            "Epoch 19756\n",
            "Epoch 19757\n",
            "Epoch 19758\n",
            "Epoch 19759\n",
            "Epoch 19760\n",
            "Epoch 19761\n",
            "Epoch 19762\n",
            "Epoch 19763\n",
            "Epoch 19764\n",
            "Epoch 19765\n",
            "Epoch 19766\n",
            "Epoch 19767\n",
            "Epoch 19768\n",
            "Epoch 19769\n",
            "Epoch 19770\n",
            "Epoch 19771\n",
            "Epoch 19772\n",
            "Epoch 19773\n",
            "Epoch 19774\n",
            "Epoch 19775\n",
            "Epoch 19776\n",
            "Epoch 19777\n",
            "Epoch 19778\n",
            "Epoch 19779\n",
            "Epoch 19780\n",
            "Epoch 19781\n",
            "Epoch 19782\n",
            "Epoch 19783\n",
            "Epoch 19784\n",
            "Epoch 19785\n",
            "Epoch 19786\n",
            "Epoch 19787\n",
            "Epoch 19788\n",
            "Epoch 19789\n",
            "Epoch 19790\n",
            "Epoch 19791\n",
            "Epoch 19792\n",
            "Epoch 19793\n",
            "Epoch 19794\n",
            "Epoch 19795\n",
            "Epoch 19796\n",
            "Epoch 19797\n",
            "Epoch 19798\n",
            "Epoch 19799\n",
            "Epoch 19800\n",
            "Epoch 19801\n",
            "Epoch 19802\n",
            "Epoch 19803\n",
            "Epoch 19804\n",
            "Epoch 19805\n",
            "Epoch 19806\n",
            "Epoch 19807\n",
            "Epoch 19808\n",
            "Epoch 19809\n",
            "Epoch 19810\n",
            "Epoch 19811\n",
            "Epoch 19812\n",
            "Epoch 19813\n",
            "Epoch 19814\n",
            "Epoch 19815\n",
            "Epoch 19816\n",
            "Epoch 19817\n",
            "Epoch 19818\n",
            "Epoch 19819\n",
            "Epoch 19820\n",
            "Epoch 19821\n",
            "Epoch 19822\n",
            "Epoch 19823\n",
            "Epoch 19824\n",
            "Epoch 19825\n",
            "Epoch 19826\n",
            "Epoch 19827\n",
            "Epoch 19828\n",
            "Epoch 19829\n",
            "Epoch 19830\n",
            "Epoch 19831\n",
            "Epoch 19832\n",
            "Epoch 19833\n",
            "Epoch 19834\n",
            "Epoch 19835\n",
            "Epoch 19836\n",
            "Epoch 19837\n",
            "Epoch 19838\n",
            "Epoch 19839\n",
            "Epoch 19840\n",
            "Epoch 19841\n",
            "Epoch 19842\n",
            "Epoch 19843\n",
            "Epoch 19844\n",
            "Epoch 19845\n",
            "Epoch 19846\n",
            "Epoch 19847\n",
            "Epoch 19848\n",
            "Epoch 19849\n",
            "Epoch 19850\n",
            "Epoch 19851\n",
            "Epoch 19852\n",
            "Epoch 19853\n",
            "Epoch 19854\n",
            "Epoch 19855\n",
            "Epoch 19856\n",
            "Epoch 19857\n",
            "Epoch 19858\n",
            "Epoch 19859\n",
            "Epoch 19860\n",
            "Epoch 19861\n",
            "Epoch 19862\n",
            "Epoch 19863\n",
            "Epoch 19864\n",
            "Epoch 19865\n",
            "Epoch 19866\n",
            "Epoch 19867\n",
            "Epoch 19868\n",
            "Epoch 19869\n",
            "Epoch 19870\n",
            "Epoch 19871\n",
            "Epoch 19872\n",
            "Epoch 19873\n",
            "Epoch 19874\n",
            "Epoch 19875\n",
            "Epoch 19876\n",
            "Epoch 19877\n",
            "Epoch 19878\n",
            "Epoch 19879\n",
            "Epoch 19880\n",
            "Epoch 19881\n",
            "Epoch 19882\n",
            "Epoch 19883\n",
            "Epoch 19884\n",
            "Epoch 19885\n",
            "Epoch 19886\n",
            "Epoch 19887\n",
            "Epoch 19888\n",
            "Epoch 19889\n",
            "Epoch 19890\n",
            "Epoch 19891\n",
            "Epoch 19892\n",
            "Epoch 19893\n",
            "Epoch 19894\n",
            "Epoch 19895\n",
            "Epoch 19896\n",
            "Epoch 19897\n",
            "Epoch 19898\n",
            "Epoch 19899\n",
            "Epoch 19900\n",
            "Epoch 19901\n",
            "Epoch 19902\n",
            "Epoch 19903\n",
            "Epoch 19904\n",
            "Epoch 19905\n",
            "Epoch 19906\n",
            "Epoch 19907\n",
            "Epoch 19908\n",
            "Epoch 19909\n",
            "Epoch 19910\n",
            "Epoch 19911\n",
            "Epoch 19912\n",
            "Epoch 19913\n",
            "Epoch 19914\n",
            "Epoch 19915\n",
            "Epoch 19916\n",
            "Epoch 19917\n",
            "Epoch 19918\n",
            "Epoch 19919\n",
            "Epoch 19920\n",
            "Epoch 19921\n",
            "Epoch 19922\n",
            "Epoch 19923\n",
            "Epoch 19924\n",
            "Epoch 19925\n",
            "Epoch 19926\n",
            "Epoch 19927\n",
            "Epoch 19928\n",
            "Epoch 19929\n",
            "Epoch 19930\n",
            "Epoch 19931\n",
            "Epoch 19932\n",
            "Epoch 19933\n",
            "Epoch 19934\n",
            "Epoch 19935\n",
            "Epoch 19936\n",
            "Epoch 19937\n",
            "Epoch 19938\n",
            "Epoch 19939\n",
            "Epoch 19940\n",
            "Epoch 19941\n",
            "Epoch 19942\n",
            "Epoch 19943\n",
            "Epoch 19944\n",
            "Epoch 19945\n",
            "Epoch 19946\n",
            "Epoch 19947\n",
            "Epoch 19948\n",
            "Epoch 19949\n",
            "Epoch 19950\n",
            "Epoch 19951\n",
            "Epoch 19952\n",
            "Epoch 19953\n",
            "Epoch 19954\n",
            "Epoch 19955\n",
            "Epoch 19956\n",
            "Epoch 19957\n",
            "Epoch 19958\n",
            "Epoch 19959\n",
            "Epoch 19960\n",
            "Epoch 19961\n",
            "Epoch 19962\n",
            "Epoch 19963\n",
            "Epoch 19964\n",
            "Epoch 19965\n",
            "Epoch 19966\n",
            "Epoch 19967\n",
            "Epoch 19968\n",
            "Epoch 19969\n",
            "Epoch 19970\n",
            "Epoch 19971\n",
            "Epoch 19972\n",
            "Epoch 19973\n",
            "Epoch 19974\n",
            "Epoch 19975\n",
            "Epoch 19976\n",
            "Epoch 19977\n",
            "Epoch 19978\n",
            "Epoch 19979\n",
            "Epoch 19980\n",
            "Epoch 19981\n",
            "Epoch 19982\n",
            "Epoch 19983\n",
            "Epoch 19984\n",
            "Epoch 19985\n",
            "Epoch 19986\n",
            "Epoch 19987\n",
            "Epoch 19988\n",
            "Epoch 19989\n",
            "Epoch 19990\n",
            "Epoch 19991\n",
            "Epoch 19992\n",
            "Epoch 19993\n",
            "Epoch 19994\n",
            "Epoch 19995\n",
            "Epoch 19996\n",
            "Epoch 19997\n",
            "Epoch 19998\n",
            "Epoch 19999\n",
            "0.2219\n",
            "0.2565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAUnmejd9ezW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feda799-a4c8-4819-a90f-94ea50181b66"
      },
      "source": [
        "compete()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n",
            "Epoch 100\n",
            "Epoch 101\n",
            "Epoch 102\n",
            "Epoch 103\n",
            "Epoch 104\n",
            "Epoch 105\n",
            "Epoch 106\n",
            "Epoch 107\n",
            "Epoch 108\n",
            "Epoch 109\n",
            "Epoch 110\n",
            "Epoch 111\n",
            "Epoch 112\n",
            "Epoch 113\n",
            "Epoch 114\n",
            "Epoch 115\n",
            "Epoch 116\n",
            "Epoch 117\n",
            "Epoch 118\n",
            "Epoch 119\n",
            "Epoch 120\n",
            "Epoch 121\n",
            "Epoch 122\n",
            "Epoch 123\n",
            "Epoch 124\n",
            "Epoch 125\n",
            "Epoch 126\n",
            "Epoch 127\n",
            "Epoch 128\n",
            "Epoch 129\n",
            "Epoch 130\n",
            "Epoch 131\n",
            "Epoch 132\n",
            "Epoch 133\n",
            "Epoch 134\n",
            "Epoch 135\n",
            "Epoch 136\n",
            "Epoch 137\n",
            "Epoch 138\n",
            "Epoch 139\n",
            "Epoch 140\n",
            "Epoch 141\n",
            "Epoch 142\n",
            "Epoch 143\n",
            "Epoch 144\n",
            "Epoch 145\n",
            "Epoch 146\n",
            "Epoch 147\n",
            "Epoch 148\n",
            "Epoch 149\n",
            "Epoch 150\n",
            "Epoch 151\n",
            "Epoch 152\n",
            "Epoch 153\n",
            "Epoch 154\n",
            "Epoch 155\n",
            "Epoch 156\n",
            "Epoch 157\n",
            "Epoch 158\n",
            "Epoch 159\n",
            "Epoch 160\n",
            "Epoch 161\n",
            "Epoch 162\n",
            "Epoch 163\n",
            "Epoch 164\n",
            "Epoch 165\n",
            "Epoch 166\n",
            "Epoch 167\n",
            "Epoch 168\n",
            "Epoch 169\n",
            "Epoch 170\n",
            "Epoch 171\n",
            "Epoch 172\n",
            "Epoch 173\n",
            "Epoch 174\n",
            "Epoch 175\n",
            "Epoch 176\n",
            "Epoch 177\n",
            "Epoch 178\n",
            "Epoch 179\n",
            "Epoch 180\n",
            "Epoch 181\n",
            "Epoch 182\n",
            "Epoch 183\n",
            "Epoch 184\n",
            "Epoch 185\n",
            "Epoch 186\n",
            "Epoch 187\n",
            "Epoch 188\n",
            "Epoch 189\n",
            "Epoch 190\n",
            "Epoch 191\n",
            "Epoch 192\n",
            "Epoch 193\n",
            "Epoch 194\n",
            "Epoch 195\n",
            "Epoch 196\n",
            "Epoch 197\n",
            "Epoch 198\n",
            "Epoch 199\n",
            "Epoch 200\n",
            "Epoch 201\n",
            "Epoch 202\n",
            "Epoch 203\n",
            "Epoch 204\n",
            "Epoch 205\n",
            "Epoch 206\n",
            "Epoch 207\n",
            "Epoch 208\n",
            "Epoch 209\n",
            "Epoch 210\n",
            "Epoch 211\n",
            "Epoch 212\n",
            "Epoch 213\n",
            "Epoch 214\n",
            "Epoch 215\n",
            "Epoch 216\n",
            "Epoch 217\n",
            "Epoch 218\n",
            "Epoch 219\n",
            "Epoch 220\n",
            "Epoch 221\n",
            "Epoch 222\n",
            "Epoch 223\n",
            "Epoch 224\n",
            "Epoch 225\n",
            "Epoch 226\n",
            "Epoch 227\n",
            "Epoch 228\n",
            "Epoch 229\n",
            "Epoch 230\n",
            "Epoch 231\n",
            "Epoch 232\n",
            "Epoch 233\n",
            "Epoch 234\n",
            "Epoch 235\n",
            "Epoch 236\n",
            "Epoch 237\n",
            "Epoch 238\n",
            "Epoch 239\n",
            "Epoch 240\n",
            "Epoch 241\n",
            "Epoch 242\n",
            "Epoch 243\n",
            "Epoch 244\n",
            "Epoch 245\n",
            "Epoch 246\n",
            "Epoch 247\n",
            "Epoch 248\n",
            "Epoch 249\n",
            "Epoch 250\n",
            "Epoch 251\n",
            "Epoch 252\n",
            "Epoch 253\n",
            "Epoch 254\n",
            "Epoch 255\n",
            "Epoch 256\n",
            "Epoch 257\n",
            "Epoch 258\n",
            "Epoch 259\n",
            "Epoch 260\n",
            "Epoch 261\n",
            "Epoch 262\n",
            "Epoch 263\n",
            "Epoch 264\n",
            "Epoch 265\n",
            "Epoch 266\n",
            "Epoch 267\n",
            "Epoch 268\n",
            "Epoch 269\n",
            "Epoch 270\n",
            "Epoch 271\n",
            "Epoch 272\n",
            "Epoch 273\n",
            "Epoch 274\n",
            "Epoch 275\n",
            "Epoch 276\n",
            "Epoch 277\n",
            "Epoch 278\n",
            "Epoch 279\n",
            "Epoch 280\n",
            "Epoch 281\n",
            "Epoch 282\n",
            "Epoch 283\n",
            "Epoch 284\n",
            "Epoch 285\n",
            "Epoch 286\n",
            "Epoch 287\n",
            "Epoch 288\n",
            "Epoch 289\n",
            "Epoch 290\n",
            "Epoch 291\n",
            "Epoch 292\n",
            "Epoch 293\n",
            "Epoch 294\n",
            "Epoch 295\n",
            "Epoch 296\n",
            "Epoch 297\n",
            "Epoch 298\n",
            "Epoch 299\n",
            "Epoch 300\n",
            "Epoch 301\n",
            "Epoch 302\n",
            "Epoch 303\n",
            "Epoch 304\n",
            "Epoch 305\n",
            "Epoch 306\n",
            "Epoch 307\n",
            "Epoch 308\n",
            "Epoch 309\n",
            "Epoch 310\n",
            "Epoch 311\n",
            "Epoch 312\n",
            "Epoch 313\n",
            "Epoch 314\n",
            "Epoch 315\n",
            "Epoch 316\n",
            "Epoch 317\n",
            "Epoch 318\n",
            "Epoch 319\n",
            "Epoch 320\n",
            "Epoch 321\n",
            "Epoch 322\n",
            "Epoch 323\n",
            "Epoch 324\n",
            "Epoch 325\n",
            "Epoch 326\n",
            "Epoch 327\n",
            "Epoch 328\n",
            "Epoch 329\n",
            "Epoch 330\n",
            "Epoch 331\n",
            "Epoch 332\n",
            "Epoch 333\n",
            "Epoch 334\n",
            "Epoch 335\n",
            "Epoch 336\n",
            "Epoch 337\n",
            "Epoch 338\n",
            "Epoch 339\n",
            "Epoch 340\n",
            "Epoch 341\n",
            "Epoch 342\n",
            "Epoch 343\n",
            "Epoch 344\n",
            "Epoch 345\n",
            "Epoch 346\n",
            "Epoch 347\n",
            "Epoch 348\n",
            "Epoch 349\n",
            "Epoch 350\n",
            "Epoch 351\n",
            "Epoch 352\n",
            "Epoch 353\n",
            "Epoch 354\n",
            "Epoch 355\n",
            "Epoch 356\n",
            "Epoch 357\n",
            "Epoch 358\n",
            "Epoch 359\n",
            "Epoch 360\n",
            "Epoch 361\n",
            "Epoch 362\n",
            "Epoch 363\n",
            "Epoch 364\n",
            "Epoch 365\n",
            "Epoch 366\n",
            "Epoch 367\n",
            "Epoch 368\n",
            "Epoch 369\n",
            "Epoch 370\n",
            "Epoch 371\n",
            "Epoch 372\n",
            "Epoch 373\n",
            "Epoch 374\n",
            "Epoch 375\n",
            "Epoch 376\n",
            "Epoch 377\n",
            "Epoch 378\n",
            "Epoch 379\n",
            "Epoch 380\n",
            "Epoch 381\n",
            "Epoch 382\n",
            "Epoch 383\n",
            "Epoch 384\n",
            "Epoch 385\n",
            "Epoch 386\n",
            "Epoch 387\n",
            "Epoch 388\n",
            "Epoch 389\n",
            "Epoch 390\n",
            "Epoch 391\n",
            "Epoch 392\n",
            "Epoch 393\n",
            "Epoch 394\n",
            "Epoch 395\n",
            "Epoch 396\n",
            "Epoch 397\n",
            "Epoch 398\n",
            "Epoch 399\n",
            "Epoch 400\n",
            "Epoch 401\n",
            "Epoch 402\n",
            "Epoch 403\n",
            "Epoch 404\n",
            "Epoch 405\n",
            "Epoch 406\n",
            "Epoch 407\n",
            "Epoch 408\n",
            "Epoch 409\n",
            "Epoch 410\n",
            "Epoch 411\n",
            "Epoch 412\n",
            "Epoch 413\n",
            "Epoch 414\n",
            "Epoch 415\n",
            "Epoch 416\n",
            "Epoch 417\n",
            "Epoch 418\n",
            "Epoch 419\n",
            "Epoch 420\n",
            "Epoch 421\n",
            "Epoch 422\n",
            "Epoch 423\n",
            "Epoch 424\n",
            "Epoch 425\n",
            "Epoch 426\n",
            "Epoch 427\n",
            "Epoch 428\n",
            "Epoch 429\n",
            "Epoch 430\n",
            "Epoch 431\n",
            "Epoch 432\n",
            "Epoch 433\n",
            "Epoch 434\n",
            "Epoch 435\n",
            "Epoch 436\n",
            "Epoch 437\n",
            "Epoch 438\n",
            "Epoch 439\n",
            "Epoch 440\n",
            "Epoch 441\n",
            "Epoch 442\n",
            "Epoch 443\n",
            "Epoch 444\n",
            "Epoch 445\n",
            "Epoch 446\n",
            "Epoch 447\n",
            "Epoch 448\n",
            "Epoch 449\n",
            "Epoch 450\n",
            "Epoch 451\n",
            "Epoch 452\n",
            "Epoch 453\n",
            "Epoch 454\n",
            "Epoch 455\n",
            "Epoch 456\n",
            "Epoch 457\n",
            "Epoch 458\n",
            "Epoch 459\n",
            "Epoch 460\n",
            "Epoch 461\n",
            "Epoch 462\n",
            "Epoch 463\n",
            "Epoch 464\n",
            "Epoch 465\n",
            "Epoch 466\n",
            "Epoch 467\n",
            "Epoch 468\n",
            "Epoch 469\n",
            "Epoch 470\n",
            "Epoch 471\n",
            "Epoch 472\n",
            "Epoch 473\n",
            "Epoch 474\n",
            "Epoch 475\n",
            "Epoch 476\n",
            "Epoch 477\n",
            "Epoch 478\n",
            "Epoch 479\n",
            "Epoch 480\n",
            "Epoch 481\n",
            "Epoch 482\n",
            "Epoch 483\n",
            "Epoch 484\n",
            "Epoch 485\n",
            "Epoch 486\n",
            "Epoch 487\n",
            "Epoch 488\n",
            "Epoch 489\n",
            "Epoch 490\n",
            "Epoch 491\n",
            "Epoch 492\n",
            "Epoch 493\n",
            "Epoch 494\n",
            "Epoch 495\n",
            "Epoch 496\n",
            "Epoch 497\n",
            "Epoch 498\n",
            "Epoch 499\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5kIEyhk9fHB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f1b613f-b944-40cc-c7fd-dd9df05bdb4d"
      },
      "source": [
        "play()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:3\n",
            "-------------\n",
            "| 0 | 0 | x | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| 0 | 0 | x | \n",
            "-------------\n",
            "| 0 | * | * | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:4\n",
            "-------------\n",
            "| 0 | 0 | x | \n",
            "-------------\n",
            "| x | * | * | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| 0 | * | x | \n",
            "-------------\n",
            "| x | * | * | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:8\n",
            "-------------\n",
            "| 0 | * | x | \n",
            "-------------\n",
            "| x | * | * | \n",
            "-------------\n",
            "| 0 | x | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| * | * | x | \n",
            "-------------\n",
            "| x | * | * | \n",
            "-------------\n",
            "| 0 | x | 0 | \n",
            "-------------\n",
            "Input your position:9\n",
            "-------------\n",
            "| * | * | x | \n",
            "-------------\n",
            "| x | * | * | \n",
            "-------------\n",
            "| 0 | x | x | \n",
            "-------------\n",
            "Tie!\n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:1\n",
            "-------------\n",
            "| x | 0 | 0 | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| x | 0 | 0 | \n",
            "-------------\n",
            "| * | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:6\n",
            "-------------\n",
            "| x | 0 | 0 | \n",
            "-------------\n",
            "| * | * | x | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| x | 0 | 0 | \n",
            "-------------\n",
            "| * | * | x | \n",
            "-------------\n",
            "| * | 0 | 0 | \n",
            "-------------\n",
            "Input your position:3\n",
            "-------------\n",
            "| x | 0 | x | \n",
            "-------------\n",
            "| * | * | x | \n",
            "-------------\n",
            "| * | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| x | 0 | x | \n",
            "-------------\n",
            "| * | * | x | \n",
            "-------------\n",
            "| * | * | 0 | \n",
            "-------------\n",
            "Input your position:2\n",
            "Win!\n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:й\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-425fd712de3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-1b5476407c33>\u001b[0m in \u001b[0;36mplay\u001b[0;34m()\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mjudger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJudger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mplayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjudger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Win!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-1b5476407c33>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, show)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentPlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mhashValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-1b5476407c33>\u001b[0m in \u001b[0;36mtakeAction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtakeAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input your position:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBOARD_COLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'й'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notHQ59Arfxu"
      },
      "source": [
        "# Классификатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwJvRx2grhSC"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWBZXnd2DjE0"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq1jqPysDkvL"
      },
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zrlCbELDpwF"
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW-JwDjZDu4m"
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL8iE6lVDylX"
      },
      "source": [
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld47LPH5D2-s"
      },
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lYcyY2aD8Kf",
        "outputId": "7f439c55-34d7-424f-908d-635da879a6c2"
      },
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 5s - loss: 0.2805 - accuracy: 0.9195 - val_loss: 0.1478 - val_accuracy: 0.9574 - 5s/epoch - 17ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 4s - loss: 0.1128 - accuracy: 0.9677 - val_loss: 0.0940 - val_accuracy: 0.9716 - 4s/epoch - 15ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 4s - loss: 0.0729 - accuracy: 0.9791 - val_loss: 0.0797 - val_accuracy: 0.9760 - 4s/epoch - 15ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 4s - loss: 0.0514 - accuracy: 0.9852 - val_loss: 0.0700 - val_accuracy: 0.9783 - 4s/epoch - 15ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 5s - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.0665 - val_accuracy: 0.9790 - 5s/epoch - 15ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 5s - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.0591 - val_accuracy: 0.9808 - 5s/epoch - 15ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 5s - loss: 0.0200 - accuracy: 0.9954 - val_loss: 0.0562 - val_accuracy: 0.9819 - 5s/epoch - 16ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 5s - loss: 0.0153 - accuracy: 0.9962 - val_loss: 0.0592 - val_accuracy: 0.9810 - 5s/epoch - 16ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 4s - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0616 - val_accuracy: 0.9813 - 4s/epoch - 15ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 5s - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.0657 - val_accuracy: 0.9789 - 5s/epoch - 16ms/step\n",
            "Baseline Error: 2.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smix1LYRAEC0"
      },
      "source": [
        "# Новый раздел"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_KLZdpLbcnP"
      },
      "source": [
        "def generate_poly(a, n, noise, filename, size = 100):\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = np.zeros((size,1))\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    if len(a) != (n+1):\n",
        "        print(f'ERROR: Length of polynomial coefficients ({len(a)}) must be the same as polynomial degree {n}')\n",
        "        return\n",
        "    for i in range(0,n+1):\n",
        "        y = y + a[i] * np.power(x,i) + noise*(np.random.rand(size, 1) -0.5)\n",
        "    print(np.shape(x))\n",
        "    data = np.hstack((x,y))\n",
        "    np.savetxt(filename,data,delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzb7dHKbN-v"
      },
      "source": [
        "def generate_linear(a, b, noise, filename, size = 100):\n",
        "    print('Generating random data y = a*x + b')\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = a * x + b +  noise*a*(np.random.rand(size, 1) -0.5)\n",
        "    data = np.hstack((x,y))\n",
        "    np.savetxt(filename,data,delimiter=',')\n",
        "    return(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbz1IWA1a75d"
      },
      "source": [
        "def linear_regression_numpy(filename):\n",
        "    # now let's read it back\n",
        "    with open(filename, 'r') as f:\n",
        "        data = np.loadtxt(f,delimiter=',')\n",
        "    #split to initial arrays\n",
        "    x,y = np.hsplit(data,2)\n",
        "    #printing shapes is useful for debugging\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    #our model\n",
        "    time_start = time()\n",
        "    model = np.polyfit(np.transpose(x)[0], np.transpose(y)[0], 1)\n",
        "    time_end = time()\n",
        "    print(f\"polyfit in {time_end - time_start} seconds\")\n",
        "    # our hypothesis for give x\n",
        "    h =  model[0]*x + model[1]\n",
        "\n",
        "    #and check if it's ok\n",
        "    plt.title(\"Linear regression task\")\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.plot(x, y, \"b.\", label = 'experiment')\n",
        "    plt.plot(x, h, \"r\", label = 'model')    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "sByOQrdCasY_",
        "outputId": "f376f097-c8bf-462c-bede-670348ef02da"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import operator\n",
        "import math\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "DATA_SIZE = 1000\n",
        "data = generate_linear(1, -3, 1, 'linear.csv', 1000)  # return (x,y)\n",
        "polynomial_data = generate_poly([1, 2, 3, 4, 5], 4, 1, 'polynomial.csv', DATA_SIZE)\n",
        "STEP_SIZE = 0.1  # learning rate\n",
        "EPOCHS = 1000\n",
        "DEGREE = 4\n",
        "regularization_coefficient = 0.5\n",
        "\n",
        "def generate_linear(a, b, noise, filename, size = 100):\n",
        "    print('Generating random data y = a*x + b')\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = a * x + b +  noise*a*(np.random.rand(size, 1) -0.5)\n",
        "    data = np.hstack((x,y))\n",
        "    np.savetxt(filename,data,delimiter=',')\n",
        "    return(x,y)\n",
        "\n",
        "\n",
        "def generate_poly(a, n, noise, filename, size = 100):\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = np.zeros((size,1))\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    if len(a) != (n+1):\n",
        "        print(f'ERROR: Length of polynomial coefficients ({len(a)}) must be the same as polynomial degree {n}')\n",
        "        return\n",
        "    for i in range(0,n+1):\n",
        "        y = y + a[i] * np.power(x,i) + noise*(np.random.rand(size, 1) -0.5)\n",
        "    print(np.shape(x))\n",
        "    data = np.hstack((x,y))\n",
        "    np.savetxt(filename,data,delimiter=',')\n",
        "\n",
        "def linear_regression_numpy(filename):\n",
        "    # now let's read it back\n",
        "    with open(filename, 'r') as f:\n",
        "        data = np.loadtxt(f,delimiter=',')\n",
        "    #split to initial arrays\n",
        "    x,y = np.hsplit(data,2)\n",
        "    #printing shapes is useful for debugging\n",
        "    print(np.shape(x))\n",
        "    print(np.shape(y))\n",
        "    #our model\n",
        "    time_start = time()\n",
        "    model = np.polyfit(np.transpose(x)[0], np.transpose(y)[0], 1)\n",
        "    time_end = time()\n",
        "    print(f\"polyfit in {time_end - time_start} seconds\")\n",
        "    # our hypothesis for give x\n",
        "    h =  model[0]*x + model[1]\n",
        "\n",
        "    #and check if it's ok\n",
        "    plt.title(\"Linear regression task\")\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.plot(x, y, \"b.\", label = 'experiment')\n",
        "    plt.plot(x, h, \"r\", label = 'model')    \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return(model)\n",
        "\n",
        "# def linear_regression_with_matrix():\n",
        "#     data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[0]])\n",
        "#     X_matrix_data = np.vstack([data[0], np.ones(len(data[0]))]).T\n",
        "#     a, b = np.linalg.lstsq(X_matrix_data, data[1], rcond=None)[0]\n",
        "\n",
        "#     plt.scatter(data[0], data[1], s=5)\n",
        "#     plt.plot(data[0], a*data[0]+b, 'r')\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "def func_sum_derivative_teta1(x, y, teta1, teta0):\n",
        "    result_sum = 0\n",
        "\n",
        "    for i in range(100):\n",
        "        result_sum += (teta1 * x[i] + teta0 - y[i]) * x[i]\n",
        "\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def func_sum_derivative_teta0(x, y, teta1, teta0):\n",
        "    result_sum = 0\n",
        "\n",
        "    for i in range(100):\n",
        "        result_sum += (teta1 * x[i] + teta0 - y[i])\n",
        "\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def batch_gradient_descent():\n",
        "    data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[0]])\n",
        "    X_matrix_data = np.vstack([data[0], np.ones(len(data[0]))]).T\n",
        "    a, b = np.linalg.lstsq(X_matrix_data, data[1], rcond=None)[0]\n",
        "\n",
        "    # plt.scatter(data[0], data[1])\n",
        "    # plt.plot(data[0], a * data[0] + b, 'r')\n",
        "    # plt.show()\n",
        "    current_teta1, previous_teta1 = 0, 0\n",
        "    current_teta0, previous_teta0 = 0, 0\n",
        "\n",
        "    # data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[0]])\n",
        "    data[1] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[1]])\n",
        "\n",
        "    for i in range(EPOCHS):\n",
        "        current_teta1 = previous_teta1 - STEP_SIZE * (1 / DATA_SIZE) * func_sum_derivative_teta1(data[0], data[1], previous_teta1, previous_teta0)\n",
        "\n",
        "        current_teta0 = previous_teta0 - STEP_SIZE * (1 / DATA_SIZE) * func_sum_derivative_teta0(data[0], data[1], previous_teta1, previous_teta0)\n",
        "\n",
        "        previous_teta1 = current_teta1\n",
        "        previous_teta0 = current_teta0\n",
        "\n",
        "    plt.scatter(data[0], data[1], s=5)\n",
        "    plt.plot(data[0], a * data[0] + b, 'red')\n",
        "    plt.plot(data[0], current_teta1 * data[0] + current_teta0, 'black')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def func_derivative_teta1(x, y, teta1, teta0):\n",
        "    return (teta1 * x + teta0 - y) * x\n",
        "\n",
        "\n",
        "def func_derivative_teta0(x, y, teta1, teta0):\n",
        "    return teta1 * x + teta0 - y\n",
        "\n",
        "\n",
        "def stochastic_gradient_descent():\n",
        "    data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[0]])\n",
        "    X_matrix_data = np.vstack([data[0], np.ones(len(data[0]))]).T\n",
        "    a, b = np.linalg.lstsq(X_matrix_data, data[1], rcond=None)[0]\n",
        "\n",
        "    data[1] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[1]])\n",
        "\n",
        "    current_teta1, previous_teta1 = 0, 0\n",
        "    current_teta0, previous_teta0 = 0, 0\n",
        "\n",
        "    step_count = 0\n",
        "\n",
        "    while step_count < EPOCHS:\n",
        "        number_of_data = random.randint(0, DATA_SIZE-1)\n",
        "\n",
        "        current_teta1 = previous_teta1 - STEP_SIZE * (1 / DATA_SIZE) * func_derivative_teta1(data[0][number_of_data], data[1][number_of_data], current_teta1, current_teta0)\n",
        "\n",
        "        current_teta0 = previous_teta0 - STEP_SIZE * (1 / DATA_SIZE) * func_derivative_teta0(data[0][number_of_data], data[1][number_of_data], previous_teta1, current_teta0)\n",
        "\n",
        "        previous_teta1 = current_teta1\n",
        "        previous_teta0 = current_teta0\n",
        "\n",
        "        step_count += 1\n",
        "\n",
        "        # list_of_used_data.append(number_of_data)\n",
        "\n",
        "    plt.scatter(data[0], data[1])\n",
        "    plt.plot(data[0], a * data[0] + b, 'r')\n",
        "    plt.plot(data[0], current_teta1 * data[0] + current_teta0, 'black')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def mini_batch_derivative_teta1(x, y, teta1, teta0, data_list):\n",
        "    result_sum = 0\n",
        "\n",
        "    for i in range(len(data_list)):\n",
        "        result_sum += (teta1 * x[data_list[i]] + teta0 - y[data_list[i]]) * x[data_list[i]]\n",
        "\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def mini_batch_derivative_teta0(x, y, teta1, teta0, data_list):\n",
        "    result_sum = 0\n",
        "\n",
        "    for i in range(len(data_list)):\n",
        "        result_sum += (teta1 * x[data_list[i]] + teta0 - y[data_list[i]])\n",
        "\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def mini_batch_gradient_descent():\n",
        "    data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[0]])\n",
        "    X_matrix_data = np.vstack([data[0], np.ones(len(data[0]))]).T\n",
        "    a, b = np.linalg.lstsq(X_matrix_data, data[1], rcond=None)[0]\n",
        "\n",
        "    # plt.scatter(data[0], data[1])\n",
        "    # plt.plot(data[0], a * data[0] + b, 'r')\n",
        "    # plt.show()\n",
        "    current_teta1, previous_teta1 = 0, 0\n",
        "    current_teta0, previous_teta0 = 0, 0\n",
        "\n",
        "    # data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[0]])\n",
        "    data[1] = np.concatenate([np.expand_dims(i[0], axis=0) for i in data[1]])\n",
        "\n",
        "    data_list = []\n",
        "\n",
        "    for i in range(int(DATA_SIZE * 0.1)):\n",
        "        data_list.append(random.randint(0, len(data[0]-1)))\n",
        "\n",
        "    for i in range(EPOCHS):\n",
        "        current_teta1 = previous_teta1 - STEP_SIZE * (1 / DATA_SIZE) * mini_batch_derivative_teta1(data[0], data[1], current_teta1, current_teta0, data_list)\n",
        "\n",
        "        current_teta0 = previous_teta0 - STEP_SIZE * (1 / DATA_SIZE) * mini_batch_derivative_teta0(data[0], data[1], previous_teta1, current_teta0, data_list)\n",
        "\n",
        "        previous_teta1 = current_teta1\n",
        "        previous_teta0 = current_teta0\n",
        "\n",
        "    plt.scatter(data[0], data[1])\n",
        "    plt.plot(data[0], a * data[0] + b, 'r')\n",
        "    plt.plot(data[0], current_teta1 * data[0] + current_teta0, 'black')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def func_sum_derivative_teta_i(x, y, teta_list, teta_number):\n",
        "    result_sum = 0\n",
        "    result_sum_degree = 0\n",
        "\n",
        "    for i in range(0, DATA_SIZE):\n",
        "\n",
        "        for degree in range(0, DEGREE+1):\n",
        "            result_sum_degree += teta_list[degree] * pow(x[i], degree)\n",
        "\n",
        "        result_sum += (result_sum_degree - y[i]) * pow(x[i], teta_number)\n",
        "\n",
        "        result_sum_degree = 0\n",
        "\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def result_polynomial_func(teta_list, polynomial_data):\n",
        "    result_sum = 0\n",
        "\n",
        "    for degree in range(0, DEGREE+1):\n",
        "        result_sum += teta_list[degree] * pow(polynomial_data, degree)\n",
        "\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def teta_list_sum(teta_list):\n",
        "    result_sum = 0\n",
        "\n",
        "    for i in range(0, DEGREE+1):\n",
        "        result_sum += teta_list[i]\n",
        "    # (regularization_coefficient / DATA_SIZE) * teta_list_sum(current_teta_i)\n",
        "    return result_sum\n",
        "\n",
        "\n",
        "def polynomial_regression_show():\n",
        "    polynomial_data[0] = np.concatenate([np.expand_dims(i[0], axis=0) for i in polynomial_data[0]])\n",
        "    polynomial_data[1] = np.concatenate([np.expand_dims(i[0], axis=0) for i in polynomial_data[1]])\n",
        "\n",
        "    current_teta_i = [0] * (DEGREE + 1)  # [0, 0, 0, 0, 0]\n",
        "    previous_teta_i = [0] * (DEGREE + 1)  # [0, 0, 0, 0, 0]\n",
        "\n",
        "    for i in range(EPOCHS):\n",
        "        for teta_number in range(0, DEGREE + 1):\n",
        "            current_teta_i[teta_number] = previous_teta_i[teta_number] - (STEP_SIZE / DATA_SIZE) * \\\n",
        "                                          func_sum_derivative_teta_i(polynomial_data[0], polynomial_data[1],\n",
        "                                                                     previous_teta_i, teta_number)\n",
        "\n",
        "        for teta_number in range(0, DEGREE + 1):\n",
        "            previous_teta_i[teta_number] = current_teta_i[teta_number]\n",
        "\n",
        "    # x = polynomial_data[0][:, np.newaxis]\n",
        "    # y = polynomial_data[1][:, np.newaxis]\n",
        "    #\n",
        "    # polynomial_features = PolynomialFeatures(degree=4)\n",
        "    # x_poly = polynomial_features.fit_transform(x)\n",
        "    #\n",
        "    # model = LinearRegression()\n",
        "    # model.fit(x_poly, y)\n",
        "    # y_poly_pred = model.predict(x_poly)\n",
        "    #\n",
        "    # # sort the values of x before line plot\n",
        "    # sort_axis = operator.itemgetter(0)\n",
        "    # sorted_zip = sorted(zip(x, y_poly_pred), key=sort_axis)\n",
        "    # x, y_poly_pred = zip(*sorted_zip)\n",
        "    # plt.plot(x, y_poly_pred, color='black')\n",
        "\n",
        "    plt.scatter(polynomial_data[0], polynomial_data[1], s=5)\n",
        "    polynomial_data[0].sort()\n",
        "    plt.plot(polynomial_data[0], result_polynomial_func(current_teta_i, polynomial_data[0]), 'red')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#linear_regression_with_matrix()\n",
        "batch_gradient_descent()\n",
        "# stochastic_gradient_descent()\n",
        "# mini_batch_gradient_descent()\n",
        "#polynomial_regression_show()\n",
        "# stohastic_polynomial_regression_show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating random data y = a*x + b\n",
            "(1000, 1)\n",
            "(1000, 1)\n",
            "(1000, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-23c14dc978e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;31m#linear_regression_with_matrix()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m \u001b[0mbatch_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;31m# stochastic_gradient_descent()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;31m# mini_batch_gradient_descent()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-23c14dc978e5>\u001b[0m in \u001b[0;36mbatch_gradient_descent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mX_matrix_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_matrix_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lCYz-d6lvoF"
      },
      "source": [
        "#LR3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG73H7Om6Kcd"
      },
      "source": [
        "1. Реализовать класс полносвзной нейросети, метод обратного распространения ошибки и метод градиентного спуска для него. Решить те же задачи (линейная и полиномиальная регрессия), что и в первой лабе. В данном случае у вас должна быть ОДНА модель для обеих задач. И качеством решения будет не точность восстановления коэффициентов полинома (их вы вообще не узнаете), а точность предсказаний на котрольной выборке. Аналогично надо оценить и сложность и переобучение и построить все сопустсвующие графики. Использовать тот же генератор, что и во второй лабе, можно в ноутбуке, если хотите.\n",
        "2. Сравните полученное решение я реализацией нейросети на tensorflow, keras или torch, параметры сети и обучения возьмите те же\n",
        "3. В прошлом году была еще бонусная задача по классификации рукописных цифр (MNIST) на четные и нечетные +10 баллов\n",
        "4. и по классификации рукописных ЧИСЕЛ на четные и нечетные (+20 баллов)\n",
        "PS  Здесь можно обойтись и без сверточных сетей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPZIHOtYlzGs",
        "outputId": "3e808969-23d5-42b6-85aa-aba1942aed71"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Наша функция активации: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Умножаем входы на веса, прибавляем порог, затем используем функцию активации\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "bias = 4                   # b = 4\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
        "print(n.feedforward(x))    # 0.9990889488055994\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYc26LRZK0g9",
        "outputId": "8d8109c5-bb14-4084-c8a9-9f581c369976"
      },
      "source": [
        "class OurNeuralNetwork:\n",
        "  '''\n",
        "  Нейронная сеть с:\n",
        "    - 2 входами\n",
        "    - скрытым слоем с 2 нейронами (h1, h2)\n",
        "    - выходным слоем с 1 нейроном (o1)\n",
        "  Все нейроны имеют одинаковые веса и пороги:\n",
        "    - w = [0, 1]\n",
        "    - b = 0\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    weights = np.array([0, 1])\n",
        "    bias = 0\n",
        "\n",
        "    # Используем класс Neuron из предыдущего раздела\n",
        "    self.h1 = Neuron(weights, bias)\n",
        "    self.h2 = Neuron(weights, bias)\n",
        "    self.o1 = Neuron(weights, bias)\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    out_h1 = self.h1.feedforward(x)\n",
        "    out_h2 = self.h2.feedforward(x)\n",
        "\n",
        "    # Входы для o1 - это выходы h1 и h2\n",
        "    out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
        "\n",
        "    return out_o1\n",
        "\n",
        "network = OurNeuralNetwork()\n",
        "x = np.array([2, 3])\n",
        "print(network.feedforward(x)) # 0.7216325609518421"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7216325609518421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuW0d4qFLOff"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
        "  fx = sigmoid(x)\n",
        "  return fx * (1 - fx)\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "  # y_true and y_pred are numpy arrays of the same length.\n",
        "  return ((y_true - y_pred) ** 2).mean()\n",
        "\n",
        "class OurNeuralNetwork:\n",
        "  '''\n",
        "  A neural network with:\n",
        "    - 2 inputs\n",
        "    - a hidden layer with 2 neurons (h1, h2)\n",
        "    - an output layer with 1 neuron (o1)\n",
        "  *** DISCLAIMER ***:\n",
        "  The code below is intended to be simple and educational, NOT optimal.\n",
        "  Real neural net code looks nothing like this. DO NOT use this code.\n",
        "  Instead, read/run it to understand how this specific network works.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    # Weights\n",
        "    self.w1 = np.random.normal()\n",
        "    self.w2 = np.random.normal()\n",
        "    self.w3 = np.random.normal()\n",
        "    self.w4 = np.random.normal()\n",
        "    self.w5 = np.random.normal()\n",
        "    self.w6 = np.random.normal()\n",
        "\n",
        "    # Biases\n",
        "    self.b1 = np.random.normal()\n",
        "    self.b2 = np.random.normal()\n",
        "    self.b3 = np.random.normal()\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    # x is a numpy array with 2 elements.\n",
        "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
        "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
        "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
        "    return o1\n",
        "\n",
        "  def train(self, data, all_y_trues):\n",
        "    '''\n",
        "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
        "    - all_y_trues is a numpy array with n elements.\n",
        "      Elements in all_y_trues correspond to those in data.\n",
        "    '''\n",
        "    learn_rate = 1\n",
        "    epochs = 100000 # number of times to loop through the entire dataset\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for x, y_true in zip(data, all_y_trues):\n",
        "        # --- Do a feedforward (we'll need these values later)\n",
        "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
        "        h1 = sigmoid(sum_h1)\n",
        "\n",
        "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
        "        h2 = sigmoid(sum_h2)\n",
        "\n",
        "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
        "        o1 = sigmoid(sum_o1)\n",
        "        y_pred = o1\n",
        "\n",
        "        # --- Calculate partial derivatives.\n",
        "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
        "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
        "\n",
        "        # Neuron o1\n",
        "        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
        "        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
        "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
        "\n",
        "        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
        "        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
        "\n",
        "        # Neuron h1\n",
        "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
        "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
        "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
        "\n",
        "        # Neuron h2\n",
        "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
        "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
        "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
        "\n",
        "        # --- Update weights and biases\n",
        "        # Neuron h1\n",
        "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
        "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
        "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
        "\n",
        "        # Neuron h2\n",
        "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
        "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
        "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
        "\n",
        "        # Neuron o1\n",
        "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
        "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
        "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
        "\n",
        "      # --- Calculate total loss at the end of each epoch\n",
        "      if epoch % 10 == 0:\n",
        "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
        "        loss = mse_loss(all_y_trues, y_preds)\n",
        "        print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
        "\n",
        "# Define dataset\n",
        "#135 66\n",
        "# data = np.array([\n",
        "#   [-2, -1],  # Alice\n",
        "#   [25, 6],   # Bob\n",
        "#   [17, 4],   # Charlie\n",
        "#   [-15, -6], # Diana\n",
        "# ])\n",
        "data = np.array([\n",
        "  [133, 65],  # Alice\n",
        "  [160, 72],   # Bob\n",
        "  [152, 70],   # Charlie\n",
        "  [120, 60], # Diana\n",
        "])\n",
        "all_y_trues = np.array([\n",
        "  1, # Alice\n",
        "  0, # Bob\n",
        "  0, # Charlie\n",
        "  1, # Diana\n",
        "])\n",
        "\n",
        "# Train our neural network!\n",
        "network = OurNeuralNetwork()\n",
        "network.train(data, all_y_trues)\n",
        "\n",
        "# Make some predictions\n",
        "emily = np.array([128, 63]) # 128 pounds, 63 inches\n",
        "frank = np.array([155, 68])  # 155 pounds, 68 inches\n",
        "print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
        "print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poly(a, n, noise, filename, size = 100):\n",
        "    x = 2 * np.random.rand(size, 1) - 1\n",
        "    y = np.zeros((size,1))\n",
        "    \n",
        "    if len(a) != (n+1):\n",
        "        print(f'ERROR: Length of polynomial coefficients ({len(a)}) must be the same as polynomial degree {n}')\n",
        "        return\n",
        "    \n",
        "    for i in range(0,n+1):\n",
        "        y += a[i] * np.power(x,i) + noise*(np.random.rand(size, 1) -0.5)\n",
        "    \n",
        "    \n",
        "\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "uFnqqijbApOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2*np.random.rand(10, 1)-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP7cMqWYGvRG",
        "outputId": "6ab60722-ceda-4682-9192-3d8b5964f23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.96408506],\n",
              "       [-0.36779709],\n",
              "       [ 0.87799656],\n",
              "       [-0.45964079],\n",
              "       [-0.22906542],\n",
              "       [ 0.10910744],\n",
              "       [ 0.88431184],\n",
              "       [-0.44629449],\n",
              "       [-0.51533458],\n",
              "       [-0.12524441]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    x, y = generate_poly([1,3,9,27], 3, 0.3, 'test.txt',size=100)\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "    ax.scatter(x, y, label='train dataset')\n",
        "    ax.set_xlabel('X', fontsize=16)\n",
        "    ax.set_ylabel('Y', fontsize=16)\n",
        "    ax.axhline(y=0, color='k')\n",
        "    ax.axvline(x=0, color='k')\n",
        "    ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "wkkRWtKHBrEN",
        "outputId": "f795baa0-2bf1-4388-9c8b-7d25fb518af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efbd5ac9e90>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}